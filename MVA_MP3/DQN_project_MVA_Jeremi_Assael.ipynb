{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jérémi Assael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\assae\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__ If train is true, then we are in the step in which we are training our agent. We have set an epsilon value between 0 ad 1 to handle the exploration/exploitation dilemma.Then, we start by taking a random number between 0 and 1. If this number is below or equal to epsilon, then our agent is going to explore a new state by taking a new action (a random action) he may never have taken being in this particular state. On the contrary, if the random number is above epsilon, our agent is going to exploit what it has already learnt by applying the learnt policy for its current state.\n",
    "\n",
    "If train is false, then we suppose that our agent has already learnt the desired policy and we are going to apply it to select the action our agent is going to take when being in a particular state. \n",
    "\n",
    "The epsilon value is essential as it allows the agent to potentially maximize its reward by both exploiting current best actions for the current state and exploring new actions for the current state which are potentially better. \n",
    "- Small espilon favored exploitation. Exloiting the learnt policy allows the agent to take an action in the current state which we already know is going to give us an important reward. \n",
    "- Large epsilon favored exploration. Exploring allows the agent to try new actions in the current state which are potentially better in terms of reward than the ones already discovered. \n",
    "\n",
    "Setting the right epsilon allows our agent to rely on known results (exploiting) while still searching for better ones (exploring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the rat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=1200 # set small when debugging\n",
    "epochs_test=25 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__ The array position is used to show the position of the rat in the game. It is a square with a size equal to the grid_size+4, the +4 allowing for an easier processing of the cases where the rat is on the borders. Because of this added size, the position array is filled as follow:\n",
    "- there are -1 in every position which are not real and that can't be taken by the rat (the ones due to the +4, only here to allow for an easier processing of the cases where the rat is on the borders). So, there are -1 in the first and last two columns and in the first and last two lines.\n",
    "- there is a 1 in the case where the rat currently is.\n",
    "- there are 0 everywhere else.\n",
    "\n",
    "The array board is a reprensation of the bonuses (in red in the drawing) and maluses (in blue in the drawing) on the game grid (with the size grid_size+4). Each case of the array board is built so that it is associated either with a positive reward (+0.5), a negative reward (-1) or no reward (0). The starting case for the rat does not contain any reward. This representation is convenient because it is really easy to have access to the successive reward the rat is getting: we just have to take in the board array the reward on the case with the same coordinates than the case of value 1 in the position array. Because of the way the board array is built, there can be rewards on the borders (first and last two columns and lines) but as the rat cannot move there, they will be ignore.\n",
    "\n",
    "A state is then defined by the concatenation of these two arrays, by taking only the 25 cases (square of dimension 5x5 centered on the rat) of visibility the rat have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        #We just choose a random action\n",
    "        random_act = np.random.randint(0,4)\n",
    "        return random_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        ##### FILL IN HERE\n",
    "        # Environment re-initialization\n",
    "        state = env.reset()\n",
    "        \n",
    "        game_over = False\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over:\n",
    "        #While the max_time has not been reached\n",
    "            \n",
    "            #We choose an action according to the policy\n",
    "            action = agent.learned_act(state)\n",
    "            prev_state = state\n",
    "            #We compute the effects of this action on the environment\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 7.5/17.0. Average score (-9.5)\n",
      "Win/lose count 6.0/11.0. Average score (-7.25)\n",
      "Win/lose count 14.5/13.0. Average score (-4.333333333333333)\n",
      "Win/lose count 9.5/13.0. Average score (-4.125)\n",
      "Win/lose count 9.5/16.0. Average score (-4.6)\n",
      "Win/lose count 12.0/10.0. Average score (-3.5)\n",
      "Win/lose count 12.0/14.0. Average score (-3.2857142857142856)\n",
      "Win/lose count 7.5/9.0. Average score (-3.0625)\n",
      "Win/lose count 9.0/27.0. Average score (-4.722222222222222)\n",
      "Win/lose count 9.0/18.0. Average score (-5.15)\n",
      "Win/lose count 9.5/10.0. Average score (-4.7272727272727275)\n",
      "Win/lose count 4.5/14.0. Average score (-5.125)\n",
      "Win/lose count 9.5/19.0. Average score (-5.461538461538462)\n",
      "Win/lose count 12.5/14.0. Average score (-5.178571428571429)\n",
      "Win/lose count 11.0/13.0. Average score (-4.966666666666667)\n",
      "Win/lose count 9.5/16.0. Average score (-5.0625)\n",
      "Win/lose count 11.5/13.0. Average score (-4.852941176470588)\n",
      "Win/lose count 11.0/19.0. Average score (-5.027777777777778)\n",
      "Win/lose count 9.5/17.0. Average score (-5.157894736842105)\n",
      "Win/lose count 10.0/16.0. Average score (-5.2)\n",
      "Win/lose count 12.0/16.0. Average score (-5.142857142857143)\n",
      "Win/lose count 10.0/13.0. Average score (-5.045454545454546)\n",
      "Win/lose count 7.5/10.0. Average score (-4.934782608695652)\n",
      "Win/lose count 7.5/13.0. Average score (-4.958333333333333)\n",
      "Win/lose count 10.5/14.0. Average score (-4.9)\n",
      "Final score: -4.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__ \n",
    "\n",
    "__(1)__\n",
    "Let's first remind that $Q^\\pi$ is defined as follow, with here $T=\\infty$ (definition given above):\n",
    "\n",
    "$$Q^\\pi(s,a)=E\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right]$$\n",
    "\n",
    "We then have:\n",
    "\n",
    "$$Q^\\pi(s,a)=E\\left[r(s,a) + \\sum_{t=1}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right]$$\n",
    "\n",
    "$$Q^\\pi(s,a)=r(s,a) + E\\left[\\sum_{t=0}^{\\infty}\\gamma^{t+1}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a\\right]$$\n",
    "\n",
    "$$Q^\\pi(s,a)=r(s,a) + \\gamma \\ E\\left[\\ E\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a\\right] | \\ s_1=s', a_1=a'\\right]$$\n",
    "\n",
    "$$Q^\\pi(s,a)=r(s,a) + \\gamma \\ E\\left[\\ E\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{1}=s',a_{1}=a'\\right] | \\ s_0=s, a_0=a\\right]$$\n",
    "\n",
    "$$Q^\\pi(s,a)=r(s,a) + \\gamma \\ \\sum_{(s',a')} p(s_{1}=s',a_{1}=a' |s_0 = s, a_0 = a )\\ E\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{1}=s',a_{1}=a'\\right]$$\n",
    "\n",
    "With :\n",
    "$$ E\\left[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{1}=s',a_{1}=a'\\right] = Q^\\pi(s',a') $$\n",
    "\n",
    "We get:\n",
    "\n",
    "$$Q^\\pi(s,a)=r(s,a) + \\gamma \\ \\sum_{(s',a')} p(s_{1}=s',a_{1}=a' |s_0 = s, a_0 = a )\\ Q^\\pi(s',a')$$\n",
    "\n",
    "$$Q^\\pi(s,a)=r(s,a) + \\gamma \\ E_{(s',a')\\sim p(.|s,a)}[Q^\\pi(s',a')]$$\n",
    "\n",
    "$$Q^\\pi(s,a)= E_{(s',a')\\sim p(.|s,a)}[r(s,a) + \\gamma Q^\\pi(s',a')]$$\n",
    "\n",
    "\n",
    "__(2)__ \n",
    "The optimal Q function is: $Q^*(s,a)=\\max_{\\pi} Q^\\pi(s,a)$\n",
    "\n",
    "Then, \n",
    "\n",
    "$$Q^*(s,a)=\\max_{\\pi}E_{(s',a')\\sim p(.|s,a)}[r(s,a) + \\gamma Q^\\pi(s',a')]$$\n",
    "\n",
    "$$Q^*(s,a)=\\max_{\\pi}\\left(r(s,a) + \\gamma \\sum_{(s',a')} p(s_{1}=s',a_{1}=a' |s_0 = s, a_0 = a )\\ Q^\\pi(s',a')\\right) \\leq r(s,a) + \\gamma\\sum_{(s',a')} p(s_{1}=s',a_{1}=a' |s_0 = s, a_0 = a )\\ \\max_{\\pi}(Q^\\pi(s',a'))$$\n",
    "\n",
    "If we note $\\pi^*$ the optimal policy, we then have:  $\\pi^*(s) = argmax_{a}Q^*(s,a)$\n",
    "\n",
    "Then, it comes that: \n",
    "\n",
    "$$Q^*(s,a) \\leq r(s,a) + \\gamma\\sum_{s'} p(s_{1}=s',a_{1}=\\pi^*(s) \\ | \\ s_0 = s, a_0 = a )\\ \\max_{a'}(Q^*(s',a')) $$\n",
    "\n",
    "We necessarily have, as $Q^*$ is the optimal action value function:\n",
    "\n",
    "$$Q^*(s,a) \\leq r(s,a) + \\gamma\\sum_{s'} p(s_{1}=s',a_{1}=\\pi^*(s) \\ | \\ s_0 = s, a_0 = a )\\ \\max_{a'}(Q^*(s',a')) \\leq Q^*(s,a) $$\n",
    "\n",
    "Finally:\n",
    "\n",
    "$$Q^*(s,a) = E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')] $$\n",
    "\n",
    "\n",
    "__(3)__ Our goal in deep Q-learning is to make our network learn the optimal Q-function. Then, we want at each iteration to reduce the gap between the optimal Q-function and the learnt one. Because we don't have access to the optimal Q-function (as we are trying to learn it), we are going to reduce this gap using a kind of proxy of the optimal Q-function: we replace the $Q^*$ in the expression of the optimal Q-function by the Q-function chosen using the action which maximize it. This proxy for $Q^*$ is then written:  $Q^*(s,a) = E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q(s',a')] $. Then, because we want to reduce the gap between this $Q^*$ proxy and the $Q$ we are currently learning, we are going to reduce the maximum gap by defining the loss as the mean square error of the maximum gap between the proxy of $Q^*$ and the $Q$ we are learning.\n",
    "\n",
    "This gives us the loss that we will try to minimize:\n",
    "\n",
    "$$\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}$$\n",
    "\n",
    "Then, if our network converge, we are going to make the learnt $Q$ converge towards $Q^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        if len(self.memory) < self.max_memory:\n",
    "            #if the memory is not full, we add the move to the memory\n",
    "            self.memory.append(m)\n",
    "        else:\n",
    "            #if the memory is full, we remove the oldest element before adding the new move\n",
    "            self.memory.pop(0)\n",
    "            self.memory.append(m)\n",
    "\n",
    "    def random_access(self):\n",
    "        # we take a random element in our memory\n",
    "        index = np.random.choice(list(range(len(self.memory))))\n",
    "        return self.memory[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.argmax(self.model.predict(s.reshape(1,5,5,self.n_state)))\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            \n",
    "            #Let's get a sample of our memory and put it in ours input_states\n",
    "            [s_old, n_s_old, a_old, r_old, game_over_old] = self.memory.random_access()\n",
    "            input_states[i] = s_old\n",
    "            \n",
    "            target_q[i] = self.model.predict(s_old.reshape(1,5,5,self.n_state))\n",
    "            if game_over_:\n",
    "                ######## FILL IN\n",
    "                target_q[i,a_old] = r_old\n",
    "            else:\n",
    "                ######## FILL IN\n",
    "                #We need to define an input and a label. As it is not supervised learning, we are using a kind of proxy for the label\n",
    "                prediction_next_state = self.model.predict(n_s_old.reshape(1,5,5,self.n_state))\n",
    "                target_q[i,a_old] = r_old + self.discount*np.max(prediction_next_state)\n",
    "        \n",
    "        ######## FILL IN\n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        ####### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5, 5, self.n_state)))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(self.n_action, activation='linear'))          \n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/400 | Loss 0.0140 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 001/400 | Loss 0.0483 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 002/400 | Loss 0.0533 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 003/400 | Loss 0.0431 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 004/400 | Loss 0.0539 | Win/lose count 7.0/3.0 (4.0)\n",
      "Epoch 005/400 | Loss 0.0645 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 006/400 | Loss 0.0868 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 007/400 | Loss 0.1131 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 008/400 | Loss 0.1238 | Win/lose count 5.0/8.0 (-3.0)\n",
      "Epoch 009/400 | Loss 0.1473 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 010/400 | Loss 0.1850 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 011/400 | Loss 0.2219 | Win/lose count 5.5/5.0 (0.5)\n",
      "Epoch 012/400 | Loss 0.2690 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 013/400 | Loss 0.3016 | Win/lose count 3.5/5.0 (-1.5)\n",
      "Epoch 014/400 | Loss 0.3588 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 015/400 | Loss 0.3664 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 016/400 | Loss 0.3594 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 017/400 | Loss 0.4453 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 018/400 | Loss 0.4163 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 019/400 | Loss 0.4575 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 020/400 | Loss 0.5168 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 021/400 | Loss 0.4870 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 022/400 | Loss 0.5731 | Win/lose count 3.5/5.0 (-1.5)\n",
      "Epoch 023/400 | Loss 0.5922 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 024/400 | Loss 0.6131 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 025/400 | Loss 0.7092 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 026/400 | Loss 0.7427 | Win/lose count 5.0/5.0 (0.0)\n",
      "Epoch 027/400 | Loss 0.8455 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 028/400 | Loss 0.7868 | Win/lose count 2.0/7.0 (-5.0)\n",
      "Epoch 029/400 | Loss 0.8137 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 030/400 | Loss 0.8792 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 031/400 | Loss 0.7600 | Win/lose count 5.5/7.0 (-1.5)\n",
      "Epoch 032/400 | Loss 0.8546 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 033/400 | Loss 0.7250 | Win/lose count 3.5/5.0 (-1.5)\n",
      "Epoch 034/400 | Loss 0.7326 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 035/400 | Loss 0.7163 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 036/400 | Loss 0.7145 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 037/400 | Loss 0.7006 | Win/lose count 8.5/8.0 (0.5)\n",
      "Epoch 038/400 | Loss 0.6332 | Win/lose count 5.0/4.0 (1.0)\n",
      "Epoch 039/400 | Loss 0.6581 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 040/400 | Loss 0.6713 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 041/400 | Loss 0.6165 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 042/400 | Loss 0.6154 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 043/400 | Loss 0.6507 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 044/400 | Loss 0.6102 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 045/400 | Loss 0.6399 | Win/lose count 13.5/5.0 (8.5)\n",
      "Epoch 046/400 | Loss 0.6237 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 047/400 | Loss 0.6235 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 048/400 | Loss 0.6468 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 049/400 | Loss 0.6984 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 050/400 | Loss 0.7837 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 051/400 | Loss 0.8223 | Win/lose count 8.0/6.0 (2.0)\n",
      "Epoch 052/400 | Loss 0.9071 | Win/lose count 8.5/8.0 (0.5)\n",
      "Epoch 053/400 | Loss 1.1276 | Win/lose count 8.0/4.0 (4.0)\n",
      "Epoch 054/400 | Loss 1.2062 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 055/400 | Loss 1.3224 | Win/lose count 6.0/0 (6.0)\n",
      "Epoch 056/400 | Loss 1.4317 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 057/400 | Loss 1.4908 | Win/lose count 10.0/1.0 (9.0)\n",
      "Epoch 058/400 | Loss 1.3731 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 059/400 | Loss 1.4445 | Win/lose count 10.5/5.0 (5.5)\n",
      "Epoch 060/400 | Loss 1.4753 | Win/lose count 5.5/0 (5.5)\n",
      "Epoch 061/400 | Loss 1.4931 | Win/lose count 10.0/4.0 (6.0)\n",
      "Epoch 062/400 | Loss 1.5715 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 063/400 | Loss 1.4578 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 064/400 | Loss 1.5452 | Win/lose count 4.5/3.0 (1.5)\n",
      "Epoch 065/400 | Loss 1.4889 | Win/lose count 2.5/5.0 (-2.5)\n",
      "Epoch 066/400 | Loss 1.4967 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 067/400 | Loss 1.3372 | Win/lose count 0/2.0 (-2.0)\n",
      "Epoch 068/400 | Loss 1.3606 | Win/lose count 5.0/4.0 (1.0)\n",
      "Epoch 069/400 | Loss 1.3761 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 070/400 | Loss 1.3202 | Win/lose count 5.0/6.0 (-1.0)\n",
      "Epoch 071/400 | Loss 1.3132 | Win/lose count 7.5/3.0 (4.5)\n",
      "Epoch 072/400 | Loss 1.2567 | Win/lose count 8.0/7.0 (1.0)\n",
      "Epoch 073/400 | Loss 1.1983 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 074/400 | Loss 1.1341 | Win/lose count 8.0/4.0 (4.0)\n",
      "Epoch 075/400 | Loss 1.0624 | Win/lose count 9.5/5.0 (4.5)\n",
      "Epoch 076/400 | Loss 1.0990 | Win/lose count 5.0/4.0 (1.0)\n",
      "Epoch 077/400 | Loss 1.0832 | Win/lose count 10.0/6.0 (4.0)\n",
      "Epoch 078/400 | Loss 1.0833 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 079/400 | Loss 1.1963 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 080/400 | Loss 1.2389 | Win/lose count 5.0/4.0 (1.0)\n",
      "Epoch 081/400 | Loss 1.4164 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 082/400 | Loss 1.4211 | Win/lose count 6.5/6.0 (0.5)\n",
      "Epoch 083/400 | Loss 1.5040 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 084/400 | Loss 1.4508 | Win/lose count 7.0/3.0 (4.0)\n",
      "Epoch 085/400 | Loss 1.4742 | Win/lose count 7.5/5.0 (2.5)\n",
      "Epoch 086/400 | Loss 1.4836 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 087/400 | Loss 1.3768 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 088/400 | Loss 1.4809 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 089/400 | Loss 1.3862 | Win/lose count 8.0/5.0 (3.0)\n",
      "Epoch 090/400 | Loss 1.5080 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 091/400 | Loss 1.5565 | Win/lose count 9.5/5.0 (4.5)\n",
      "Epoch 092/400 | Loss 1.5165 | Win/lose count 4.0/4.0 (0.0)\n",
      "Epoch 093/400 | Loss 1.5415 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 094/400 | Loss 1.5537 | Win/lose count 7.5/2.0 (5.5)\n",
      "Epoch 095/400 | Loss 1.5731 | Win/lose count 9.5/4.0 (5.5)\n",
      "Epoch 096/400 | Loss 1.5578 | Win/lose count 14.5/7.0 (7.5)\n",
      "Epoch 097/400 | Loss 1.5423 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 098/400 | Loss 1.4897 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 099/400 | Loss 1.4556 | Win/lose count 5.5/4.0 (1.5)\n",
      "Epoch 100/400 | Loss 1.4846 | Win/lose count 13.0/4.0 (9.0)\n",
      "Epoch 101/400 | Loss 1.5536 | Win/lose count 18.0/5.0 (13.0)\n",
      "Epoch 102/400 | Loss 1.5494 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 103/400 | Loss 1.5723 | Win/lose count 7.0/1.0 (6.0)\n",
      "Epoch 104/400 | Loss 1.5256 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 105/400 | Loss 1.5940 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 106/400 | Loss 1.5655 | Win/lose count 7.5/3.0 (4.5)\n",
      "Epoch 107/400 | Loss 1.4965 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 108/400 | Loss 1.5112 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 109/400 | Loss 1.5869 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 110/400 | Loss 1.5304 | Win/lose count 9.5/0 (9.5)\n",
      "Epoch 111/400 | Loss 1.5757 | Win/lose count 22.0/1.0 (21.0)\n",
      "Epoch 112/400 | Loss 1.5657 | Win/lose count 9.0/1.0 (8.0)\n",
      "Epoch 113/400 | Loss 1.5669 | Win/lose count 15.0/2.0 (13.0)\n",
      "Epoch 114/400 | Loss 1.6063 | Win/lose count 7.5/2.0 (5.5)\n",
      "Epoch 115/400 | Loss 1.7020 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 116/400 | Loss 1.5927 | Win/lose count 14.0/7.0 (7.0)\n",
      "Epoch 117/400 | Loss 1.6486 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 118/400 | Loss 1.6423 | Win/lose count 5.5/0 (5.5)\n",
      "Epoch 119/400 | Loss 1.5332 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 120/400 | Loss 1.6136 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 121/400 | Loss 1.6417 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 122/400 | Loss 1.6203 | Win/lose count 13.0/2.0 (11.0)\n",
      "Epoch 123/400 | Loss 1.6155 | Win/lose count 9.0/3.0 (6.0)\n",
      "Epoch 124/400 | Loss 1.6007 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 125/400 | Loss 1.5593 | Win/lose count 14.0/1.0 (13.0)\n",
      "Epoch 126/400 | Loss 1.6655 | Win/lose count 12.5/0 (12.5)\n",
      "Epoch 127/400 | Loss 1.6548 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 128/400 | Loss 1.6492 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 129/400 | Loss 1.5907 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 130/400 | Loss 1.5953 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 131/400 | Loss 1.6008 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 132/400 | Loss 1.5798 | Win/lose count 7.5/1.0 (6.5)\n",
      "Epoch 133/400 | Loss 1.6039 | Win/lose count 11.5/0 (11.5)\n",
      "Epoch 134/400 | Loss 1.6911 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 135/400 | Loss 1.5940 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 136/400 | Loss 1.5906 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 137/400 | Loss 1.6132 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 138/400 | Loss 1.5869 | Win/lose count 4.5/0 (4.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/400 | Loss 1.5877 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 140/400 | Loss 1.5979 | Win/lose count 10.0/3.0 (7.0)\n",
      "Epoch 141/400 | Loss 1.5763 | Win/lose count 13.5/3.0 (10.5)\n",
      "Epoch 142/400 | Loss 1.6068 | Win/lose count 8.0/4.0 (4.0)\n",
      "Epoch 143/400 | Loss 1.5572 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 144/400 | Loss 1.5667 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 145/400 | Loss 1.5437 | Win/lose count 19.5/5.0 (14.5)\n",
      "Epoch 146/400 | Loss 1.5960 | Win/lose count 13.5/0 (13.5)\n",
      "Epoch 147/400 | Loss 1.5850 | Win/lose count 6.5/2.0 (4.5)\n",
      "Epoch 148/400 | Loss 1.5956 | Win/lose count 7.0/1.0 (6.0)\n",
      "Epoch 149/400 | Loss 1.5802 | Win/lose count 18.5/2.0 (16.5)\n",
      "Epoch 150/400 | Loss 1.5622 | Win/lose count 10.0/5.0 (5.0)\n",
      "Epoch 151/400 | Loss 1.6681 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 152/400 | Loss 1.6582 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 153/400 | Loss 1.5619 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 154/400 | Loss 1.5835 | Win/lose count 20.5/1.0 (19.5)\n",
      "Epoch 155/400 | Loss 1.5970 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 156/400 | Loss 1.6633 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 157/400 | Loss 1.6475 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 158/400 | Loss 1.6456 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 159/400 | Loss 1.6992 | Win/lose count 15.5/7.0 (8.5)\n",
      "Epoch 160/400 | Loss 1.6194 | Win/lose count 8.5/0 (8.5)\n",
      "Epoch 161/400 | Loss 1.6510 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 162/400 | Loss 1.6748 | Win/lose count 22.5/4.0 (18.5)\n",
      "Epoch 163/400 | Loss 1.6251 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 164/400 | Loss 1.6777 | Win/lose count 7.0/4.0 (3.0)\n",
      "Epoch 165/400 | Loss 1.5744 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 166/400 | Loss 1.6050 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 167/400 | Loss 1.6483 | Win/lose count 10.5/3.0 (7.5)\n",
      "Epoch 168/400 | Loss 1.6820 | Win/lose count 17.0/4.0 (13.0)\n",
      "Epoch 169/400 | Loss 1.6401 | Win/lose count 16.0/1.0 (15.0)\n",
      "Epoch 170/400 | Loss 1.6234 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 171/400 | Loss 1.6638 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 172/400 | Loss 1.6451 | Win/lose count 12.0/1.0 (11.0)\n",
      "Epoch 173/400 | Loss 1.6551 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 174/400 | Loss 1.7040 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 175/400 | Loss 1.5932 | Win/lose count 11.5/0 (11.5)\n",
      "Epoch 176/400 | Loss 1.5644 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 177/400 | Loss 1.6402 | Win/lose count 10.0/1.0 (9.0)\n",
      "Epoch 178/400 | Loss 1.6176 | Win/lose count 12.0/4.0 (8.0)\n",
      "Epoch 179/400 | Loss 1.6392 | Win/lose count 6.0/4.0 (2.0)\n",
      "Epoch 180/400 | Loss 1.6166 | Win/lose count 12.0/2.0 (10.0)\n",
      "Epoch 181/400 | Loss 1.6186 | Win/lose count 8.5/0 (8.5)\n",
      "Epoch 182/400 | Loss 1.5734 | Win/lose count 15.5/4.0 (11.5)\n",
      "Epoch 183/400 | Loss 1.5826 | Win/lose count 9.5/3.0 (6.5)\n",
      "Epoch 184/400 | Loss 1.6143 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 185/400 | Loss 1.5620 | Win/lose count 8.0/3.0 (5.0)\n",
      "Epoch 186/400 | Loss 1.5021 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 187/400 | Loss 1.5221 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 188/400 | Loss 1.5078 | Win/lose count 7.5/0 (7.5)\n",
      "Epoch 189/400 | Loss 1.4720 | Win/lose count 7.5/5.0 (2.5)\n",
      "Epoch 190/400 | Loss 1.4797 | Win/lose count 5.5/0 (5.5)\n",
      "Epoch 191/400 | Loss 1.4399 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 192/400 | Loss 1.4755 | Win/lose count 12.0/2.0 (10.0)\n",
      "Epoch 193/400 | Loss 1.5447 | Win/lose count 15.5/1.0 (14.5)\n",
      "Epoch 194/400 | Loss 1.5038 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 195/400 | Loss 1.5607 | Win/lose count 16.0/5.0 (11.0)\n",
      "Epoch 196/400 | Loss 1.5409 | Win/lose count 13.0/4.0 (9.0)\n",
      "Epoch 197/400 | Loss 1.6389 | Win/lose count 15.5/2.0 (13.5)\n",
      "Epoch 198/400 | Loss 1.6084 | Win/lose count 7.0/1.0 (6.0)\n",
      "Epoch 199/400 | Loss 1.6244 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 200/400 | Loss 1.6265 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 201/400 | Loss 1.6006 | Win/lose count 9.5/7.0 (2.5)\n",
      "Epoch 202/400 | Loss 1.6038 | Win/lose count 10.5/4.0 (6.5)\n",
      "Epoch 203/400 | Loss 1.6541 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 204/400 | Loss 1.6230 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 205/400 | Loss 1.6901 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 206/400 | Loss 1.5441 | Win/lose count 11.0/0 (11.0)\n",
      "Epoch 207/400 | Loss 1.5932 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 208/400 | Loss 1.6271 | Win/lose count 15.5/2.0 (13.5)\n",
      "Epoch 209/400 | Loss 1.5960 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 210/400 | Loss 1.5340 | Win/lose count 9.0/4.0 (5.0)\n",
      "Epoch 211/400 | Loss 1.5164 | Win/lose count 10.5/4.0 (6.5)\n",
      "Epoch 212/400 | Loss 1.5222 | Win/lose count 12.5/0 (12.5)\n",
      "Epoch 213/400 | Loss 1.5369 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 214/400 | Loss 1.5652 | Win/lose count 15.5/4.0 (11.5)\n",
      "Epoch 215/400 | Loss 1.5992 | Win/lose count 16.0/0 (16.0)\n",
      "Epoch 216/400 | Loss 1.5806 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 217/400 | Loss 1.5994 | Win/lose count 6.0/1.0 (5.0)\n",
      "Epoch 218/400 | Loss 1.5545 | Win/lose count 21.0/4.0 (17.0)\n",
      "Epoch 219/400 | Loss 1.5797 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 220/400 | Loss 1.5848 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 221/400 | Loss 1.5976 | Win/lose count 16.5/2.0 (14.5)\n",
      "Epoch 222/400 | Loss 1.5594 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 223/400 | Loss 1.6619 | Win/lose count 11.5/5.0 (6.5)\n",
      "Epoch 224/400 | Loss 1.6368 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 225/400 | Loss 1.5874 | Win/lose count 17.0/4.0 (13.0)\n",
      "Epoch 226/400 | Loss 1.6565 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 227/400 | Loss 1.6314 | Win/lose count 7.5/1.0 (6.5)\n",
      "Epoch 228/400 | Loss 1.6472 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 229/400 | Loss 1.6577 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 230/400 | Loss 1.6186 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 231/400 | Loss 1.7196 | Win/lose count 12.0/5.0 (7.0)\n",
      "Epoch 232/400 | Loss 1.6913 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 233/400 | Loss 1.6324 | Win/lose count 18.0/4.0 (14.0)\n",
      "Epoch 234/400 | Loss 1.6259 | Win/lose count 12.0/1.0 (11.0)\n",
      "Epoch 235/400 | Loss 1.6849 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 236/400 | Loss 1.6337 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 237/400 | Loss 1.6350 | Win/lose count 19.5/2.0 (17.5)\n",
      "Epoch 238/400 | Loss 1.6572 | Win/lose count 14.0/0 (14.0)\n",
      "Epoch 239/400 | Loss 1.6232 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 240/400 | Loss 1.6578 | Win/lose count 15.5/0 (15.5)\n",
      "Epoch 241/400 | Loss 1.6617 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 242/400 | Loss 1.7172 | Win/lose count 13.5/4.0 (9.5)\n",
      "Epoch 243/400 | Loss 1.7161 | Win/lose count 11.5/0 (11.5)\n",
      "Epoch 244/400 | Loss 1.6631 | Win/lose count 9.0/0 (9.0)\n",
      "Epoch 245/400 | Loss 1.6774 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 246/400 | Loss 1.7129 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 247/400 | Loss 1.7164 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 248/400 | Loss 1.6710 | Win/lose count 14.0/6.0 (8.0)\n",
      "Epoch 249/400 | Loss 1.6773 | Win/lose count 17.5/0 (17.5)\n",
      "Epoch 250/400 | Loss 1.6886 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 251/400 | Loss 1.6860 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 252/400 | Loss 1.6763 | Win/lose count 11.5/0 (11.5)\n",
      "Epoch 253/400 | Loss 1.6681 | Win/lose count 11.5/1.0 (10.5)\n",
      "Epoch 254/400 | Loss 1.6542 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 255/400 | Loss 1.6525 | Win/lose count 15.0/1.0 (14.0)\n",
      "Epoch 256/400 | Loss 1.6480 | Win/lose count 11.0/5.0 (6.0)\n",
      "Epoch 257/400 | Loss 1.6192 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 258/400 | Loss 1.5962 | Win/lose count 16.5/0 (16.5)\n",
      "Epoch 259/400 | Loss 1.6157 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 260/400 | Loss 1.6611 | Win/lose count 6.0/0 (6.0)\n",
      "Epoch 261/400 | Loss 1.6270 | Win/lose count 10.0/8.0 (2.0)\n",
      "Epoch 262/400 | Loss 1.5854 | Win/lose count 16.5/1.0 (15.5)\n",
      "Epoch 263/400 | Loss 1.6514 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 264/400 | Loss 1.5916 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 265/400 | Loss 1.6690 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 266/400 | Loss 1.6458 | Win/lose count 17.5/1.0 (16.5)\n",
      "Epoch 267/400 | Loss 1.6685 | Win/lose count 11.5/5.0 (6.5)\n",
      "Epoch 268/400 | Loss 1.6519 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 269/400 | Loss 1.6569 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 270/400 | Loss 1.6697 | Win/lose count 15.5/6.0 (9.5)\n",
      "Epoch 271/400 | Loss 1.6209 | Win/lose count 12.5/3.0 (9.5)\n",
      "Epoch 272/400 | Loss 1.6489 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 273/400 | Loss 1.7443 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 274/400 | Loss 1.7462 | Win/lose count 19.5/3.0 (16.5)\n",
      "Epoch 275/400 | Loss 1.7230 | Win/lose count 7.5/4.0 (3.5)\n",
      "Epoch 276/400 | Loss 1.7277 | Win/lose count 20.0/0 (20.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/400 | Loss 1.7420 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 278/400 | Loss 1.7283 | Win/lose count 12.0/4.0 (8.0)\n",
      "Epoch 279/400 | Loss 1.7139 | Win/lose count 9.5/3.0 (6.5)\n",
      "Epoch 280/400 | Loss 1.6512 | Win/lose count 11.5/4.0 (7.5)\n",
      "Epoch 281/400 | Loss 1.6484 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 282/400 | Loss 1.6580 | Win/lose count 17.5/2.0 (15.5)\n",
      "Epoch 283/400 | Loss 1.6880 | Win/lose count 19.0/5.0 (14.0)\n",
      "Epoch 284/400 | Loss 1.6810 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 285/400 | Loss 1.6405 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 286/400 | Loss 1.6271 | Win/lose count 17.5/4.0 (13.5)\n",
      "Epoch 287/400 | Loss 1.6593 | Win/lose count 18.0/4.0 (14.0)\n",
      "Epoch 288/400 | Loss 1.6411 | Win/lose count 15.5/2.0 (13.5)\n",
      "Epoch 289/400 | Loss 1.6922 | Win/lose count 17.5/1.0 (16.5)\n",
      "Epoch 290/400 | Loss 1.6650 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 291/400 | Loss 1.6480 | Win/lose count 19.5/2.0 (17.5)\n",
      "Epoch 292/400 | Loss 1.7128 | Win/lose count 17.0/1.0 (16.0)\n",
      "Epoch 293/400 | Loss 1.7049 | Win/lose count 18.5/1.0 (17.5)\n",
      "Epoch 294/400 | Loss 1.7289 | Win/lose count 21.0/5.0 (16.0)\n",
      "Epoch 295/400 | Loss 1.6796 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 296/400 | Loss 1.7018 | Win/lose count 3.5/0 (3.5)\n",
      "Epoch 297/400 | Loss 1.7175 | Win/lose count 12.5/1.0 (11.5)\n",
      "Epoch 298/400 | Loss 1.6879 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 299/400 | Loss 1.6923 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 300/400 | Loss 1.6452 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 301/400 | Loss 1.6389 | Win/lose count 12.5/3.0 (9.5)\n",
      "Epoch 302/400 | Loss 1.5999 | Win/lose count 15.5/1.0 (14.5)\n",
      "Epoch 303/400 | Loss 1.6636 | Win/lose count 20.0/3.0 (17.0)\n",
      "Epoch 304/400 | Loss 1.6788 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 305/400 | Loss 1.6084 | Win/lose count 17.5/1.0 (16.5)\n",
      "Epoch 306/400 | Loss 1.6690 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 307/400 | Loss 1.6094 | Win/lose count 25.0/1.0 (24.0)\n",
      "Epoch 308/400 | Loss 1.6448 | Win/lose count 16.0/2.0 (14.0)\n",
      "Epoch 309/400 | Loss 1.6375 | Win/lose count 17.0/3.0 (14.0)\n",
      "Epoch 310/400 | Loss 1.6650 | Win/lose count 18.5/1.0 (17.5)\n",
      "Epoch 311/400 | Loss 1.6909 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 312/400 | Loss 1.7028 | Win/lose count 21.0/5.0 (16.0)\n",
      "Epoch 313/400 | Loss 1.7543 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 314/400 | Loss 1.7207 | Win/lose count 8.0/2.0 (6.0)\n",
      "Epoch 315/400 | Loss 1.6806 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 316/400 | Loss 1.7016 | Win/lose count 13.0/5.0 (8.0)\n",
      "Epoch 317/400 | Loss 1.7128 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 318/400 | Loss 1.7122 | Win/lose count 20.5/2.0 (18.5)\n",
      "Epoch 319/400 | Loss 1.6698 | Win/lose count 10.0/1.0 (9.0)\n",
      "Epoch 320/400 | Loss 1.6995 | Win/lose count 6.5/2.0 (4.5)\n",
      "Epoch 321/400 | Loss 1.7056 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 322/400 | Loss 1.6687 | Win/lose count 9.5/3.0 (6.5)\n",
      "Epoch 323/400 | Loss 1.6925 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 324/400 | Loss 1.6703 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 325/400 | Loss 1.6510 | Win/lose count 12.0/1.0 (11.0)\n",
      "Epoch 326/400 | Loss 1.6681 | Win/lose count 18.5/4.0 (14.5)\n",
      "Epoch 327/400 | Loss 1.6537 | Win/lose count 16.5/3.0 (13.5)\n",
      "Epoch 328/400 | Loss 1.6294 | Win/lose count 9.0/5.0 (4.0)\n",
      "Epoch 329/400 | Loss 1.6321 | Win/lose count 11.0/0 (11.0)\n",
      "Epoch 330/400 | Loss 1.6185 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 331/400 | Loss 1.6487 | Win/lose count 8.0/4.0 (4.0)\n",
      "Epoch 332/400 | Loss 1.6026 | Win/lose count 16.5/1.0 (15.5)\n",
      "Epoch 333/400 | Loss 1.6881 | Win/lose count 28.0/1.0 (27.0)\n",
      "Epoch 334/400 | Loss 1.6383 | Win/lose count 16.0/1.0 (15.0)\n",
      "Epoch 335/400 | Loss 1.6921 | Win/lose count 15.0/1.0 (14.0)\n",
      "Epoch 336/400 | Loss 1.6848 | Win/lose count 24.0/2.0 (22.0)\n",
      "Epoch 337/400 | Loss 1.6843 | Win/lose count 15.5/1.0 (14.5)\n",
      "Epoch 338/400 | Loss 1.6733 | Win/lose count 10.0/1.0 (9.0)\n",
      "Epoch 339/400 | Loss 1.7225 | Win/lose count 16.5/3.0 (13.5)\n",
      "Epoch 340/400 | Loss 1.6710 | Win/lose count 16.0/2.0 (14.0)\n",
      "Epoch 341/400 | Loss 1.7330 | Win/lose count 16.5/4.0 (12.5)\n",
      "Epoch 342/400 | Loss 1.6863 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 343/400 | Loss 1.7354 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 344/400 | Loss 1.6701 | Win/lose count 7.5/4.0 (3.5)\n",
      "Epoch 345/400 | Loss 1.6788 | Win/lose count 16.5/2.0 (14.5)\n",
      "Epoch 346/400 | Loss 1.7039 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 347/400 | Loss 1.6955 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 348/400 | Loss 1.6763 | Win/lose count 14.5/9.0 (5.5)\n",
      "Epoch 349/400 | Loss 1.6639 | Win/lose count 27.0/2.0 (25.0)\n",
      "Epoch 350/400 | Loss 1.6819 | Win/lose count 13.5/4.0 (9.5)\n",
      "Epoch 351/400 | Loss 1.7066 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 352/400 | Loss 1.7489 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 353/400 | Loss 1.6501 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 354/400 | Loss 1.6572 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 355/400 | Loss 1.6737 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 356/400 | Loss 1.6293 | Win/lose count 15.5/3.0 (12.5)\n",
      "Epoch 357/400 | Loss 1.6900 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 358/400 | Loss 1.6492 | Win/lose count 16.0/3.0 (13.0)\n",
      "Epoch 359/400 | Loss 1.6531 | Win/lose count 19.0/1.0 (18.0)\n",
      "Epoch 360/400 | Loss 1.6355 | Win/lose count 12.0/0 (12.0)\n",
      "Epoch 361/400 | Loss 1.6399 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 362/400 | Loss 1.5997 | Win/lose count 17.5/6.0 (11.5)\n",
      "Epoch 363/400 | Loss 1.6656 | Win/lose count 12.5/1.0 (11.5)\n",
      "Epoch 364/400 | Loss 1.6388 | Win/lose count 14.0/1.0 (13.0)\n",
      "Epoch 365/400 | Loss 1.6639 | Win/lose count 20.5/4.0 (16.5)\n",
      "Epoch 366/400 | Loss 1.6742 | Win/lose count 13.5/2.0 (11.5)\n",
      "Epoch 367/400 | Loss 1.6405 | Win/lose count 18.0/3.0 (15.0)\n",
      "Epoch 368/400 | Loss 1.6973 | Win/lose count 12.0/4.0 (8.0)\n",
      "Epoch 369/400 | Loss 1.6987 | Win/lose count 10.0/0 (10.0)\n",
      "Epoch 370/400 | Loss 1.6584 | Win/lose count 13.5/1.0 (12.5)\n",
      "Epoch 371/400 | Loss 1.7019 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 372/400 | Loss 1.7322 | Win/lose count 17.0/2.0 (15.0)\n",
      "Epoch 373/400 | Loss 1.6871 | Win/lose count 16.5/1.0 (15.5)\n",
      "Epoch 374/400 | Loss 1.6559 | Win/lose count 23.0/3.0 (20.0)\n",
      "Epoch 375/400 | Loss 1.7162 | Win/lose count 7.5/3.0 (4.5)\n",
      "Epoch 376/400 | Loss 1.7146 | Win/lose count 9.5/3.0 (6.5)\n",
      "Epoch 377/400 | Loss 1.7208 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 378/400 | Loss 1.7405 | Win/lose count 12.0/2.0 (10.0)\n",
      "Epoch 379/400 | Loss 1.6952 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 380/400 | Loss 1.6605 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 381/400 | Loss 1.6968 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 382/400 | Loss 1.6384 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 383/400 | Loss 1.6323 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 384/400 | Loss 1.6444 | Win/lose count 19.5/5.0 (14.5)\n",
      "Epoch 385/400 | Loss 1.6080 | Win/lose count 12.5/0 (12.5)\n",
      "Epoch 386/400 | Loss 1.6455 | Win/lose count 19.5/2.0 (17.5)\n",
      "Epoch 387/400 | Loss 1.6461 | Win/lose count 11.0/0 (11.0)\n",
      "Epoch 388/400 | Loss 1.6706 | Win/lose count 15.5/3.0 (12.5)\n",
      "Epoch 389/400 | Loss 1.6705 | Win/lose count 11.0/3.0 (8.0)\n",
      "Epoch 390/400 | Loss 1.6684 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 391/400 | Loss 1.6369 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 392/400 | Loss 1.6615 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 393/400 | Loss 1.6926 | Win/lose count 18.5/3.0 (15.5)\n",
      "Epoch 394/400 | Loss 1.7129 | Win/lose count 11.0/3.0 (8.0)\n",
      "Epoch 395/400 | Loss 1.7426 | Win/lose count 19.5/0 (19.5)\n",
      "Epoch 396/400 | Loss 1.6921 | Win/lose count 11.5/1.0 (10.5)\n",
      "Epoch 397/400 | Loss 1.6793 | Win/lose count 4.5/3.0 (1.5)\n",
      "Epoch 398/400 | Loss 1.6943 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 399/400 | Loss 1.7003 | Win/lose count 12.0/5.0 (7.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=temperature)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2500, batch_size=32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=2, activation=\"relu\", input_shape=(5, 5, self.n_state)))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Conv2D(32, kernel_size=1, activation=\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4, activation=\"linear\"))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/400 | Loss 0.0789 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 001/400 | Loss 0.3162 | Win/lose count 0.5/2.0 (-1.5)\n",
      "Epoch 002/400 | Loss 0.6867 | Win/lose count 3.0/8.0 (-5.0)\n",
      "Epoch 003/400 | Loss 1.3232 | Win/lose count 3.0/7.0 (-4.0)\n",
      "Epoch 004/400 | Loss 1.2989 | Win/lose count 2.5/5.0 (-2.5)\n",
      "Epoch 005/400 | Loss 0.8004 | Win/lose count 2.5/6.0 (-3.5)\n",
      "Epoch 006/400 | Loss 0.5212 | Win/lose count 4.0/6.0 (-2.0)\n",
      "Epoch 007/400 | Loss 0.4051 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 008/400 | Loss 0.4653 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 009/400 | Loss 0.7480 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 010/400 | Loss 0.6711 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 011/400 | Loss 0.7068 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 012/400 | Loss 0.6593 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 013/400 | Loss 0.5095 | Win/lose count 3.5/9.0 (-5.5)\n",
      "Epoch 014/400 | Loss 0.5649 | Win/lose count 3.5/0 (3.5)\n",
      "Epoch 015/400 | Loss 0.5634 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 016/400 | Loss 0.7591 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 017/400 | Loss 0.6880 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 018/400 | Loss 0.6705 | Win/lose count 2.5/5.0 (-2.5)\n",
      "Epoch 019/400 | Loss 0.6993 | Win/lose count 6.0/0 (6.0)\n",
      "Epoch 020/400 | Loss 1.0104 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 021/400 | Loss 1.1337 | Win/lose count 6.0/6.0 (0.0)\n",
      "Epoch 022/400 | Loss 1.0506 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 023/400 | Loss 1.0996 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 024/400 | Loss 1.4218 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 025/400 | Loss 1.6012 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 026/400 | Loss 1.4034 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 027/400 | Loss 1.2534 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 028/400 | Loss 1.1622 | Win/lose count 7.0/4.0 (3.0)\n",
      "Epoch 029/400 | Loss 1.0636 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 030/400 | Loss 1.2226 | Win/lose count 5.0/6.0 (-1.0)\n",
      "Epoch 031/400 | Loss 1.4981 | Win/lose count 6.0/0 (6.0)\n",
      "Epoch 032/400 | Loss 1.5180 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 033/400 | Loss 1.6239 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 034/400 | Loss 1.6227 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 035/400 | Loss 1.8083 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 036/400 | Loss 1.6522 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 037/400 | Loss 1.5475 | Win/lose count 4.5/3.0 (1.5)\n",
      "Epoch 038/400 | Loss 1.5736 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 039/400 | Loss 1.6621 | Win/lose count 5.0/4.0 (1.0)\n",
      "Epoch 040/400 | Loss 1.6914 | Win/lose count 10.5/11.0 (-0.5)\n",
      "Epoch 041/400 | Loss 1.6820 | Win/lose count 7.5/0 (7.5)\n",
      "Epoch 042/400 | Loss 1.5569 | Win/lose count 8.5/8.0 (0.5)\n",
      "Epoch 043/400 | Loss 1.6975 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 044/400 | Loss 1.5931 | Win/lose count 7.0/3.0 (4.0)\n",
      "Epoch 045/400 | Loss 1.6317 | Win/lose count 4.5/3.0 (1.5)\n",
      "Epoch 046/400 | Loss 1.4436 | Win/lose count 7.0/3.0 (4.0)\n",
      "Epoch 047/400 | Loss 1.2292 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 048/400 | Loss 1.3390 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 049/400 | Loss 1.4587 | Win/lose count 9.0/6.0 (3.0)\n",
      "Epoch 050/400 | Loss 1.3482 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 051/400 | Loss 1.3867 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 052/400 | Loss 1.4583 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 053/400 | Loss 1.6646 | Win/lose count 7.5/3.0 (4.5)\n",
      "Epoch 054/400 | Loss 1.4832 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 055/400 | Loss 1.4595 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 056/400 | Loss 1.4754 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 057/400 | Loss 1.5086 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 058/400 | Loss 1.5454 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 059/400 | Loss 1.6976 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 060/400 | Loss 1.6470 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 061/400 | Loss 1.7185 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 062/400 | Loss 1.5411 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 063/400 | Loss 1.5743 | Win/lose count 8.0/2.0 (6.0)\n",
      "Epoch 064/400 | Loss 1.5696 | Win/lose count 7.0/1.0 (6.0)\n",
      "Epoch 065/400 | Loss 1.5591 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 066/400 | Loss 1.6223 | Win/lose count 20.5/2.0 (18.5)\n",
      "Epoch 067/400 | Loss 1.5729 | Win/lose count 12.5/1.0 (11.5)\n",
      "Epoch 068/400 | Loss 1.5924 | Win/lose count 20.5/3.0 (17.5)\n",
      "Epoch 069/400 | Loss 1.5748 | Win/lose count 15.5/0 (15.5)\n",
      "Epoch 070/400 | Loss 1.5271 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 071/400 | Loss 1.6532 | Win/lose count 14.0/1.0 (13.0)\n",
      "Epoch 072/400 | Loss 1.6210 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 073/400 | Loss 1.6000 | Win/lose count 12.5/5.0 (7.5)\n",
      "Epoch 074/400 | Loss 1.4619 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 075/400 | Loss 1.6356 | Win/lose count 10.0/4.0 (6.0)\n",
      "Epoch 076/400 | Loss 1.5805 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 077/400 | Loss 1.6141 | Win/lose count 16.0/3.0 (13.0)\n",
      "Epoch 078/400 | Loss 1.5835 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 079/400 | Loss 1.5908 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 080/400 | Loss 1.4971 | Win/lose count 17.5/1.0 (16.5)\n",
      "Epoch 081/400 | Loss 1.5555 | Win/lose count 16.5/2.0 (14.5)\n",
      "Epoch 082/400 | Loss 1.6002 | Win/lose count 17.5/3.0 (14.5)\n",
      "Epoch 083/400 | Loss 1.5168 | Win/lose count 19.0/3.0 (16.0)\n",
      "Epoch 084/400 | Loss 1.6376 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 085/400 | Loss 1.5068 | Win/lose count 19.5/8.0 (11.5)\n",
      "Epoch 086/400 | Loss 1.5233 | Win/lose count 19.5/6.0 (13.5)\n",
      "Epoch 087/400 | Loss 1.4966 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 088/400 | Loss 1.5651 | Win/lose count 16.0/1.0 (15.0)\n",
      "Epoch 089/400 | Loss 1.6265 | Win/lose count 16.5/2.0 (14.5)\n",
      "Epoch 090/400 | Loss 1.6224 | Win/lose count 21.0/3.0 (18.0)\n",
      "Epoch 091/400 | Loss 1.5697 | Win/lose count 18.5/3.0 (15.5)\n",
      "Epoch 092/400 | Loss 1.6174 | Win/lose count 9.0/0 (9.0)\n",
      "Epoch 093/400 | Loss 1.6221 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 094/400 | Loss 1.5963 | Win/lose count 21.0/3.0 (18.0)\n",
      "Epoch 095/400 | Loss 1.6712 | Win/lose count 19.0/3.0 (16.0)\n",
      "Epoch 096/400 | Loss 1.5604 | Win/lose count 12.0/6.0 (6.0)\n",
      "Epoch 097/400 | Loss 1.6196 | Win/lose count 16.0/2.0 (14.0)\n",
      "Epoch 098/400 | Loss 1.5977 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 099/400 | Loss 1.5885 | Win/lose count 15.5/2.0 (13.5)\n",
      "Epoch 100/400 | Loss 1.5609 | Win/lose count 21.5/1.0 (20.5)\n",
      "Epoch 101/400 | Loss 1.6401 | Win/lose count 17.5/4.0 (13.5)\n",
      "Epoch 102/400 | Loss 1.6282 | Win/lose count 17.0/5.0 (12.0)\n",
      "Epoch 103/400 | Loss 1.4892 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 104/400 | Loss 1.6784 | Win/lose count 15.5/4.0 (11.5)\n",
      "Epoch 105/400 | Loss 1.5678 | Win/lose count 16.0/6.0 (10.0)\n",
      "Epoch 106/400 | Loss 1.5911 | Win/lose count 12.5/4.0 (8.5)\n",
      "Epoch 107/400 | Loss 1.5819 | Win/lose count 17.5/2.0 (15.5)\n",
      "Epoch 108/400 | Loss 1.6137 | Win/lose count 22.0/5.0 (17.0)\n",
      "Epoch 109/400 | Loss 1.5405 | Win/lose count 17.0/5.0 (12.0)\n",
      "Epoch 110/400 | Loss 1.5553 | Win/lose count 18.5/7.0 (11.5)\n",
      "Epoch 111/400 | Loss 1.4988 | Win/lose count 18.0/3.0 (15.0)\n",
      "Epoch 112/400 | Loss 1.4920 | Win/lose count 21.0/8.0 (13.0)\n",
      "Epoch 113/400 | Loss 1.5391 | Win/lose count 17.5/7.0 (10.5)\n",
      "Epoch 114/400 | Loss 1.5217 | Win/lose count 16.5/5.0 (11.5)\n",
      "Epoch 115/400 | Loss 1.4951 | Win/lose count 11.0/3.0 (8.0)\n",
      "Epoch 116/400 | Loss 1.4861 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 117/400 | Loss 1.5620 | Win/lose count 24.5/6.0 (18.5)\n",
      "Epoch 118/400 | Loss 1.5030 | Win/lose count 24.0/2.0 (22.0)\n",
      "Epoch 119/400 | Loss 1.4880 | Win/lose count 16.0/0 (16.0)\n",
      "Epoch 120/400 | Loss 1.5969 | Win/lose count 19.5/1.0 (18.5)\n",
      "Epoch 121/400 | Loss 1.5498 | Win/lose count 11.5/6.0 (5.5)\n",
      "Epoch 122/400 | Loss 1.4571 | Win/lose count 10.5/0 (10.5)\n",
      "Epoch 123/400 | Loss 1.5594 | Win/lose count 5.5/4.0 (1.5)\n",
      "Epoch 124/400 | Loss 1.5487 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 125/400 | Loss 1.5495 | Win/lose count 19.0/3.0 (16.0)\n",
      "Epoch 126/400 | Loss 1.6004 | Win/lose count 12.0/2.0 (10.0)\n",
      "Epoch 127/400 | Loss 1.4882 | Win/lose count 17.0/0 (17.0)\n",
      "Epoch 128/400 | Loss 1.6277 | Win/lose count 16.0/1.0 (15.0)\n",
      "Epoch 129/400 | Loss 1.5550 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 130/400 | Loss 1.5702 | Win/lose count 20.5/7.0 (13.5)\n",
      "Epoch 131/400 | Loss 1.5181 | Win/lose count 18.5/5.0 (13.5)\n",
      "Epoch 132/400 | Loss 1.6251 | Win/lose count 25.0/6.0 (19.0)\n",
      "Epoch 133/400 | Loss 1.6304 | Win/lose count 10.0/4.0 (6.0)\n",
      "Epoch 134/400 | Loss 1.5370 | Win/lose count 22.5/8.0 (14.5)\n",
      "Epoch 135/400 | Loss 1.7610 | Win/lose count 15.0/1.0 (14.0)\n",
      "Epoch 136/400 | Loss 1.5866 | Win/lose count 16.0/5.0 (11.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/400 | Loss 1.5192 | Win/lose count 22.0/4.0 (18.0)\n",
      "Epoch 138/400 | Loss 1.5775 | Win/lose count 26.0/2.0 (24.0)\n",
      "Epoch 139/400 | Loss 1.5650 | Win/lose count 20.5/4.0 (16.5)\n",
      "Epoch 140/400 | Loss 1.5705 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 141/400 | Loss 1.5590 | Win/lose count 23.0/6.0 (17.0)\n",
      "Epoch 142/400 | Loss 1.4829 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 143/400 | Loss 1.5643 | Win/lose count 17.5/9.0 (8.5)\n",
      "Epoch 144/400 | Loss 1.5961 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 145/400 | Loss 1.5981 | Win/lose count 20.5/2.0 (18.5)\n",
      "Epoch 146/400 | Loss 1.5928 | Win/lose count 22.5/4.0 (18.5)\n",
      "Epoch 147/400 | Loss 1.6070 | Win/lose count 16.0/7.0 (9.0)\n",
      "Epoch 148/400 | Loss 1.6461 | Win/lose count 21.5/1.0 (20.5)\n",
      "Epoch 149/400 | Loss 1.5620 | Win/lose count 21.0/5.0 (16.0)\n",
      "Epoch 150/400 | Loss 1.5730 | Win/lose count 12.0/5.0 (7.0)\n",
      "Epoch 151/400 | Loss 1.5027 | Win/lose count 8.5/0 (8.5)\n",
      "Epoch 152/400 | Loss 1.5388 | Win/lose count 17.0/4.0 (13.0)\n",
      "Epoch 153/400 | Loss 1.6030 | Win/lose count 13.5/5.0 (8.5)\n",
      "Epoch 154/400 | Loss 1.5297 | Win/lose count 23.5/4.0 (19.5)\n",
      "Epoch 155/400 | Loss 1.5018 | Win/lose count 21.5/6.0 (15.5)\n",
      "Epoch 156/400 | Loss 1.5808 | Win/lose count 23.0/2.0 (21.0)\n",
      "Epoch 157/400 | Loss 1.6189 | Win/lose count 15.0/7.0 (8.0)\n",
      "Epoch 158/400 | Loss 1.5563 | Win/lose count 22.0/4.0 (18.0)\n",
      "Epoch 159/400 | Loss 1.6293 | Win/lose count 22.5/2.0 (20.5)\n",
      "Epoch 160/400 | Loss 1.5797 | Win/lose count 16.5/4.0 (12.5)\n",
      "Epoch 161/400 | Loss 1.4791 | Win/lose count 21.0/6.0 (15.0)\n",
      "Epoch 162/400 | Loss 1.5760 | Win/lose count 24.5/3.0 (21.5)\n",
      "Epoch 163/400 | Loss 1.6536 | Win/lose count 21.0/5.0 (16.0)\n",
      "Epoch 164/400 | Loss 1.5728 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 165/400 | Loss 1.5733 | Win/lose count 11.5/5.0 (6.5)\n",
      "Epoch 166/400 | Loss 1.5834 | Win/lose count 8.5/2.0 (6.5)\n",
      "Epoch 167/400 | Loss 1.5190 | Win/lose count 13.5/5.0 (8.5)\n",
      "Epoch 168/400 | Loss 1.5595 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 169/400 | Loss 1.6189 | Win/lose count 21.5/1.0 (20.5)\n",
      "Epoch 170/400 | Loss 1.4705 | Win/lose count 23.5/2.0 (21.5)\n",
      "Epoch 171/400 | Loss 1.6091 | Win/lose count 25.5/5.0 (20.5)\n",
      "Epoch 172/400 | Loss 1.6505 | Win/lose count 17.0/4.0 (13.0)\n",
      "Epoch 173/400 | Loss 1.6500 | Win/lose count 22.5/6.0 (16.5)\n",
      "Epoch 174/400 | Loss 1.4578 | Win/lose count 21.5/6.0 (15.5)\n",
      "Epoch 175/400 | Loss 1.5296 | Win/lose count 19.0/5.0 (14.0)\n",
      "Epoch 176/400 | Loss 1.5705 | Win/lose count 17.0/6.0 (11.0)\n",
      "Epoch 177/400 | Loss 1.5302 | Win/lose count 17.5/0 (17.5)\n",
      "Epoch 178/400 | Loss 1.6076 | Win/lose count 21.0/6.0 (15.0)\n",
      "Epoch 179/400 | Loss 1.5964 | Win/lose count 19.0/5.0 (14.0)\n",
      "Epoch 180/400 | Loss 1.6276 | Win/lose count 14.0/3.0 (11.0)\n",
      "Epoch 181/400 | Loss 1.5340 | Win/lose count 13.5/6.0 (7.5)\n",
      "Epoch 182/400 | Loss 1.5782 | Win/lose count 20.0/6.0 (14.0)\n",
      "Epoch 183/400 | Loss 1.5537 | Win/lose count 20.0/4.0 (16.0)\n",
      "Epoch 184/400 | Loss 1.5430 | Win/lose count 28.0/5.0 (23.0)\n",
      "Epoch 185/400 | Loss 1.5276 | Win/lose count 22.0/5.0 (17.0)\n",
      "Epoch 186/400 | Loss 1.5873 | Win/lose count 24.0/8.0 (16.0)\n",
      "Epoch 187/400 | Loss 1.6165 | Win/lose count 19.5/3.0 (16.5)\n",
      "Epoch 188/400 | Loss 1.5136 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 189/400 | Loss 1.6385 | Win/lose count 18.5/2.0 (16.5)\n",
      "Epoch 190/400 | Loss 1.5747 | Win/lose count 9.5/4.0 (5.5)\n",
      "Epoch 191/400 | Loss 1.5121 | Win/lose count 12.0/2.0 (10.0)\n",
      "Epoch 192/400 | Loss 1.5771 | Win/lose count 19.0/3.0 (16.0)\n",
      "Epoch 193/400 | Loss 1.5059 | Win/lose count 18.0/2.0 (16.0)\n",
      "Epoch 194/400 | Loss 1.5441 | Win/lose count 14.0/5.0 (9.0)\n",
      "Epoch 195/400 | Loss 1.6037 | Win/lose count 16.5/0 (16.5)\n",
      "Epoch 196/400 | Loss 1.6630 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 197/400 | Loss 1.4932 | Win/lose count 17.0/4.0 (13.0)\n",
      "Epoch 198/400 | Loss 1.5299 | Win/lose count 9.5/5.0 (4.5)\n",
      "Epoch 199/400 | Loss 1.5006 | Win/lose count 16.5/5.0 (11.5)\n",
      "Epoch 200/400 | Loss 1.5481 | Win/lose count 20.0/4.0 (16.0)\n",
      "Epoch 201/400 | Loss 1.6112 | Win/lose count 18.5/2.0 (16.5)\n",
      "Epoch 202/400 | Loss 1.5385 | Win/lose count 21.5/4.0 (17.5)\n",
      "Epoch 203/400 | Loss 1.5309 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 204/400 | Loss 1.5209 | Win/lose count 17.5/4.0 (13.5)\n",
      "Epoch 205/400 | Loss 1.4616 | Win/lose count 18.0/6.0 (12.0)\n",
      "Epoch 206/400 | Loss 1.4915 | Win/lose count 18.5/7.0 (11.5)\n",
      "Epoch 207/400 | Loss 1.3847 | Win/lose count 19.5/5.0 (14.5)\n",
      "Epoch 208/400 | Loss 1.4685 | Win/lose count 18.5/4.0 (14.5)\n",
      "Epoch 209/400 | Loss 1.4919 | Win/lose count 12.0/4.0 (8.0)\n",
      "Epoch 210/400 | Loss 1.4601 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 211/400 | Loss 1.4655 | Win/lose count 9.0/2.0 (7.0)\n",
      "Epoch 212/400 | Loss 1.3769 | Win/lose count 22.0/4.0 (18.0)\n",
      "Epoch 213/400 | Loss 1.4407 | Win/lose count 10.0/1.0 (9.0)\n",
      "Epoch 214/400 | Loss 1.3979 | Win/lose count 12.5/1.0 (11.5)\n",
      "Epoch 215/400 | Loss 1.3818 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 216/400 | Loss 1.4189 | Win/lose count 14.0/3.0 (11.0)\n",
      "Epoch 217/400 | Loss 1.3784 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 218/400 | Loss 1.4871 | Win/lose count 19.5/8.0 (11.5)\n",
      "Epoch 219/400 | Loss 1.4692 | Win/lose count 20.0/4.0 (16.0)\n",
      "Epoch 220/400 | Loss 1.4419 | Win/lose count 22.0/5.0 (17.0)\n",
      "Epoch 221/400 | Loss 1.4335 | Win/lose count 16.0/6.0 (10.0)\n",
      "Epoch 222/400 | Loss 1.3069 | Win/lose count 24.5/4.0 (20.5)\n",
      "Epoch 223/400 | Loss 1.4578 | Win/lose count 14.5/4.0 (10.5)\n",
      "Epoch 224/400 | Loss 1.4559 | Win/lose count 13.0/5.0 (8.0)\n",
      "Epoch 225/400 | Loss 1.4732 | Win/lose count 20.5/3.0 (17.5)\n",
      "Epoch 226/400 | Loss 1.4477 | Win/lose count 9.0/0 (9.0)\n",
      "Epoch 227/400 | Loss 1.3703 | Win/lose count 19.5/6.0 (13.5)\n",
      "Epoch 228/400 | Loss 1.4110 | Win/lose count 18.5/3.0 (15.5)\n",
      "Epoch 229/400 | Loss 1.5260 | Win/lose count 19.5/4.0 (15.5)\n",
      "Epoch 230/400 | Loss 1.4900 | Win/lose count 15.0/6.0 (9.0)\n",
      "Epoch 231/400 | Loss 1.4996 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 232/400 | Loss 1.4649 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 233/400 | Loss 1.4723 | Win/lose count 23.5/3.0 (20.5)\n",
      "Epoch 234/400 | Loss 1.4447 | Win/lose count 20.0/4.0 (16.0)\n",
      "Epoch 235/400 | Loss 1.4445 | Win/lose count 16.5/5.0 (11.5)\n",
      "Epoch 236/400 | Loss 1.4773 | Win/lose count 22.0/7.0 (15.0)\n",
      "Epoch 237/400 | Loss 1.4622 | Win/lose count 19.0/8.0 (11.0)\n",
      "Epoch 238/400 | Loss 1.4635 | Win/lose count 18.0/6.0 (12.0)\n",
      "Epoch 239/400 | Loss 1.4872 | Win/lose count 12.0/5.0 (7.0)\n",
      "Epoch 240/400 | Loss 1.4935 | Win/lose count 21.0/4.0 (17.0)\n",
      "Epoch 241/400 | Loss 1.3849 | Win/lose count 18.0/4.0 (14.0)\n",
      "Epoch 242/400 | Loss 1.4101 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 243/400 | Loss 1.4953 | Win/lose count 13.0/2.0 (11.0)\n",
      "Epoch 244/400 | Loss 1.3670 | Win/lose count 24.5/4.0 (20.5)\n",
      "Epoch 245/400 | Loss 1.4423 | Win/lose count 21.0/3.0 (18.0)\n",
      "Epoch 246/400 | Loss 1.4702 | Win/lose count 12.0/1.0 (11.0)\n",
      "Epoch 247/400 | Loss 1.3254 | Win/lose count 18.5/4.0 (14.5)\n",
      "Epoch 248/400 | Loss 1.3768 | Win/lose count 13.5/3.0 (10.5)\n",
      "Epoch 249/400 | Loss 1.4609 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 250/400 | Loss 1.4012 | Win/lose count 7.5/1.0 (6.5)\n",
      "Epoch 251/400 | Loss 1.3280 | Win/lose count 15.0/2.0 (13.0)\n",
      "Epoch 252/400 | Loss 1.4744 | Win/lose count 19.0/3.0 (16.0)\n",
      "Epoch 253/400 | Loss 1.3208 | Win/lose count 10.0/3.0 (7.0)\n",
      "Epoch 254/400 | Loss 1.3850 | Win/lose count 23.0/6.0 (17.0)\n",
      "Epoch 255/400 | Loss 1.3708 | Win/lose count 22.0/8.0 (14.0)\n",
      "Epoch 256/400 | Loss 1.3281 | Win/lose count 13.0/6.0 (7.0)\n",
      "Epoch 257/400 | Loss 1.3988 | Win/lose count 24.5/4.0 (20.5)\n",
      "Epoch 258/400 | Loss 1.2811 | Win/lose count 22.0/5.0 (17.0)\n",
      "Epoch 259/400 | Loss 1.3165 | Win/lose count 20.0/3.0 (17.0)\n",
      "Epoch 260/400 | Loss 1.3033 | Win/lose count 7.5/2.0 (5.5)\n",
      "Epoch 261/400 | Loss 1.3187 | Win/lose count 5.0/6.0 (-1.0)\n",
      "Epoch 262/400 | Loss 1.2557 | Win/lose count 12.5/3.0 (9.5)\n",
      "Epoch 263/400 | Loss 1.3894 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 264/400 | Loss 1.3908 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 265/400 | Loss 1.4048 | Win/lose count 20.0/6.0 (14.0)\n",
      "Epoch 266/400 | Loss 1.3232 | Win/lose count 16.5/2.0 (14.5)\n",
      "Epoch 267/400 | Loss 1.4756 | Win/lose count 19.0/4.0 (15.0)\n",
      "Epoch 268/400 | Loss 1.3771 | Win/lose count 8.5/1.0 (7.5)\n",
      "Epoch 269/400 | Loss 1.3184 | Win/lose count 9.5/0 (9.5)\n",
      "Epoch 270/400 | Loss 1.2612 | Win/lose count 11.0/3.0 (8.0)\n",
      "Epoch 271/400 | Loss 1.3594 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 272/400 | Loss 1.2212 | Win/lose count 17.5/7.0 (10.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/400 | Loss 1.3207 | Win/lose count 23.0/1.0 (22.0)\n",
      "Epoch 274/400 | Loss 1.3531 | Win/lose count 17.0/1.0 (16.0)\n",
      "Epoch 275/400 | Loss 1.3088 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 276/400 | Loss 1.4797 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 277/400 | Loss 1.4324 | Win/lose count 15.0/2.0 (13.0)\n",
      "Epoch 278/400 | Loss 1.3768 | Win/lose count 18.5/4.0 (14.5)\n",
      "Epoch 279/400 | Loss 1.3250 | Win/lose count 21.0/7.0 (14.0)\n",
      "Epoch 280/400 | Loss 1.3019 | Win/lose count 22.0/6.0 (16.0)\n",
      "Epoch 281/400 | Loss 1.3491 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 282/400 | Loss 1.4493 | Win/lose count 11.0/4.0 (7.0)\n",
      "Epoch 283/400 | Loss 1.4366 | Win/lose count 26.5/11.0 (15.5)\n",
      "Epoch 284/400 | Loss 1.4485 | Win/lose count 17.0/9.0 (8.0)\n",
      "Epoch 285/400 | Loss 1.3329 | Win/lose count 25.5/3.0 (22.5)\n",
      "Epoch 286/400 | Loss 1.3910 | Win/lose count 20.0/3.0 (17.0)\n",
      "Epoch 287/400 | Loss 1.3881 | Win/lose count 21.5/3.0 (18.5)\n",
      "Epoch 288/400 | Loss 1.4401 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 289/400 | Loss 1.3811 | Win/lose count 21.5/8.0 (13.5)\n",
      "Epoch 290/400 | Loss 1.4617 | Win/lose count 22.0/6.0 (16.0)\n",
      "Epoch 291/400 | Loss 1.4062 | Win/lose count 21.5/3.0 (18.5)\n",
      "Epoch 292/400 | Loss 1.3672 | Win/lose count 20.5/2.0 (18.5)\n",
      "Epoch 293/400 | Loss 1.4371 | Win/lose count 24.0/6.0 (18.0)\n",
      "Epoch 294/400 | Loss 1.5387 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 295/400 | Loss 1.4472 | Win/lose count 16.5/2.0 (14.5)\n",
      "Epoch 296/400 | Loss 1.5341 | Win/lose count 11.5/5.0 (6.5)\n",
      "Epoch 297/400 | Loss 1.4309 | Win/lose count 19.0/6.0 (13.0)\n",
      "Epoch 298/400 | Loss 1.5440 | Win/lose count 11.0/5.0 (6.0)\n",
      "Epoch 299/400 | Loss 1.3294 | Win/lose count 24.0/3.0 (21.0)\n",
      "Epoch 300/400 | Loss 1.5365 | Win/lose count 18.5/2.0 (16.5)\n",
      "Epoch 301/400 | Loss 1.4910 | Win/lose count 19.0/6.0 (13.0)\n",
      "Epoch 302/400 | Loss 1.5492 | Win/lose count 16.5/0 (16.5)\n",
      "Epoch 303/400 | Loss 1.5495 | Win/lose count 13.5/5.0 (8.5)\n",
      "Epoch 304/400 | Loss 1.4031 | Win/lose count 14.5/5.0 (9.5)\n",
      "Epoch 305/400 | Loss 1.4026 | Win/lose count 21.0/4.0 (17.0)\n",
      "Epoch 306/400 | Loss 1.4278 | Win/lose count 21.0/7.0 (14.0)\n",
      "Epoch 307/400 | Loss 1.3919 | Win/lose count 15.5/2.0 (13.5)\n",
      "Epoch 308/400 | Loss 1.4364 | Win/lose count 24.0/5.0 (19.0)\n",
      "Epoch 309/400 | Loss 1.4260 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 310/400 | Loss 1.3845 | Win/lose count 21.5/5.0 (16.5)\n",
      "Epoch 311/400 | Loss 1.4149 | Win/lose count 13.5/5.0 (8.5)\n",
      "Epoch 312/400 | Loss 1.3797 | Win/lose count 17.5/5.0 (12.5)\n",
      "Epoch 313/400 | Loss 1.4077 | Win/lose count 21.5/8.0 (13.5)\n",
      "Epoch 314/400 | Loss 1.3934 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 315/400 | Loss 1.4915 | Win/lose count 15.0/5.0 (10.0)\n",
      "Epoch 316/400 | Loss 1.4829 | Win/lose count 17.5/5.0 (12.5)\n",
      "Epoch 317/400 | Loss 1.5126 | Win/lose count 18.5/4.0 (14.5)\n",
      "Epoch 318/400 | Loss 1.4089 | Win/lose count 25.5/10.0 (15.5)\n",
      "Epoch 319/400 | Loss 1.3848 | Win/lose count 17.5/4.0 (13.5)\n",
      "Epoch 320/400 | Loss 1.4273 | Win/lose count 23.5/1.0 (22.5)\n",
      "Epoch 321/400 | Loss 1.3913 | Win/lose count 21.0/4.0 (17.0)\n",
      "Epoch 322/400 | Loss 1.4160 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 323/400 | Loss 1.2962 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 324/400 | Loss 1.3169 | Win/lose count 13.5/0 (13.5)\n",
      "Epoch 325/400 | Loss 1.3697 | Win/lose count 15.0/2.0 (13.0)\n",
      "Epoch 326/400 | Loss 1.4061 | Win/lose count 25.5/10.0 (15.5)\n",
      "Epoch 327/400 | Loss 1.3788 | Win/lose count 14.0/3.0 (11.0)\n",
      "Epoch 328/400 | Loss 1.4182 | Win/lose count 22.0/7.0 (15.0)\n",
      "Epoch 329/400 | Loss 1.3816 | Win/lose count 13.0/4.0 (9.0)\n",
      "Epoch 330/400 | Loss 1.3515 | Win/lose count 20.5/3.0 (17.5)\n",
      "Epoch 331/400 | Loss 1.3644 | Win/lose count 14.0/3.0 (11.0)\n",
      "Epoch 332/400 | Loss 1.3744 | Win/lose count 18.5/8.0 (10.5)\n",
      "Epoch 333/400 | Loss 1.3150 | Win/lose count 10.0/6.0 (4.0)\n",
      "Epoch 334/400 | Loss 1.3874 | Win/lose count 25.5/6.0 (19.5)\n",
      "Epoch 335/400 | Loss 1.4458 | Win/lose count 21.5/6.0 (15.5)\n",
      "Epoch 336/400 | Loss 1.4140 | Win/lose count 25.5/4.0 (21.5)\n",
      "Epoch 337/400 | Loss 1.5315 | Win/lose count 25.5/6.0 (19.5)\n",
      "Epoch 338/400 | Loss 1.3818 | Win/lose count 18.5/6.0 (12.5)\n",
      "Epoch 339/400 | Loss 1.3888 | Win/lose count 13.0/1.0 (12.0)\n",
      "Epoch 340/400 | Loss 1.3387 | Win/lose count 15.0/4.0 (11.0)\n",
      "Epoch 341/400 | Loss 1.4279 | Win/lose count 20.0/9.0 (11.0)\n",
      "Epoch 342/400 | Loss 1.4047 | Win/lose count 13.5/6.0 (7.5)\n",
      "Epoch 343/400 | Loss 1.3149 | Win/lose count 26.0/6.0 (20.0)\n",
      "Epoch 344/400 | Loss 1.6189 | Win/lose count 22.5/7.0 (15.5)\n",
      "Epoch 345/400 | Loss 1.5064 | Win/lose count 26.5/5.0 (21.5)\n",
      "Epoch 346/400 | Loss 1.4585 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 347/400 | Loss 1.3899 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 348/400 | Loss 1.4075 | Win/lose count 15.5/2.0 (13.5)\n",
      "Epoch 349/400 | Loss 1.4799 | Win/lose count 19.0/3.0 (16.0)\n",
      "Epoch 350/400 | Loss 1.4944 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 351/400 | Loss 1.3670 | Win/lose count 13.5/6.0 (7.5)\n",
      "Epoch 352/400 | Loss 1.3347 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 353/400 | Loss 1.3685 | Win/lose count 13.5/2.0 (11.5)\n",
      "Epoch 354/400 | Loss 1.4365 | Win/lose count 16.0/3.0 (13.0)\n",
      "Epoch 355/400 | Loss 1.4045 | Win/lose count 21.0/8.0 (13.0)\n",
      "Epoch 356/400 | Loss 1.4061 | Win/lose count 24.5/2.0 (22.5)\n",
      "Epoch 357/400 | Loss 1.3582 | Win/lose count 16.0/5.0 (11.0)\n",
      "Epoch 358/400 | Loss 1.3918 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 359/400 | Loss 1.4426 | Win/lose count 23.0/6.0 (17.0)\n",
      "Epoch 360/400 | Loss 1.5277 | Win/lose count 21.5/3.0 (18.5)\n",
      "Epoch 361/400 | Loss 1.4485 | Win/lose count 22.0/4.0 (18.0)\n",
      "Epoch 362/400 | Loss 1.4731 | Win/lose count 13.0/3.0 (10.0)\n",
      "Epoch 363/400 | Loss 1.3748 | Win/lose count 16.5/4.0 (12.5)\n",
      "Epoch 364/400 | Loss 1.3906 | Win/lose count 14.0/3.0 (11.0)\n",
      "Epoch 365/400 | Loss 1.4545 | Win/lose count 17.5/6.0 (11.5)\n",
      "Epoch 366/400 | Loss 1.3578 | Win/lose count 24.5/8.0 (16.5)\n",
      "Epoch 367/400 | Loss 1.4461 | Win/lose count 14.0/2.0 (12.0)\n",
      "Epoch 368/400 | Loss 1.6461 | Win/lose count 29.0/10.0 (19.0)\n",
      "Epoch 369/400 | Loss 1.3543 | Win/lose count 20.5/4.0 (16.5)\n",
      "Epoch 370/400 | Loss 1.3841 | Win/lose count 23.5/2.0 (21.5)\n",
      "Epoch 371/400 | Loss 1.4163 | Win/lose count 17.5/7.0 (10.5)\n",
      "Epoch 372/400 | Loss 1.3945 | Win/lose count 19.5/2.0 (17.5)\n",
      "Epoch 373/400 | Loss 1.3588 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 374/400 | Loss 1.4343 | Win/lose count 20.0/3.0 (17.0)\n",
      "Epoch 375/400 | Loss 1.6012 | Win/lose count 25.5/3.0 (22.5)\n",
      "Epoch 376/400 | Loss 1.4794 | Win/lose count 19.0/6.0 (13.0)\n",
      "Epoch 377/400 | Loss 1.4874 | Win/lose count 23.5/9.0 (14.5)\n",
      "Epoch 378/400 | Loss 1.4817 | Win/lose count 9.0/3.0 (6.0)\n",
      "Epoch 379/400 | Loss 1.4449 | Win/lose count 18.5/5.0 (13.5)\n",
      "Epoch 380/400 | Loss 1.4661 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 381/400 | Loss 1.4773 | Win/lose count 13.0/5.0 (8.0)\n",
      "Epoch 382/400 | Loss 1.4216 | Win/lose count 26.5/7.0 (19.5)\n",
      "Epoch 383/400 | Loss 1.3745 | Win/lose count 18.0/5.0 (13.0)\n",
      "Epoch 384/400 | Loss 1.5385 | Win/lose count 17.5/1.0 (16.5)\n",
      "Epoch 385/400 | Loss 1.4636 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 386/400 | Loss 1.5399 | Win/lose count 22.5/5.0 (17.5)\n",
      "Epoch 387/400 | Loss 1.3872 | Win/lose count 19.0/1.0 (18.0)\n",
      "Epoch 388/400 | Loss 1.4457 | Win/lose count 18.5/2.0 (16.5)\n",
      "Epoch 389/400 | Loss 1.3924 | Win/lose count 8.0/2.0 (6.0)\n",
      "Epoch 390/400 | Loss 1.2897 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 391/400 | Loss 1.4430 | Win/lose count 23.5/4.0 (19.5)\n",
      "Epoch 392/400 | Loss 1.4926 | Win/lose count 21.5/7.0 (14.5)\n",
      "Epoch 393/400 | Loss 1.3260 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 394/400 | Loss 1.4159 | Win/lose count 22.0/6.0 (16.0)\n",
      "Epoch 395/400 | Loss 1.3496 | Win/lose count 14.0/4.0 (10.0)\n",
      "Epoch 396/400 | Loss 1.4898 | Win/lose count 17.5/4.0 (13.5)\n",
      "Epoch 397/400 | Loss 1.4603 | Win/lose count 16.5/5.0 (11.5)\n",
      "Epoch 398/400 | Loss 1.3547 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 399/400 | Loss 1.3698 | Win/lose count 24.5/5.0 (19.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=temperature)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2500, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 12.5/1.0. Average score (11.5)\n",
      "Win/lose count 19.5/1.0. Average score (15.0)\n",
      "Win/lose count 7.5/1.0. Average score (12.166666666666666)\n",
      "Win/lose count 10.5/3.0. Average score (11.0)\n",
      "Win/lose count 19.0/1.0. Average score (12.4)\n",
      "Win/lose count 14.0/2.0. Average score (12.333333333333334)\n",
      "Win/lose count 24.0/3.0. Average score (13.571428571428571)\n",
      "Win/lose count 20.0/2.0. Average score (14.125)\n",
      "Win/lose count 24.5/3.0. Average score (14.944444444444445)\n",
      "Win/lose count 12.5/0. Average score (14.7)\n",
      "Win/lose count 13.0/1.0. Average score (14.454545454545455)\n",
      "Win/lose count 20.0/1.0. Average score (14.833333333333334)\n",
      "Win/lose count 17.5/2.0. Average score (14.884615384615385)\n",
      "Win/lose count 20.5/4.0. Average score (15.0)\n",
      "Win/lose count 2.5/0. Average score (14.166666666666666)\n",
      "Win/lose count 7.0/1.0. Average score (13.65625)\n",
      "Win/lose count 23.0/1.0. Average score (14.147058823529411)\n",
      "Win/lose count 11.5/1.0. Average score (13.944444444444445)\n",
      "Win/lose count 3.5/0. Average score (13.394736842105264)\n",
      "Win/lose count 12.5/1.0. Average score (13.3)\n",
      "Win/lose count 9.5/2.0. Average score (13.023809523809524)\n",
      "Win/lose count 11.5/2.0. Average score (12.863636363636363)\n",
      "Win/lose count 24.5/4.0. Average score (13.195652173913043)\n",
      "Win/lose count 0.5/0. Average score (12.666666666666666)\n",
      "Win/lose count 18.0/2.0. Average score (12.8)\n",
      "Final score: 12.8\n",
      "Test of the FC\n",
      "Win/lose count 2.0/0. Average score (2.0)\n",
      "Win/lose count 14.0/0. Average score (8.0)\n",
      "Win/lose count 11.5/0. Average score (9.166666666666666)\n",
      "Win/lose count 7.5/0. Average score (8.75)\n",
      "Win/lose count 4.5/0. Average score (7.9)\n",
      "Win/lose count 5.0/0. Average score (7.416666666666667)\n",
      "Win/lose count 4.0/0. Average score (6.928571428571429)\n",
      "Win/lose count 3.5/0. Average score (6.5)\n",
      "Win/lose count 10.5/0. Average score (6.944444444444445)\n",
      "Win/lose count 9.0/0. Average score (7.15)\n",
      "Win/lose count 5.0/0. Average score (6.954545454545454)\n",
      "Win/lose count 4.0/0. Average score (6.708333333333333)\n",
      "Win/lose count 5.5/0. Average score (6.615384615384615)\n",
      "Win/lose count 7.5/0. Average score (6.678571428571429)\n",
      "Win/lose count 5.5/0. Average score (6.6)\n",
      "Win/lose count 20.5/1.0. Average score (7.40625)\n",
      "Win/lose count 10.0/0. Average score (7.5588235294117645)\n",
      "Win/lose count 12.0/0. Average score (7.805555555555555)\n",
      "Win/lose count 1.5/0. Average score (7.473684210526316)\n",
      "Win/lose count 5.5/0. Average score (7.375)\n",
      "Win/lose count 4.5/0. Average score (7.238095238095238)\n",
      "Win/lose count 10.0/0. Average score (7.363636363636363)\n",
      "Win/lose count 20.0/0. Average score (7.913043478260869)\n",
      "Win/lose count 1.5/0. Average score (7.645833333333333)\n",
      "Win/lose count 6.0/0. Average score (7.58)\n",
      "Final score: 7.58\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2500, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2500, batch_size = 32)\n",
    "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__ We can observe that, without modifying the temperature settings (0.3), our agent does not explore a lot the environment. It starts by moving a bit around the map, taking mostly bonuses but as soon as it is in a \"safe\" area (without any reward), it starts oscillating between the same cases and does not go and seek the bonuses. Regarding this issue, we can note than the CNN does way better than the fully-connected network: with the CNN training, the agent explore more the environment and get more rewards before oscillating between the same cases whereas with the fully-connected one it starts oscillating quite quickly. We only trained our agent for 400 epochs: a longer training may improve a bit our results. \n",
    "\n",
    "However, the idea behind our algorithm is working: the agent mainly collect bonuses and try avoiding maluses.\n",
    "\n",
    "By increasing the temperature, we increase the proportions of bonuses being on the board (red cases). We can observe that the agent is then exploring more as it does not find a lot of maluses in his sight. The Q-value of an action allowing to move a bit more accross the board is then higher. By increasing the temperature, the agent can move a lot more accross the board (even if the game finishes way before our agent was able to get a majority of the rewards).\n",
    "\n",
    "We can note that training with a big batch causes a kind of overfitting: the training is good, with some exploration but during testing our agent is almost immediatly stuck. Training with a small memory prevents the agent from exploring a lot whereas a bigger memory showed better results (as it really breaks the continuity between the different states)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    new_epsilon = agent.epsilon\n",
    "    number_epochs_to_change_epsilon = 20\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        ### decreasing the epsilon value to exploit more as we train\n",
    "        # we decrease our epsilon value every 20 epochs by a certain amount during around 90% of the training epochs\n",
    "        # then, when epsilon reachs 0.1 after around 90% of the epochs, we let it at 0.1 during the 10% remaining epochs\n",
    "        if e % number_epochs_to_change_epsilon == 0:\n",
    "            if new_epsilon > 0.1:\n",
    "                new_epsilon = 1 - e/(epoch-int(0.1*epoch))\n",
    "            else:\n",
    "                new_epsilon = 0.1\n",
    "            agent.set_epsilon(new_epsilon)\n",
    "            print(\"New epsilon : \", new_epsilon)\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the rat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "    def act(self, action, train=False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        \n",
    "        reward = 0\n",
    "        if train:\n",
    "            # we set a (small) malus if the case has already been visited in order to favored exploration of new cases\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "        \n",
    "        #we update the reward with this new malus\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        \n",
    "        #we have a third array to take into account the already visited cases\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "        \n",
    "        #reinitializing the array malus_position\n",
    "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
    "\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        \n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New epsilon :  1.0\n",
      "Epoch 000/1200 | Loss 0.3206 | Win/lose count 14.0/25.900000000000063 (-11.900000000000063)\n",
      "Epoch 001/1200 | Loss 1.3475 | Win/lose count 9.5/28.700000000000077 (-19.200000000000077)\n",
      "Epoch 002/1200 | Loss 1.0625 | Win/lose count 9.5/33.4000000000001 (-23.900000000000098)\n",
      "Epoch 003/1200 | Loss 1.0943 | Win/lose count 11.0/30.50000000000005 (-19.50000000000005)\n",
      "Epoch 004/1200 | Loss 1.6692 | Win/lose count 8.5/34.400000000000134 (-25.900000000000134)\n",
      "Epoch 005/1200 | Loss 1.6809 | Win/lose count 10.0/22.700000000000003 (-12.700000000000003)\n",
      "Epoch 006/1200 | Loss 1.8752 | Win/lose count 13.5/24.600000000000097 (-11.100000000000097)\n",
      "Epoch 007/1200 | Loss 1.8070 | Win/lose count 10.0/21.900000000000013 (-11.900000000000013)\n",
      "Epoch 008/1200 | Loss 1.8271 | Win/lose count 5.0/35.8000000000001 (-30.800000000000097)\n",
      "Epoch 009/1200 | Loss 1.8065 | Win/lose count 10.5/18.90000000000001 (-8.40000000000001)\n",
      "Epoch 010/1200 | Loss 1.8425 | Win/lose count 11.5/24.80000000000002 (-13.300000000000018)\n",
      "Epoch 011/1200 | Loss 1.7453 | Win/lose count 9.0/26.20000000000006 (-17.20000000000006)\n",
      "Epoch 012/1200 | Loss 1.9052 | Win/lose count 10.0/31.200000000000067 (-21.200000000000067)\n",
      "Epoch 013/1200 | Loss 1.8798 | Win/lose count 12.5/32.80000000000008 (-20.300000000000082)\n",
      "Epoch 014/1200 | Loss 1.7870 | Win/lose count 11.0/27.700000000000063 (-16.700000000000063)\n",
      "Epoch 015/1200 | Loss 1.8340 | Win/lose count 10.0/33.00000000000009 (-23.000000000000092)\n",
      "Epoch 016/1200 | Loss 1.8612 | Win/lose count 11.0/25.90000000000007 (-14.90000000000007)\n",
      "Epoch 017/1200 | Loss 1.9118 | Win/lose count 13.0/29.20000000000013 (-16.20000000000013)\n",
      "Epoch 018/1200 | Loss 1.8176 | Win/lose count 9.0/26.30000000000003 (-17.30000000000003)\n",
      "Epoch 019/1200 | Loss 1.8123 | Win/lose count 7.0/21.800000000000026 (-14.800000000000026)\n",
      "New epsilon :  0.9814814814814815\n",
      "Epoch 020/1200 | Loss 1.8227 | Win/lose count 7.0/25.200000000000077 (-18.200000000000077)\n",
      "Epoch 021/1200 | Loss 1.8165 | Win/lose count 9.0/23.30000000000008 (-14.300000000000079)\n",
      "Epoch 022/1200 | Loss 1.7441 | Win/lose count 8.5/25.800000000000093 (-17.300000000000093)\n",
      "Epoch 023/1200 | Loss 1.8225 | Win/lose count 12.0/24.500000000000036 (-12.500000000000036)\n",
      "Epoch 024/1200 | Loss 1.9689 | Win/lose count 15.0/23.600000000000076 (-8.600000000000076)\n",
      "Epoch 025/1200 | Loss 1.9609 | Win/lose count 10.0/26.200000000000074 (-16.200000000000074)\n",
      "Epoch 026/1200 | Loss 1.8717 | Win/lose count 13.0/29.200000000000085 (-16.200000000000085)\n",
      "Epoch 027/1200 | Loss 1.8382 | Win/lose count 9.0/27.10000000000006 (-18.10000000000006)\n",
      "Epoch 028/1200 | Loss 1.8331 | Win/lose count 7.5/25.600000000000076 (-18.100000000000076)\n",
      "Epoch 029/1200 | Loss 1.7964 | Win/lose count 10.5/32.80000000000007 (-22.300000000000068)\n",
      "Epoch 030/1200 | Loss 1.8494 | Win/lose count 10.0/28.200000000000074 (-18.200000000000074)\n",
      "Epoch 031/1200 | Loss 1.9475 | Win/lose count 10.0/31.200000000000085 (-21.200000000000085)\n",
      "Epoch 032/1200 | Loss 1.8486 | Win/lose count 8.0/25.200000000000077 (-17.200000000000077)\n",
      "Epoch 033/1200 | Loss 1.8468 | Win/lose count 10.5/30.30000000000005 (-19.80000000000005)\n",
      "Epoch 034/1200 | Loss 1.9566 | Win/lose count 14.0/31.600000000000097 (-17.600000000000097)\n",
      "Epoch 035/1200 | Loss 1.9637 | Win/lose count 9.5/23.10000000000001 (-13.600000000000009)\n",
      "Epoch 036/1200 | Loss 1.8160 | Win/lose count 10.0/29.900000000000098 (-19.900000000000098)\n",
      "Epoch 037/1200 | Loss 1.9093 | Win/lose count 9.5/31.400000000000116 (-21.900000000000116)\n",
      "Epoch 038/1200 | Loss 2.0363 | Win/lose count 14.0/25.200000000000067 (-11.200000000000067)\n",
      "Epoch 039/1200 | Loss 1.8888 | Win/lose count 10.5/22.300000000000047 (-11.800000000000047)\n",
      "New epsilon :  0.962962962962963\n",
      "Epoch 040/1200 | Loss 1.9808 | Win/lose count 10.0/26.000000000000064 (-16.000000000000064)\n",
      "Epoch 041/1200 | Loss 2.0479 | Win/lose count 11.0/26.40000000000005 (-15.400000000000048)\n",
      "Epoch 042/1200 | Loss 1.9013 | Win/lose count 14.5/19.00000000000002 (-4.500000000000021)\n",
      "Epoch 043/1200 | Loss 1.8505 | Win/lose count 10.0/31.500000000000142 (-21.500000000000142)\n",
      "Epoch 044/1200 | Loss 1.9071 | Win/lose count 12.0/23.0 (-11.0)\n",
      "Epoch 045/1200 | Loss 2.0226 | Win/lose count 11.0/23.000000000000036 (-12.000000000000036)\n",
      "Epoch 046/1200 | Loss 1.9547 | Win/lose count 8.5/26.00000000000008 (-17.50000000000008)\n",
      "Epoch 047/1200 | Loss 1.9005 | Win/lose count 7.5/29.20000000000008 (-21.70000000000008)\n",
      "Epoch 048/1200 | Loss 1.8830 | Win/lose count 10.0/20.20000000000004 (-10.200000000000038)\n",
      "Epoch 049/1200 | Loss 1.8659 | Win/lose count 11.0/25.600000000000097 (-14.600000000000097)\n",
      "Epoch 050/1200 | Loss 1.8616 | Win/lose count 14.0/26.900000000000095 (-12.900000000000095)\n",
      "Epoch 051/1200 | Loss 1.8411 | Win/lose count 12.0/29.40000000000011 (-17.40000000000011)\n",
      "Epoch 052/1200 | Loss 1.8897 | Win/lose count 14.0/23.900000000000052 (-9.900000000000052)\n",
      "Epoch 053/1200 | Loss 1.8948 | Win/lose count 5.0/22.80000000000004 (-17.80000000000004)\n",
      "Epoch 054/1200 | Loss 1.9369 | Win/lose count 14.0/24.600000000000065 (-10.600000000000065)\n",
      "Epoch 055/1200 | Loss 1.8972 | Win/lose count 11.0/29.700000000000095 (-18.700000000000095)\n",
      "Epoch 056/1200 | Loss 1.9369 | Win/lose count 9.5/26.900000000000066 (-17.400000000000066)\n",
      "Epoch 057/1200 | Loss 1.8520 | Win/lose count 9.5/28.3000000000001 (-18.8000000000001)\n",
      "Epoch 058/1200 | Loss 1.9275 | Win/lose count 9.0/31.5000000000001 (-22.5000000000001)\n",
      "Epoch 059/1200 | Loss 1.8481 | Win/lose count 6.5/33.900000000000084 (-27.400000000000084)\n",
      "New epsilon :  0.9444444444444444\n",
      "Epoch 060/1200 | Loss 1.8548 | Win/lose count 12.5/29.000000000000096 (-16.500000000000096)\n",
      "Epoch 061/1200 | Loss 1.8366 | Win/lose count 5.0/27.20000000000009 (-22.20000000000009)\n",
      "Epoch 062/1200 | Loss 1.8644 | Win/lose count 7.5/26.700000000000102 (-19.200000000000102)\n",
      "Epoch 063/1200 | Loss 2.0165 | Win/lose count 15.5/25.900000000000063 (-10.400000000000063)\n",
      "Epoch 064/1200 | Loss 1.7976 | Win/lose count 5.5/28.60000000000007 (-23.10000000000007)\n",
      "Epoch 065/1200 | Loss 1.8057 | Win/lose count 7.0/27.500000000000075 (-20.500000000000075)\n",
      "Epoch 066/1200 | Loss 1.8645 | Win/lose count 11.0/31.800000000000075 (-20.800000000000075)\n",
      "Epoch 067/1200 | Loss 1.8755 | Win/lose count 15.5/23.70000000000004 (-8.200000000000038)\n",
      "Epoch 068/1200 | Loss 1.7949 | Win/lose count 13.5/33.00000000000011 (-19.500000000000107)\n",
      "Epoch 069/1200 | Loss 1.9049 | Win/lose count 10.0/26.200000000000095 (-16.200000000000095)\n",
      "Epoch 070/1200 | Loss 1.8763 | Win/lose count 9.0/20.200000000000035 (-11.200000000000035)\n",
      "Epoch 071/1200 | Loss 1.9727 | Win/lose count 15.5/23.50000000000003 (-8.000000000000028)\n",
      "Epoch 072/1200 | Loss 1.8328 | Win/lose count 12.5/28.500000000000075 (-16.000000000000075)\n",
      "Epoch 073/1200 | Loss 1.8247 | Win/lose count 9.5/28.300000000000047 (-18.800000000000047)\n",
      "Epoch 074/1200 | Loss 1.8520 | Win/lose count 10.0/26.100000000000072 (-16.100000000000072)\n",
      "Epoch 075/1200 | Loss 1.8706 | Win/lose count 16.0/25.400000000000023 (-9.400000000000023)\n",
      "Epoch 076/1200 | Loss 1.9496 | Win/lose count 6.5/32.200000000000145 (-25.700000000000145)\n",
      "Epoch 077/1200 | Loss 1.8399 | Win/lose count 10.0/32.2000000000001 (-22.200000000000102)\n",
      "Epoch 078/1200 | Loss 1.8822 | Win/lose count 9.5/29.500000000000092 (-20.000000000000092)\n",
      "Epoch 079/1200 | Loss 1.8177 | Win/lose count 11.0/23.100000000000037 (-12.100000000000037)\n",
      "New epsilon :  0.9259259259259259\n",
      "Epoch 080/1200 | Loss 1.8634 | Win/lose count 12.5/34.000000000000114 (-21.500000000000114)\n",
      "Epoch 081/1200 | Loss 1.8576 | Win/lose count 12.5/27.30000000000004 (-14.80000000000004)\n",
      "Epoch 082/1200 | Loss 1.9096 | Win/lose count 10.0/30.000000000000085 (-20.000000000000085)\n",
      "Epoch 083/1200 | Loss 1.9393 | Win/lose count 7.5/27.100000000000076 (-19.600000000000076)\n",
      "Epoch 084/1200 | Loss 1.9058 | Win/lose count 16.0/26.80000000000009 (-10.80000000000009)\n",
      "Epoch 085/1200 | Loss 1.9020 | Win/lose count 10.0/29.200000000000138 (-19.200000000000138)\n",
      "Epoch 086/1200 | Loss 1.8767 | Win/lose count 14.0/28.700000000000095 (-14.700000000000095)\n",
      "Epoch 087/1200 | Loss 1.8502 | Win/lose count 11.5/26.300000000000104 (-14.800000000000104)\n",
      "Epoch 088/1200 | Loss 1.9408 | Win/lose count 8.0/23.500000000000043 (-15.500000000000043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 089/1200 | Loss 1.8973 | Win/lose count 13.0/30.400000000000077 (-17.400000000000077)\n",
      "Epoch 090/1200 | Loss 1.8529 | Win/lose count 9.0/26.70000000000011 (-17.70000000000011)\n",
      "Epoch 091/1200 | Loss 1.8397 | Win/lose count 14.0/23.10000000000002 (-9.10000000000002)\n",
      "Epoch 092/1200 | Loss 1.8236 | Win/lose count 6.5/24.70000000000009 (-18.20000000000009)\n",
      "Epoch 093/1200 | Loss 1.8500 | Win/lose count 12.5/23.500000000000025 (-11.000000000000025)\n",
      "Epoch 094/1200 | Loss 1.8803 | Win/lose count 9.0/28.200000000000045 (-19.200000000000045)\n",
      "Epoch 095/1200 | Loss 1.8827 | Win/lose count 7.0/28.900000000000112 (-21.900000000000112)\n",
      "Epoch 096/1200 | Loss 1.8891 | Win/lose count 11.0/26.30000000000007 (-15.300000000000072)\n",
      "Epoch 097/1200 | Loss 1.9779 | Win/lose count 12.5/23.400000000000055 (-10.900000000000055)\n",
      "Epoch 098/1200 | Loss 1.9761 | Win/lose count 9.5/23.100000000000033 (-13.600000000000033)\n",
      "Epoch 099/1200 | Loss 1.8877 | Win/lose count 13.5/27.60000000000009 (-14.10000000000009)\n",
      "New epsilon :  0.9074074074074074\n",
      "Epoch 100/1200 | Loss 1.7998 | Win/lose count 12.0/24.60000000000005 (-12.600000000000051)\n",
      "Epoch 101/1200 | Loss 1.8685 | Win/lose count 10.5/27.60000000000006 (-17.10000000000006)\n",
      "Epoch 102/1200 | Loss 1.9440 | Win/lose count 17.5/27.600000000000097 (-10.100000000000097)\n",
      "Epoch 103/1200 | Loss 1.8424 | Win/lose count 6.0/20.40000000000003 (-14.40000000000003)\n",
      "Epoch 104/1200 | Loss 1.9128 | Win/lose count 9.0/22.70000000000002 (-13.70000000000002)\n",
      "Epoch 105/1200 | Loss 1.8363 | Win/lose count 11.0/25.000000000000092 (-14.000000000000092)\n",
      "Epoch 106/1200 | Loss 1.8874 | Win/lose count 16.0/19.1 (-3.1000000000000014)\n",
      "Epoch 107/1200 | Loss 1.8920 | Win/lose count 12.0/31.200000000000117 (-19.200000000000117)\n",
      "Epoch 108/1200 | Loss 1.9751 | Win/lose count 10.0/24.500000000000092 (-14.500000000000092)\n",
      "Epoch 109/1200 | Loss 1.9026 | Win/lose count 11.0/22.00000000000001 (-11.00000000000001)\n",
      "Epoch 110/1200 | Loss 1.8417 | Win/lose count 10.5/26.70000000000009 (-16.20000000000009)\n",
      "Epoch 111/1200 | Loss 1.7966 | Win/lose count 10.0/29.600000000000094 (-19.600000000000094)\n",
      "Epoch 112/1200 | Loss 1.8013 | Win/lose count 14.5/28.800000000000093 (-14.300000000000093)\n",
      "Epoch 113/1200 | Loss 1.8745 | Win/lose count 12.0/31.200000000000053 (-19.200000000000053)\n",
      "Epoch 114/1200 | Loss 1.7657 | Win/lose count 9.5/27.400000000000084 (-17.900000000000084)\n",
      "Epoch 115/1200 | Loss 1.7794 | Win/lose count 9.5/24.200000000000035 (-14.700000000000035)\n",
      "Epoch 116/1200 | Loss 1.8968 | Win/lose count 9.0/22.800000000000026 (-13.800000000000026)\n",
      "Epoch 117/1200 | Loss 1.8805 | Win/lose count 11.0/30.500000000000075 (-19.500000000000075)\n",
      "Epoch 118/1200 | Loss 1.8052 | Win/lose count 10.5/21.500000000000053 (-11.000000000000053)\n",
      "Epoch 119/1200 | Loss 1.8373 | Win/lose count 11.0/24.900000000000063 (-13.900000000000063)\n",
      "New epsilon :  0.8888888888888888\n",
      "Epoch 120/1200 | Loss 1.7439 | Win/lose count 7.5/22.600000000000037 (-15.100000000000037)\n",
      "Epoch 121/1200 | Loss 1.8754 | Win/lose count 16.5/28.900000000000052 (-12.400000000000052)\n",
      "Epoch 122/1200 | Loss 1.8471 | Win/lose count 14.0/20.199999999999992 (-6.199999999999992)\n",
      "Epoch 123/1200 | Loss 1.8326 | Win/lose count 9.0/26.200000000000088 (-17.200000000000088)\n",
      "Epoch 124/1200 | Loss 1.8073 | Win/lose count 14.0/25.70000000000005 (-11.700000000000049)\n",
      "Epoch 125/1200 | Loss 1.8794 | Win/lose count 14.0/35.0000000000001 (-21.0000000000001)\n",
      "Epoch 126/1200 | Loss 1.8520 | Win/lose count 10.0/30.80000000000008 (-20.80000000000008)\n",
      "Epoch 127/1200 | Loss 1.8657 | Win/lose count 13.0/18.90000000000001 (-5.900000000000009)\n",
      "Epoch 128/1200 | Loss 1.8932 | Win/lose count 18.0/35.600000000000094 (-17.600000000000094)\n",
      "Epoch 129/1200 | Loss 1.9337 | Win/lose count 15.5/19.40000000000001 (-3.9000000000000092)\n",
      "Epoch 130/1200 | Loss 1.8982 | Win/lose count 13.5/24.10000000000004 (-10.60000000000004)\n",
      "Epoch 131/1200 | Loss 1.9122 | Win/lose count 4.5/27.30000000000013 (-22.80000000000013)\n",
      "Epoch 132/1200 | Loss 1.8081 | Win/lose count 11.5/26.400000000000084 (-14.900000000000084)\n",
      "Epoch 133/1200 | Loss 1.8908 | Win/lose count 9.5/28.900000000000095 (-19.400000000000095)\n",
      "Epoch 134/1200 | Loss 1.8104 | Win/lose count 10.5/31.600000000000072 (-21.100000000000072)\n",
      "Epoch 135/1200 | Loss 1.8151 | Win/lose count 14.5/26.70000000000007 (-12.20000000000007)\n",
      "Epoch 136/1200 | Loss 1.7531 | Win/lose count 15.0/27.100000000000033 (-12.100000000000033)\n",
      "Epoch 137/1200 | Loss 1.8496 | Win/lose count 12.0/24.70000000000008 (-12.700000000000081)\n",
      "Epoch 138/1200 | Loss 1.8589 | Win/lose count 7.0/25.80000000000005 (-18.80000000000005)\n",
      "Epoch 139/1200 | Loss 1.8424 | Win/lose count 12.0/26.50000000000004 (-14.500000000000039)\n",
      "New epsilon :  0.8703703703703703\n",
      "Epoch 140/1200 | Loss 1.8145 | Win/lose count 11.5/32.20000000000008 (-20.70000000000008)\n",
      "Epoch 141/1200 | Loss 1.8451 | Win/lose count 4.0/18.5 (-14.5)\n",
      "Epoch 142/1200 | Loss 1.9375 | Win/lose count 10.5/26.10000000000008 (-15.60000000000008)\n",
      "Epoch 143/1200 | Loss 1.9415 | Win/lose count 15.5/26.40000000000004 (-10.900000000000041)\n",
      "Epoch 144/1200 | Loss 1.9059 | Win/lose count 11.5/30.100000000000108 (-18.600000000000108)\n",
      "Epoch 145/1200 | Loss 1.8709 | Win/lose count 8.0/23.600000000000087 (-15.600000000000087)\n",
      "Epoch 146/1200 | Loss 1.8948 | Win/lose count 10.5/26.900000000000034 (-16.400000000000034)\n",
      "Epoch 147/1200 | Loss 1.8635 | Win/lose count 12.0/28.900000000000084 (-16.900000000000084)\n",
      "Epoch 148/1200 | Loss 1.9047 | Win/lose count 13.0/34.60000000000011 (-21.600000000000108)\n",
      "Epoch 149/1200 | Loss 1.8522 | Win/lose count 14.0/27.700000000000056 (-13.700000000000056)\n",
      "Epoch 150/1200 | Loss 1.8312 | Win/lose count 8.5/28.400000000000077 (-19.900000000000077)\n",
      "Epoch 151/1200 | Loss 1.8348 | Win/lose count 13.0/27.70000000000006 (-14.70000000000006)\n",
      "Epoch 152/1200 | Loss 1.9190 | Win/lose count 11.5/26.0000000000001 (-14.5000000000001)\n",
      "Epoch 153/1200 | Loss 1.8044 | Win/lose count 11.5/26.000000000000046 (-14.500000000000046)\n",
      "Epoch 154/1200 | Loss 1.7774 | Win/lose count 9.5/24.60000000000008 (-15.10000000000008)\n",
      "Epoch 155/1200 | Loss 1.7660 | Win/lose count 12.0/21.000000000000018 (-9.000000000000018)\n",
      "Epoch 156/1200 | Loss 1.8634 | Win/lose count 10.5/25.40000000000005 (-14.900000000000048)\n",
      "Epoch 157/1200 | Loss 1.7831 | Win/lose count 12.0/30.600000000000094 (-18.600000000000094)\n",
      "Epoch 158/1200 | Loss 1.9176 | Win/lose count 10.0/27.200000000000095 (-17.200000000000095)\n",
      "Epoch 159/1200 | Loss 1.8767 | Win/lose count 7.5/28.900000000000073 (-21.400000000000073)\n",
      "New epsilon :  0.8518518518518519\n",
      "Epoch 160/1200 | Loss 1.8451 | Win/lose count 8.0/22.400000000000052 (-14.400000000000052)\n",
      "Epoch 161/1200 | Loss 1.8344 | Win/lose count 15.0/19.90000000000002 (-4.90000000000002)\n",
      "Epoch 162/1200 | Loss 1.8842 | Win/lose count 16.5/23.600000000000037 (-7.100000000000037)\n",
      "Epoch 163/1200 | Loss 1.8395 | Win/lose count 11.5/26.00000000000003 (-14.500000000000028)\n",
      "Epoch 164/1200 | Loss 1.8433 | Win/lose count 11.5/25.300000000000026 (-13.800000000000026)\n",
      "Epoch 165/1200 | Loss 1.7837 | Win/lose count 11.5/25.30000000000004 (-13.80000000000004)\n",
      "Epoch 166/1200 | Loss 1.8991 | Win/lose count 9.5/28.200000000000067 (-18.700000000000067)\n",
      "Epoch 167/1200 | Loss 1.9194 | Win/lose count 9.5/21.900000000000038 (-12.400000000000038)\n",
      "Epoch 168/1200 | Loss 1.8245 | Win/lose count 12.0/23.599999999999994 (-11.599999999999994)\n",
      "Epoch 169/1200 | Loss 1.9485 | Win/lose count 4.0/28.700000000000138 (-24.700000000000138)\n",
      "Epoch 170/1200 | Loss 1.7942 | Win/lose count 14.5/29.500000000000057 (-15.000000000000057)\n",
      "Epoch 171/1200 | Loss 1.8684 | Win/lose count 14.5/25.900000000000066 (-11.400000000000066)\n",
      "Epoch 172/1200 | Loss 1.8763 | Win/lose count 8.5/29.500000000000107 (-21.000000000000107)\n",
      "Epoch 173/1200 | Loss 1.7817 | Win/lose count 12.5/28.300000000000086 (-15.800000000000086)\n",
      "Epoch 174/1200 | Loss 1.8157 | Win/lose count 11.5/23.500000000000036 (-12.000000000000036)\n",
      "Epoch 175/1200 | Loss 1.8763 | Win/lose count 8.5/22.70000000000003 (-14.200000000000031)\n",
      "Epoch 176/1200 | Loss 1.9013 | Win/lose count 13.0/25.400000000000045 (-12.400000000000045)\n",
      "Epoch 177/1200 | Loss 1.7463 | Win/lose count 11.5/30.700000000000074 (-19.200000000000074)\n",
      "Epoch 178/1200 | Loss 1.7918 | Win/lose count 9.5/24.300000000000043 (-14.800000000000043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1200 | Loss 1.7940 | Win/lose count 18.0/27.300000000000033 (-9.300000000000033)\n",
      "New epsilon :  0.8333333333333334\n",
      "Epoch 180/1200 | Loss 1.8338 | Win/lose count 12.0/26.60000000000005 (-14.600000000000051)\n",
      "Epoch 181/1200 | Loss 1.8338 | Win/lose count 12.0/26.900000000000077 (-14.900000000000077)\n",
      "Epoch 182/1200 | Loss 1.8470 | Win/lose count 16.5/27.20000000000006 (-10.70000000000006)\n",
      "Epoch 183/1200 | Loss 1.9084 | Win/lose count 13.5/28.500000000000085 (-15.000000000000085)\n",
      "Epoch 184/1200 | Loss 1.7661 | Win/lose count 14.5/23.600000000000044 (-9.100000000000044)\n",
      "Epoch 185/1200 | Loss 1.8211 | Win/lose count 15.0/26.100000000000016 (-11.100000000000016)\n",
      "Epoch 186/1200 | Loss 1.7544 | Win/lose count 12.5/25.300000000000104 (-12.800000000000104)\n",
      "Epoch 187/1200 | Loss 1.7712 | Win/lose count 13.5/26.100000000000037 (-12.600000000000037)\n",
      "Epoch 188/1200 | Loss 1.7265 | Win/lose count 14.0/26.300000000000086 (-12.300000000000086)\n",
      "Epoch 189/1200 | Loss 1.8991 | Win/lose count 14.0/19.900000000000006 (-5.900000000000006)\n",
      "Epoch 190/1200 | Loss 1.8524 | Win/lose count 9.0/24.000000000000085 (-15.000000000000085)\n",
      "Epoch 191/1200 | Loss 1.7774 | Win/lose count 11.0/21.20000000000002 (-10.20000000000002)\n",
      "Epoch 192/1200 | Loss 1.7920 | Win/lose count 16.0/15.599999999999964 (0.4000000000000359)\n",
      "Epoch 193/1200 | Loss 1.7819 | Win/lose count 15.0/29.500000000000075 (-14.500000000000075)\n",
      "Epoch 194/1200 | Loss 1.8079 | Win/lose count 9.5/20.30000000000002 (-10.800000000000018)\n",
      "Epoch 195/1200 | Loss 1.8701 | Win/lose count 16.0/27.400000000000038 (-11.400000000000038)\n",
      "Epoch 196/1200 | Loss 1.8895 | Win/lose count 12.0/26.800000000000097 (-14.800000000000097)\n",
      "Epoch 197/1200 | Loss 1.8725 | Win/lose count 11.5/24.20000000000008 (-12.700000000000081)\n",
      "Epoch 198/1200 | Loss 1.8749 | Win/lose count 8.0/23.90000000000004 (-15.900000000000041)\n",
      "Epoch 199/1200 | Loss 1.8107 | Win/lose count 18.0/24.60000000000005 (-6.600000000000051)\n",
      "New epsilon :  0.8148148148148149\n",
      "Epoch 200/1200 | Loss 1.8758 | Win/lose count 16.5/29.700000000000095 (-13.200000000000095)\n",
      "Epoch 201/1200 | Loss 1.8415 | Win/lose count 14.0/24.600000000000055 (-10.600000000000055)\n",
      "Epoch 202/1200 | Loss 1.8431 | Win/lose count 13.0/26.600000000000076 (-13.600000000000076)\n",
      "Epoch 203/1200 | Loss 1.9551 | Win/lose count 15.5/21.200000000000006 (-5.700000000000006)\n",
      "Epoch 204/1200 | Loss 1.8364 | Win/lose count 13.5/31.800000000000107 (-18.300000000000107)\n",
      "Epoch 205/1200 | Loss 1.9577 | Win/lose count 11.5/21.600000000000023 (-10.100000000000023)\n",
      "Epoch 206/1200 | Loss 1.8811 | Win/lose count 14.0/32.100000000000094 (-18.100000000000094)\n",
      "Epoch 207/1200 | Loss 1.8297 | Win/lose count 11.5/24.100000000000044 (-12.600000000000044)\n",
      "Epoch 208/1200 | Loss 1.8888 | Win/lose count 14.5/24.500000000000053 (-10.000000000000053)\n",
      "Epoch 209/1200 | Loss 1.8351 | Win/lose count 10.5/25.000000000000064 (-14.500000000000064)\n",
      "Epoch 210/1200 | Loss 1.8453 | Win/lose count 13.0/23.400000000000034 (-10.400000000000034)\n",
      "Epoch 211/1200 | Loss 1.8293 | Win/lose count 10.5/25.600000000000055 (-15.100000000000055)\n",
      "Epoch 212/1200 | Loss 1.7122 | Win/lose count 14.5/22.300000000000022 (-7.800000000000022)\n",
      "Epoch 213/1200 | Loss 1.8135 | Win/lose count 11.5/28.0000000000001 (-16.5000000000001)\n",
      "Epoch 214/1200 | Loss 1.7846 | Win/lose count 12.5/20.500000000000036 (-8.000000000000036)\n",
      "Epoch 215/1200 | Loss 1.7733 | Win/lose count 12.5/24.40000000000008 (-11.90000000000008)\n",
      "Epoch 216/1200 | Loss 1.6889 | Win/lose count 14.5/20.600000000000005 (-6.100000000000005)\n",
      "Epoch 217/1200 | Loss 1.7581 | Win/lose count 13.0/22.600000000000037 (-9.600000000000037)\n",
      "Epoch 218/1200 | Loss 1.8199 | Win/lose count 10.0/26.700000000000074 (-16.700000000000074)\n",
      "Epoch 219/1200 | Loss 1.7874 | Win/lose count 16.0/28.50000000000005 (-12.50000000000005)\n",
      "New epsilon :  0.7962962962962963\n",
      "Epoch 220/1200 | Loss 1.8581 | Win/lose count 9.0/29.00000000000007 (-20.00000000000007)\n",
      "Epoch 221/1200 | Loss 1.8851 | Win/lose count 16.5/27.50000000000006 (-11.00000000000006)\n",
      "Epoch 222/1200 | Loss 1.8356 | Win/lose count 9.5/25.200000000000035 (-15.700000000000035)\n",
      "Epoch 223/1200 | Loss 1.8019 | Win/lose count 15.5/28.400000000000077 (-12.900000000000077)\n",
      "Epoch 224/1200 | Loss 1.8663 | Win/lose count 9.0/20.800000000000004 (-11.800000000000004)\n",
      "Epoch 225/1200 | Loss 1.7780 | Win/lose count 17.0/22.80000000000005 (-5.8000000000000504)\n",
      "Epoch 226/1200 | Loss 1.8224 | Win/lose count 15.0/23.0 (-8.0)\n",
      "Epoch 227/1200 | Loss 1.7722 | Win/lose count 16.0/22.70000000000006 (-6.70000000000006)\n",
      "Epoch 228/1200 | Loss 1.7519 | Win/lose count 12.5/26.000000000000068 (-13.500000000000068)\n",
      "Epoch 229/1200 | Loss 1.7667 | Win/lose count 19.0/22.200000000000024 (-3.200000000000024)\n",
      "Epoch 230/1200 | Loss 1.7337 | Win/lose count 10.5/25.500000000000053 (-15.000000000000053)\n",
      "Epoch 231/1200 | Loss 1.8538 | Win/lose count 16.5/29.800000000000065 (-13.300000000000065)\n",
      "Epoch 232/1200 | Loss 1.7700 | Win/lose count 13.0/26.700000000000095 (-13.700000000000095)\n",
      "Epoch 233/1200 | Loss 1.7845 | Win/lose count 18.5/27.00000000000005 (-8.50000000000005)\n",
      "Epoch 234/1200 | Loss 1.8095 | Win/lose count 17.0/23.100000000000044 (-6.100000000000044)\n",
      "Epoch 235/1200 | Loss 1.7960 | Win/lose count 20.0/29.30000000000006 (-9.300000000000061)\n",
      "Epoch 236/1200 | Loss 1.7271 | Win/lose count 14.0/26.10000000000008 (-12.10000000000008)\n",
      "Epoch 237/1200 | Loss 1.8306 | Win/lose count 15.0/25.800000000000065 (-10.800000000000065)\n",
      "Epoch 238/1200 | Loss 1.7770 | Win/lose count 14.5/26.90000000000005 (-12.400000000000048)\n",
      "Epoch 239/1200 | Loss 1.8165 | Win/lose count 12.5/28.100000000000055 (-15.600000000000055)\n",
      "New epsilon :  0.7777777777777778\n",
      "Epoch 240/1200 | Loss 1.7632 | Win/lose count 17.0/27.400000000000077 (-10.400000000000077)\n",
      "Epoch 241/1200 | Loss 1.8281 | Win/lose count 14.5/28.10000000000007 (-13.600000000000069)\n",
      "Epoch 242/1200 | Loss 1.7972 | Win/lose count 9.5/27.90000000000012 (-18.40000000000012)\n",
      "Epoch 243/1200 | Loss 1.8180 | Win/lose count 14.0/24.100000000000083 (-10.100000000000083)\n",
      "Epoch 244/1200 | Loss 1.8114 | Win/lose count 17.5/24.700000000000045 (-7.2000000000000455)\n",
      "Epoch 245/1200 | Loss 1.8786 | Win/lose count 12.5/26.200000000000077 (-13.700000000000077)\n",
      "Epoch 246/1200 | Loss 1.8344 | Win/lose count 20.5/23.40000000000004 (-2.900000000000041)\n",
      "Epoch 247/1200 | Loss 1.8696 | Win/lose count 17.0/23.600000000000026 (-6.600000000000026)\n",
      "Epoch 248/1200 | Loss 1.8512 | Win/lose count 10.5/26.70000000000009 (-16.20000000000009)\n",
      "Epoch 249/1200 | Loss 1.8089 | Win/lose count 14.5/26.500000000000064 (-12.000000000000064)\n",
      "Epoch 250/1200 | Loss 1.7725 | Win/lose count 17.0/21.40000000000004 (-4.400000000000041)\n",
      "Epoch 251/1200 | Loss 1.9089 | Win/lose count 17.0/27.600000000000065 (-10.600000000000065)\n",
      "Epoch 252/1200 | Loss 1.7580 | Win/lose count 15.5/32.30000000000006 (-16.80000000000006)\n",
      "Epoch 253/1200 | Loss 1.7098 | Win/lose count 17.0/22.80000000000001 (-5.800000000000011)\n",
      "Epoch 254/1200 | Loss 1.8069 | Win/lose count 16.0/28.700000000000095 (-12.700000000000095)\n",
      "Epoch 255/1200 | Loss 1.6854 | Win/lose count 13.0/26.600000000000094 (-13.600000000000094)\n",
      "Epoch 256/1200 | Loss 1.7163 | Win/lose count 13.5/27.80000000000008 (-14.300000000000079)\n",
      "Epoch 257/1200 | Loss 1.8337 | Win/lose count 16.5/23.10000000000003 (-6.60000000000003)\n",
      "Epoch 258/1200 | Loss 1.7910 | Win/lose count 14.0/27.90000000000005 (-13.900000000000048)\n",
      "Epoch 259/1200 | Loss 1.8038 | Win/lose count 11.5/23.000000000000043 (-11.500000000000043)\n",
      "New epsilon :  0.7592592592592593\n",
      "Epoch 260/1200 | Loss 1.8578 | Win/lose count 13.5/21.400000000000013 (-7.900000000000013)\n",
      "Epoch 261/1200 | Loss 1.7995 | Win/lose count 17.0/29.20000000000004 (-12.200000000000038)\n",
      "Epoch 262/1200 | Loss 1.7775 | Win/lose count 8.0/26.900000000000077 (-18.900000000000077)\n",
      "Epoch 263/1200 | Loss 1.8136 | Win/lose count 14.5/28.000000000000075 (-13.500000000000075)\n",
      "Epoch 264/1200 | Loss 1.7886 | Win/lose count 19.0/34.00000000000005 (-15.00000000000005)\n",
      "Epoch 265/1200 | Loss 1.8657 | Win/lose count 18.5/20.600000000000044 (-2.100000000000044)\n",
      "Epoch 266/1200 | Loss 1.7773 | Win/lose count 18.5/24.40000000000005 (-5.900000000000048)\n",
      "Epoch 267/1200 | Loss 1.7998 | Win/lose count 16.0/26.500000000000078 (-10.500000000000078)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1200 | Loss 1.8155 | Win/lose count 16.5/27.20000000000004 (-10.700000000000038)\n",
      "Epoch 269/1200 | Loss 1.7212 | Win/lose count 15.5/30.70000000000007 (-15.20000000000007)\n",
      "Epoch 270/1200 | Loss 1.7955 | Win/lose count 9.0/20.200000000000028 (-11.200000000000028)\n",
      "Epoch 271/1200 | Loss 1.8719 | Win/lose count 13.0/22.30000000000004 (-9.30000000000004)\n",
      "Epoch 272/1200 | Loss 1.7408 | Win/lose count 15.0/24.900000000000066 (-9.900000000000066)\n",
      "Epoch 273/1200 | Loss 1.7391 | Win/lose count 8.5/24.200000000000067 (-15.700000000000067)\n",
      "Epoch 274/1200 | Loss 1.7851 | Win/lose count 10.5/24.500000000000036 (-14.000000000000036)\n",
      "Epoch 275/1200 | Loss 1.7870 | Win/lose count 16.5/22.600000000000044 (-6.100000000000044)\n",
      "Epoch 276/1200 | Loss 1.8557 | Win/lose count 9.5/21.300000000000036 (-11.800000000000036)\n",
      "Epoch 277/1200 | Loss 1.7479 | Win/lose count 19.5/21.400000000000023 (-1.9000000000000234)\n",
      "Epoch 278/1200 | Loss 1.8257 | Win/lose count 14.5/25.90000000000006 (-11.400000000000059)\n",
      "Epoch 279/1200 | Loss 1.6959 | Win/lose count 12.0/26.50000000000007 (-14.500000000000071)\n",
      "New epsilon :  0.7407407407407407\n",
      "Epoch 280/1200 | Loss 1.8168 | Win/lose count 21.5/20.400000000000027 (1.099999999999973)\n",
      "Epoch 281/1200 | Loss 1.8082 | Win/lose count 15.0/25.00000000000003 (-10.000000000000028)\n",
      "Epoch 282/1200 | Loss 1.7823 | Win/lose count 14.5/24.90000000000004 (-10.400000000000041)\n",
      "Epoch 283/1200 | Loss 1.7924 | Win/lose count 6.0/20.400000000000034 (-14.400000000000034)\n",
      "Epoch 284/1200 | Loss 1.7209 | Win/lose count 9.0/23.70000000000006 (-14.70000000000006)\n",
      "Epoch 285/1200 | Loss 1.7291 | Win/lose count 13.0/26.700000000000035 (-13.700000000000035)\n",
      "Epoch 286/1200 | Loss 1.7239 | Win/lose count 20.0/23.800000000000047 (-3.800000000000047)\n",
      "Epoch 287/1200 | Loss 1.7188 | Win/lose count 13.0/17.599999999999994 (-4.599999999999994)\n",
      "Epoch 288/1200 | Loss 1.8864 | Win/lose count 18.5/19.600000000000012 (-1.100000000000012)\n",
      "Epoch 289/1200 | Loss 1.8001 | Win/lose count 13.5/26.90000000000009 (-13.400000000000091)\n",
      "Epoch 290/1200 | Loss 1.7477 | Win/lose count 12.0/22.700000000000024 (-10.700000000000024)\n",
      "Epoch 291/1200 | Loss 1.7714 | Win/lose count 16.5/21.600000000000062 (-5.100000000000062)\n",
      "Epoch 292/1200 | Loss 1.7392 | Win/lose count 11.5/23.400000000000023 (-11.900000000000023)\n",
      "Epoch 293/1200 | Loss 1.8767 | Win/lose count 11.5/21.500000000000043 (-10.000000000000043)\n",
      "Epoch 294/1200 | Loss 1.7678 | Win/lose count 12.0/32.50000000000008 (-20.500000000000078)\n",
      "Epoch 295/1200 | Loss 1.7721 | Win/lose count 14.5/21.70000000000003 (-7.200000000000031)\n",
      "Epoch 296/1200 | Loss 1.7385 | Win/lose count 11.0/23.000000000000057 (-12.000000000000057)\n",
      "Epoch 297/1200 | Loss 1.6710 | Win/lose count 16.0/22.90000000000003 (-6.9000000000000306)\n",
      "Epoch 298/1200 | Loss 1.6948 | Win/lose count 13.5/36.40000000000008 (-22.900000000000077)\n",
      "Epoch 299/1200 | Loss 1.7294 | Win/lose count 13.0/24.300000000000015 (-11.300000000000015)\n",
      "New epsilon :  0.7222222222222222\n",
      "Epoch 300/1200 | Loss 1.7669 | Win/lose count 10.0/22.700000000000056 (-12.700000000000056)\n",
      "Epoch 301/1200 | Loss 1.6890 | Win/lose count 8.5/31.30000000000007 (-22.80000000000007)\n",
      "Epoch 302/1200 | Loss 1.6863 | Win/lose count 13.5/24.300000000000033 (-10.800000000000033)\n",
      "Epoch 303/1200 | Loss 1.7129 | Win/lose count 13.0/28.400000000000052 (-15.400000000000052)\n",
      "Epoch 304/1200 | Loss 1.6745 | Win/lose count 13.5/25.600000000000065 (-12.100000000000065)\n",
      "Epoch 305/1200 | Loss 1.7284 | Win/lose count 13.0/23.50000000000001 (-10.50000000000001)\n",
      "Epoch 306/1200 | Loss 1.6458 | Win/lose count 19.5/22.90000000000004 (-3.400000000000041)\n",
      "Epoch 307/1200 | Loss 1.6558 | Win/lose count 17.5/26.300000000000043 (-8.800000000000043)\n",
      "Epoch 308/1200 | Loss 1.6862 | Win/lose count 15.5/30.200000000000088 (-14.700000000000088)\n",
      "Epoch 309/1200 | Loss 1.6266 | Win/lose count 12.0/23.600000000000044 (-11.600000000000044)\n",
      "Epoch 310/1200 | Loss 1.6842 | Win/lose count 16.5/19.699999999999996 (-3.1999999999999957)\n",
      "Epoch 311/1200 | Loss 1.8355 | Win/lose count 14.5/25.300000000000036 (-10.800000000000036)\n",
      "Epoch 312/1200 | Loss 1.7651 | Win/lose count 16.0/21.90000000000002 (-5.90000000000002)\n",
      "Epoch 313/1200 | Loss 1.7921 | Win/lose count 12.0/20.40000000000002 (-8.40000000000002)\n",
      "Epoch 314/1200 | Loss 1.6666 | Win/lose count 23.5/26.800000000000054 (-3.300000000000054)\n",
      "Epoch 315/1200 | Loss 1.8334 | Win/lose count 12.0/19.00000000000001 (-7.000000000000011)\n",
      "Epoch 316/1200 | Loss 1.7579 | Win/lose count 11.0/29.300000000000086 (-18.300000000000086)\n",
      "Epoch 317/1200 | Loss 1.6894 | Win/lose count 16.0/26.400000000000063 (-10.400000000000063)\n",
      "Epoch 318/1200 | Loss 1.7464 | Win/lose count 13.5/29.400000000000027 (-15.900000000000027)\n",
      "Epoch 319/1200 | Loss 1.7821 | Win/lose count 15.0/27.40000000000004 (-12.400000000000041)\n",
      "New epsilon :  0.7037037037037037\n",
      "Epoch 320/1200 | Loss 1.7896 | Win/lose count 16.5/22.60000000000004 (-6.1000000000000405)\n",
      "Epoch 321/1200 | Loss 1.7132 | Win/lose count 10.0/25.000000000000064 (-15.000000000000064)\n",
      "Epoch 322/1200 | Loss 1.7190 | Win/lose count 11.5/24.800000000000075 (-13.300000000000075)\n",
      "Epoch 323/1200 | Loss 1.6990 | Win/lose count 16.0/25.000000000000057 (-9.000000000000057)\n",
      "Epoch 324/1200 | Loss 1.6830 | Win/lose count 13.0/25.20000000000007 (-12.20000000000007)\n",
      "Epoch 325/1200 | Loss 1.7115 | Win/lose count 14.5/23.700000000000024 (-9.200000000000024)\n",
      "Epoch 326/1200 | Loss 1.7011 | Win/lose count 7.0/28.500000000000107 (-21.500000000000107)\n",
      "Epoch 327/1200 | Loss 1.7546 | Win/lose count 17.0/28.100000000000065 (-11.100000000000065)\n",
      "Epoch 328/1200 | Loss 1.7623 | Win/lose count 15.0/21.80000000000001 (-6.800000000000011)\n",
      "Epoch 329/1200 | Loss 1.6463 | Win/lose count 11.5/27.500000000000092 (-16.000000000000092)\n",
      "Epoch 330/1200 | Loss 1.7833 | Win/lose count 18.0/21.100000000000016 (-3.1000000000000156)\n",
      "Epoch 331/1200 | Loss 1.7439 | Win/lose count 12.0/21.50000000000006 (-9.50000000000006)\n",
      "Epoch 332/1200 | Loss 1.6904 | Win/lose count 10.5/25.50000000000006 (-15.00000000000006)\n",
      "Epoch 333/1200 | Loss 1.8268 | Win/lose count 13.0/26.300000000000043 (-13.300000000000043)\n",
      "Epoch 334/1200 | Loss 1.7034 | Win/lose count 18.5/28.20000000000006 (-9.70000000000006)\n",
      "Epoch 335/1200 | Loss 1.6940 | Win/lose count 13.5/24.800000000000033 (-11.300000000000033)\n",
      "Epoch 336/1200 | Loss 1.6999 | Win/lose count 10.5/22.70000000000002 (-12.20000000000002)\n",
      "Epoch 337/1200 | Loss 1.6718 | Win/lose count 10.5/21.500000000000053 (-11.000000000000053)\n",
      "Epoch 338/1200 | Loss 1.7475 | Win/lose count 22.0/22.700000000000017 (-0.700000000000017)\n",
      "Epoch 339/1200 | Loss 1.8326 | Win/lose count 15.0/31.900000000000052 (-16.900000000000052)\n",
      "New epsilon :  0.6851851851851851\n",
      "Epoch 340/1200 | Loss 1.7498 | Win/lose count 20.5/24.000000000000036 (-3.5000000000000355)\n",
      "Epoch 341/1200 | Loss 1.6729 | Win/lose count 16.5/22.600000000000048 (-6.100000000000048)\n",
      "Epoch 342/1200 | Loss 1.7406 | Win/lose count 17.5/22.50000000000006 (-5.00000000000006)\n",
      "Epoch 343/1200 | Loss 1.7461 | Win/lose count 14.0/20.400000000000038 (-6.400000000000038)\n",
      "Epoch 344/1200 | Loss 1.7366 | Win/lose count 17.0/20.200000000000024 (-3.200000000000024)\n",
      "Epoch 345/1200 | Loss 1.6751 | Win/lose count 16.5/26.200000000000085 (-9.700000000000085)\n",
      "Epoch 346/1200 | Loss 1.7251 | Win/lose count 18.0/21.300000000000054 (-3.300000000000054)\n",
      "Epoch 347/1200 | Loss 1.7670 | Win/lose count 18.5/24.3 (-5.800000000000001)\n",
      "Epoch 348/1200 | Loss 1.7041 | Win/lose count 21.0/20.50000000000001 (0.49999999999998934)\n",
      "Epoch 349/1200 | Loss 1.7378 | Win/lose count 20.0/24.20000000000002 (-4.200000000000021)\n",
      "Epoch 350/1200 | Loss 1.7939 | Win/lose count 20.5/17.900000000000002 (2.599999999999998)\n",
      "Epoch 351/1200 | Loss 1.7316 | Win/lose count 16.5/28.000000000000043 (-11.500000000000043)\n",
      "Epoch 352/1200 | Loss 1.7737 | Win/lose count 20.5/24.700000000000045 (-4.2000000000000455)\n",
      "Epoch 353/1200 | Loss 1.8251 | Win/lose count 15.0/27.40000000000005 (-12.400000000000048)\n",
      "Epoch 354/1200 | Loss 1.7354 | Win/lose count 14.5/25.800000000000022 (-11.300000000000022)\n",
      "Epoch 355/1200 | Loss 1.7654 | Win/lose count 14.0/24.800000000000068 (-10.800000000000068)\n",
      "Epoch 356/1200 | Loss 1.8490 | Win/lose count 16.5/29.80000000000009 (-13.30000000000009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/1200 | Loss 1.7791 | Win/lose count 11.0/28.50000000000007 (-17.50000000000007)\n",
      "Epoch 358/1200 | Loss 1.7482 | Win/lose count 16.5/26.300000000000047 (-9.800000000000047)\n",
      "Epoch 359/1200 | Loss 1.8077 | Win/lose count 17.0/20.800000000000015 (-3.800000000000015)\n",
      "New epsilon :  0.6666666666666667\n",
      "Epoch 360/1200 | Loss 1.8527 | Win/lose count 16.0/20.20000000000003 (-4.200000000000031)\n",
      "Epoch 361/1200 | Loss 1.7312 | Win/lose count 13.5/21.100000000000044 (-7.600000000000044)\n",
      "Epoch 362/1200 | Loss 1.7524 | Win/lose count 16.0/21.50000000000001 (-5.500000000000011)\n",
      "Epoch 363/1200 | Loss 1.6893 | Win/lose count 16.0/27.000000000000085 (-11.000000000000085)\n",
      "Epoch 364/1200 | Loss 1.6500 | Win/lose count 19.0/31.600000000000072 (-12.600000000000072)\n",
      "Epoch 365/1200 | Loss 1.8083 | Win/lose count 24.0/19.000000000000007 (4.999999999999993)\n",
      "Epoch 366/1200 | Loss 1.6880 | Win/lose count 14.5/21.000000000000014 (-6.500000000000014)\n",
      "Epoch 367/1200 | Loss 1.6710 | Win/lose count 16.0/22.900000000000034 (-6.900000000000034)\n",
      "Epoch 368/1200 | Loss 1.6575 | Win/lose count 10.0/27.400000000000123 (-17.400000000000123)\n",
      "Epoch 369/1200 | Loss 1.6727 | Win/lose count 17.0/23.800000000000082 (-6.800000000000082)\n",
      "Epoch 370/1200 | Loss 1.6778 | Win/lose count 15.0/27.80000000000009 (-12.80000000000009)\n",
      "Epoch 371/1200 | Loss 1.7200 | Win/lose count 17.5/22.800000000000004 (-5.300000000000004)\n",
      "Epoch 372/1200 | Loss 1.7252 | Win/lose count 17.5/29.30000000000007 (-11.800000000000072)\n",
      "Epoch 373/1200 | Loss 1.6563 | Win/lose count 17.5/15.399999999999968 (2.1000000000000316)\n",
      "Epoch 374/1200 | Loss 1.6173 | Win/lose count 14.0/23.500000000000078 (-9.500000000000078)\n",
      "Epoch 375/1200 | Loss 1.6775 | Win/lose count 20.5/21.500000000000046 (-1.0000000000000462)\n",
      "Epoch 376/1200 | Loss 1.7519 | Win/lose count 16.0/27.10000000000005 (-11.100000000000051)\n",
      "Epoch 377/1200 | Loss 1.6999 | Win/lose count 18.5/24.600000000000065 (-6.100000000000065)\n",
      "Epoch 378/1200 | Loss 1.6180 | Win/lose count 19.5/22.00000000000004 (-2.500000000000039)\n",
      "Epoch 379/1200 | Loss 1.7223 | Win/lose count 16.5/26.000000000000053 (-9.500000000000053)\n",
      "New epsilon :  0.6481481481481481\n",
      "Epoch 380/1200 | Loss 1.6981 | Win/lose count 23.0/16.69999999999998 (6.3000000000000185)\n",
      "Epoch 381/1200 | Loss 1.7377 | Win/lose count 20.0/24.40000000000004 (-4.400000000000041)\n",
      "Epoch 382/1200 | Loss 1.5881 | Win/lose count 19.0/22.500000000000032 (-3.500000000000032)\n",
      "Epoch 383/1200 | Loss 1.6817 | Win/lose count 13.0/25.600000000000083 (-12.600000000000083)\n",
      "Epoch 384/1200 | Loss 1.7315 | Win/lose count 16.0/22.800000000000015 (-6.800000000000015)\n",
      "Epoch 385/1200 | Loss 1.7295 | Win/lose count 19.5/18.19999999999999 (1.3000000000000114)\n",
      "Epoch 386/1200 | Loss 1.6472 | Win/lose count 18.5/21.400000000000006 (-2.9000000000000057)\n",
      "Epoch 387/1200 | Loss 1.6562 | Win/lose count 17.0/22.90000000000002 (-5.90000000000002)\n",
      "Epoch 388/1200 | Loss 1.6652 | Win/lose count 17.5/25.70000000000004 (-8.200000000000038)\n",
      "Epoch 389/1200 | Loss 1.6436 | Win/lose count 18.0/26.30000000000004 (-8.30000000000004)\n",
      "Epoch 390/1200 | Loss 1.6666 | Win/lose count 18.0/21.500000000000043 (-3.5000000000000426)\n",
      "Epoch 391/1200 | Loss 1.7800 | Win/lose count 12.0/25.100000000000055 (-13.100000000000055)\n",
      "Epoch 392/1200 | Loss 1.7200 | Win/lose count 14.0/23.700000000000063 (-9.700000000000063)\n",
      "Epoch 393/1200 | Loss 1.7346 | Win/lose count 18.0/29.000000000000078 (-11.000000000000078)\n",
      "Epoch 394/1200 | Loss 1.7058 | Win/lose count 18.0/24.50000000000003 (-6.500000000000028)\n",
      "Epoch 395/1200 | Loss 1.7678 | Win/lose count 10.5/24.70000000000006 (-14.20000000000006)\n",
      "Epoch 396/1200 | Loss 1.7689 | Win/lose count 12.5/23.500000000000025 (-11.000000000000025)\n",
      "Epoch 397/1200 | Loss 1.6475 | Win/lose count 17.5/28.700000000000045 (-11.200000000000045)\n",
      "Epoch 398/1200 | Loss 1.7086 | Win/lose count 17.5/22.800000000000036 (-5.300000000000036)\n",
      "Epoch 399/1200 | Loss 1.7026 | Win/lose count 21.0/26.600000000000065 (-5.600000000000065)\n",
      "New epsilon :  0.6296296296296297\n",
      "Epoch 400/1200 | Loss 1.6785 | Win/lose count 19.0/28.10000000000003 (-9.10000000000003)\n",
      "Epoch 401/1200 | Loss 1.6908 | Win/lose count 20.5/18.399999999999995 (2.100000000000005)\n",
      "Epoch 402/1200 | Loss 1.6730 | Win/lose count 14.5/23.100000000000037 (-8.600000000000037)\n",
      "Epoch 403/1200 | Loss 1.6415 | Win/lose count 19.0/20.800000000000054 (-1.800000000000054)\n",
      "Epoch 404/1200 | Loss 1.6806 | Win/lose count 16.0/22.900000000000038 (-6.900000000000038)\n",
      "Epoch 405/1200 | Loss 1.6844 | Win/lose count 18.0/24.70000000000006 (-6.70000000000006)\n",
      "Epoch 406/1200 | Loss 1.7222 | Win/lose count 15.0/25.000000000000078 (-10.000000000000078)\n",
      "Epoch 407/1200 | Loss 1.6502 | Win/lose count 22.5/22.800000000000043 (-0.30000000000004334)\n",
      "Epoch 408/1200 | Loss 1.6926 | Win/lose count 21.5/26.90000000000006 (-5.400000000000059)\n",
      "Epoch 409/1200 | Loss 1.7826 | Win/lose count 16.5/29.200000000000074 (-12.700000000000074)\n",
      "Epoch 410/1200 | Loss 1.6954 | Win/lose count 18.0/27.800000000000047 (-9.800000000000047)\n",
      "Epoch 411/1200 | Loss 1.7308 | Win/lose count 18.5/23.700000000000014 (-5.2000000000000135)\n",
      "Epoch 412/1200 | Loss 1.7301 | Win/lose count 15.5/24.800000000000047 (-9.300000000000047)\n",
      "Epoch 413/1200 | Loss 1.7894 | Win/lose count 20.0/22.800000000000043 (-2.8000000000000433)\n",
      "Epoch 414/1200 | Loss 1.7819 | Win/lose count 14.5/25.000000000000064 (-10.500000000000064)\n",
      "Epoch 415/1200 | Loss 1.6458 | Win/lose count 18.5/25.100000000000023 (-6.600000000000023)\n",
      "Epoch 416/1200 | Loss 1.6847 | Win/lose count 15.0/19.30000000000002 (-4.3000000000000185)\n",
      "Epoch 417/1200 | Loss 1.5783 | Win/lose count 17.0/27.10000000000004 (-10.10000000000004)\n",
      "Epoch 418/1200 | Loss 1.6606 | Win/lose count 18.0/25.700000000000063 (-7.700000000000063)\n",
      "Epoch 419/1200 | Loss 1.6290 | Win/lose count 19.0/20.00000000000004 (-1.000000000000039)\n",
      "New epsilon :  0.6111111111111112\n",
      "Epoch 420/1200 | Loss 1.5765 | Win/lose count 21.0/19.399999999999984 (1.6000000000000156)\n",
      "Epoch 421/1200 | Loss 1.6640 | Win/lose count 14.5/21.50000000000004 (-7.000000000000039)\n",
      "Epoch 422/1200 | Loss 1.6129 | Win/lose count 24.0/14.499999999999975 (9.500000000000025)\n",
      "Epoch 423/1200 | Loss 1.5498 | Win/lose count 16.5/24.500000000000075 (-8.000000000000075)\n",
      "Epoch 424/1200 | Loss 1.6602 | Win/lose count 16.5/22.800000000000082 (-6.300000000000082)\n",
      "Epoch 425/1200 | Loss 1.6759 | Win/lose count 19.5/19.799999999999997 (-0.29999999999999716)\n",
      "Epoch 426/1200 | Loss 1.6288 | Win/lose count 18.0/21.80000000000001 (-3.8000000000000114)\n",
      "Epoch 427/1200 | Loss 1.7264 | Win/lose count 13.5/27.40000000000006 (-13.900000000000059)\n",
      "Epoch 428/1200 | Loss 1.6630 | Win/lose count 21.0/19.100000000000026 (1.8999999999999737)\n",
      "Epoch 429/1200 | Loss 1.6685 | Win/lose count 24.0/25.100000000000023 (-1.1000000000000227)\n",
      "Epoch 430/1200 | Loss 1.5888 | Win/lose count 21.0/21.10000000000004 (-0.1000000000000405)\n",
      "Epoch 431/1200 | Loss 1.6591 | Win/lose count 22.0/24.70000000000005 (-2.700000000000049)\n",
      "Epoch 432/1200 | Loss 1.7721 | Win/lose count 15.0/22.90000000000003 (-7.9000000000000306)\n",
      "Epoch 433/1200 | Loss 1.6610 | Win/lose count 17.5/20.100000000000037 (-2.600000000000037)\n",
      "Epoch 434/1200 | Loss 1.7512 | Win/lose count 16.0/21.400000000000027 (-5.400000000000027)\n",
      "Epoch 435/1200 | Loss 1.6601 | Win/lose count 22.0/25.500000000000036 (-3.5000000000000355)\n",
      "Epoch 436/1200 | Loss 1.6667 | Win/lose count 17.0/23.40000000000006 (-6.400000000000059)\n",
      "Epoch 437/1200 | Loss 1.7509 | Win/lose count 21.0/23.100000000000044 (-2.100000000000044)\n",
      "Epoch 438/1200 | Loss 1.7068 | Win/lose count 13.0/26.400000000000052 (-13.400000000000052)\n",
      "Epoch 439/1200 | Loss 1.7041 | Win/lose count 21.5/20.799999999999997 (0.7000000000000028)\n",
      "New epsilon :  0.5925925925925926\n",
      "Epoch 440/1200 | Loss 1.6425 | Win/lose count 18.5/20.8 (-2.3000000000000007)\n",
      "Epoch 441/1200 | Loss 1.7376 | Win/lose count 16.5/29.60000000000003 (-13.10000000000003)\n",
      "Epoch 442/1200 | Loss 1.6811 | Win/lose count 20.5/19.100000000000005 (1.399999999999995)\n",
      "Epoch 443/1200 | Loss 1.6502 | Win/lose count 15.5/21.400000000000023 (-5.9000000000000234)\n",
      "Epoch 444/1200 | Loss 1.6467 | Win/lose count 17.5/23.300000000000065 (-5.800000000000065)\n",
      "Epoch 445/1200 | Loss 1.7576 | Win/lose count 11.0/23.200000000000045 (-12.200000000000045)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1200 | Loss 1.6202 | Win/lose count 15.5/23.500000000000075 (-8.000000000000075)\n",
      "Epoch 447/1200 | Loss 1.6147 | Win/lose count 22.5/24.80000000000004 (-2.30000000000004)\n",
      "Epoch 448/1200 | Loss 1.6558 | Win/lose count 15.5/22.70000000000005 (-7.200000000000049)\n",
      "Epoch 449/1200 | Loss 1.6012 | Win/lose count 11.0/27.20000000000007 (-16.20000000000007)\n",
      "Epoch 450/1200 | Loss 1.6514 | Win/lose count 25.0/18.400000000000006 (6.599999999999994)\n",
      "Epoch 451/1200 | Loss 1.6459 | Win/lose count 14.0/21.800000000000033 (-7.800000000000033)\n",
      "Epoch 452/1200 | Loss 1.7077 | Win/lose count 23.0/23.70000000000005 (-0.700000000000049)\n",
      "Epoch 453/1200 | Loss 1.6314 | Win/lose count 22.0/20.400000000000013 (1.5999999999999872)\n",
      "Epoch 454/1200 | Loss 1.5917 | Win/lose count 16.0/23.30000000000004 (-7.30000000000004)\n",
      "Epoch 455/1200 | Loss 1.6465 | Win/lose count 24.5/21.20000000000003 (3.2999999999999687)\n",
      "Epoch 456/1200 | Loss 1.5987 | Win/lose count 25.5/21.30000000000003 (4.199999999999971)\n",
      "Epoch 457/1200 | Loss 1.6954 | Win/lose count 18.5/20.00000000000002 (-1.5000000000000213)\n",
      "Epoch 458/1200 | Loss 1.6739 | Win/lose count 17.5/16.199999999999978 (1.300000000000022)\n",
      "Epoch 459/1200 | Loss 1.6088 | Win/lose count 21.5/21.200000000000024 (0.29999999999997584)\n",
      "New epsilon :  0.5740740740740741\n",
      "Epoch 460/1200 | Loss 1.6726 | Win/lose count 19.0/21.300000000000026 (-2.3000000000000256)\n",
      "Epoch 461/1200 | Loss 1.7551 | Win/lose count 18.5/20.70000000000001 (-2.20000000000001)\n",
      "Epoch 462/1200 | Loss 1.6700 | Win/lose count 21.0/19.500000000000025 (1.4999999999999751)\n",
      "Epoch 463/1200 | Loss 1.7700 | Win/lose count 18.5/20.70000000000003 (-2.2000000000000313)\n",
      "Epoch 464/1200 | Loss 1.6684 | Win/lose count 15.5/21.400000000000023 (-5.9000000000000234)\n",
      "Epoch 465/1200 | Loss 1.7518 | Win/lose count 25.5/22.90000000000003 (2.5999999999999694)\n",
      "Epoch 466/1200 | Loss 1.7982 | Win/lose count 18.0/21.10000000000001 (-3.1000000000000085)\n",
      "Epoch 467/1200 | Loss 1.5701 | Win/lose count 14.0/25.50000000000006 (-11.50000000000006)\n",
      "Epoch 468/1200 | Loss 1.7385 | Win/lose count 15.0/19.100000000000012 (-4.100000000000012)\n",
      "Epoch 469/1200 | Loss 1.6260 | Win/lose count 11.5/20.400000000000002 (-8.900000000000002)\n",
      "Epoch 470/1200 | Loss 1.7299 | Win/lose count 17.5/21.400000000000027 (-3.900000000000027)\n",
      "Epoch 471/1200 | Loss 1.5719 | Win/lose count 15.5/27.500000000000057 (-12.000000000000057)\n",
      "Epoch 472/1200 | Loss 1.5865 | Win/lose count 15.5/24.400000000000055 (-8.900000000000055)\n",
      "Epoch 473/1200 | Loss 1.7118 | Win/lose count 20.5/27.00000000000007 (-6.500000000000071)\n",
      "Epoch 474/1200 | Loss 1.7244 | Win/lose count 14.5/24.300000000000047 (-9.800000000000047)\n",
      "Epoch 475/1200 | Loss 1.6136 | Win/lose count 21.0/19.10000000000001 (1.8999999999999915)\n",
      "Epoch 476/1200 | Loss 1.6823 | Win/lose count 14.0/30.000000000000053 (-16.000000000000053)\n",
      "Epoch 477/1200 | Loss 1.6988 | Win/lose count 20.5/18.099999999999994 (2.4000000000000057)\n",
      "Epoch 478/1200 | Loss 1.6115 | Win/lose count 20.5/23.300000000000026 (-2.8000000000000256)\n",
      "Epoch 479/1200 | Loss 1.6441 | Win/lose count 24.5/22.80000000000002 (1.6999999999999815)\n",
      "New epsilon :  0.5555555555555556\n",
      "Epoch 480/1200 | Loss 1.6980 | Win/lose count 21.0/17.099999999999973 (3.900000000000027)\n",
      "Epoch 481/1200 | Loss 1.6857 | Win/lose count 20.5/17.69999999999998 (2.8000000000000185)\n",
      "Epoch 482/1200 | Loss 1.6858 | Win/lose count 20.5/21.40000000000005 (-0.9000000000000483)\n",
      "Epoch 483/1200 | Loss 1.5635 | Win/lose count 16.0/20.900000000000013 (-4.900000000000013)\n",
      "Epoch 484/1200 | Loss 1.6791 | Win/lose count 18.5/21.300000000000043 (-2.8000000000000433)\n",
      "Epoch 485/1200 | Loss 1.6871 | Win/lose count 16.5/25.300000000000058 (-8.800000000000058)\n",
      "Epoch 486/1200 | Loss 1.6949 | Win/lose count 16.0/19.60000000000002 (-3.600000000000019)\n",
      "Epoch 487/1200 | Loss 1.6326 | Win/lose count 18.5/30.000000000000057 (-11.500000000000057)\n",
      "Epoch 488/1200 | Loss 1.6656 | Win/lose count 18.0/29.500000000000092 (-11.500000000000092)\n",
      "Epoch 489/1200 | Loss 1.6588 | Win/lose count 21.0/22.300000000000033 (-1.3000000000000327)\n",
      "Epoch 490/1200 | Loss 1.6260 | Win/lose count 21.0/22.800000000000026 (-1.8000000000000256)\n",
      "Epoch 491/1200 | Loss 1.6334 | Win/lose count 18.5/19.0 (-0.5)\n",
      "Epoch 492/1200 | Loss 1.6432 | Win/lose count 18.0/19.199999999999996 (-1.1999999999999957)\n",
      "Epoch 493/1200 | Loss 1.5781 | Win/lose count 17.0/26.60000000000008 (-9.60000000000008)\n",
      "Epoch 494/1200 | Loss 1.6871 | Win/lose count 23.0/21.70000000000004 (1.2999999999999616)\n",
      "Epoch 495/1200 | Loss 1.7598 | Win/lose count 19.0/20.90000000000004 (-1.9000000000000412)\n",
      "Epoch 496/1200 | Loss 1.6895 | Win/lose count 12.0/24.60000000000008 (-12.60000000000008)\n",
      "Epoch 497/1200 | Loss 1.6204 | Win/lose count 6.5/24.80000000000004 (-18.30000000000004)\n",
      "Epoch 498/1200 | Loss 1.5841 | Win/lose count 17.5/20.19999999999999 (-2.6999999999999886)\n",
      "Epoch 499/1200 | Loss 1.6750 | Win/lose count 16.5/23.700000000000045 (-7.2000000000000455)\n",
      "New epsilon :  0.537037037037037\n",
      "Epoch 500/1200 | Loss 1.5547 | Win/lose count 24.0/20.30000000000002 (3.6999999999999815)\n",
      "Epoch 501/1200 | Loss 1.6476 | Win/lose count 20.0/25.00000000000003 (-5.000000000000028)\n",
      "Epoch 502/1200 | Loss 1.6738 | Win/lose count 17.5/24.60000000000006 (-7.100000000000058)\n",
      "Epoch 503/1200 | Loss 1.5738 | Win/lose count 11.5/20.50000000000001 (-9.00000000000001)\n",
      "Epoch 504/1200 | Loss 1.6303 | Win/lose count 14.5/22.10000000000006 (-7.600000000000058)\n",
      "Epoch 505/1200 | Loss 1.4402 | Win/lose count 18.0/16.899999999999988 (1.100000000000012)\n",
      "Epoch 506/1200 | Loss 1.5050 | Win/lose count 18.5/23.60000000000001 (-5.1000000000000085)\n",
      "Epoch 507/1200 | Loss 1.6324 | Win/lose count 16.5/22.900000000000045 (-6.400000000000045)\n",
      "Epoch 508/1200 | Loss 1.5418 | Win/lose count 18.0/23.100000000000055 (-5.100000000000055)\n",
      "Epoch 509/1200 | Loss 1.6199 | Win/lose count 12.5/24.800000000000082 (-12.300000000000082)\n",
      "Epoch 510/1200 | Loss 1.5615 | Win/lose count 16.5/22.10000000000004 (-5.6000000000000405)\n",
      "Epoch 511/1200 | Loss 1.5697 | Win/lose count 19.0/25.70000000000005 (-6.700000000000049)\n",
      "Epoch 512/1200 | Loss 1.6064 | Win/lose count 13.0/22.500000000000057 (-9.500000000000057)\n",
      "Epoch 513/1200 | Loss 1.6343 | Win/lose count 20.5/22.700000000000028 (-2.2000000000000277)\n",
      "Epoch 514/1200 | Loss 1.6439 | Win/lose count 12.5/19.3 (-6.800000000000001)\n",
      "Epoch 515/1200 | Loss 1.5709 | Win/lose count 18.5/23.700000000000067 (-5.200000000000067)\n",
      "Epoch 516/1200 | Loss 1.5539 | Win/lose count 18.0/27.800000000000086 (-9.800000000000086)\n",
      "Epoch 517/1200 | Loss 1.6395 | Win/lose count 15.5/24.300000000000054 (-8.800000000000054)\n",
      "Epoch 518/1200 | Loss 1.5979 | Win/lose count 16.0/24.100000000000065 (-8.100000000000065)\n",
      "Epoch 519/1200 | Loss 1.5431 | Win/lose count 19.0/27.400000000000098 (-8.400000000000098)\n",
      "New epsilon :  0.5185185185185186\n",
      "Epoch 520/1200 | Loss 1.6762 | Win/lose count 13.0/23.70000000000004 (-10.700000000000038)\n",
      "Epoch 521/1200 | Loss 1.5445 | Win/lose count 13.0/21.100000000000037 (-8.100000000000037)\n",
      "Epoch 522/1200 | Loss 1.6049 | Win/lose count 22.0/16.399999999999974 (5.600000000000026)\n",
      "Epoch 523/1200 | Loss 1.4553 | Win/lose count 17.5/19.69999999999999 (-2.1999999999999886)\n",
      "Epoch 524/1200 | Loss 1.5640 | Win/lose count 14.5/27.300000000000054 (-12.800000000000054)\n",
      "Epoch 525/1200 | Loss 1.5081 | Win/lose count 21.0/20.00000000000002 (0.9999999999999787)\n",
      "Epoch 526/1200 | Loss 1.5064 | Win/lose count 19.0/26.40000000000006 (-7.400000000000059)\n",
      "Epoch 527/1200 | Loss 1.5641 | Win/lose count 14.5/25.200000000000042 (-10.700000000000042)\n",
      "Epoch 528/1200 | Loss 1.4155 | Win/lose count 15.5/18.000000000000004 (-2.5000000000000036)\n",
      "Epoch 529/1200 | Loss 1.4429 | Win/lose count 14.5/23.30000000000002 (-8.800000000000018)\n",
      "Epoch 530/1200 | Loss 1.5313 | Win/lose count 18.5/22.20000000000005 (-3.700000000000049)\n",
      "Epoch 531/1200 | Loss 1.4576 | Win/lose count 10.0/24.50000000000004 (-14.500000000000039)\n",
      "Epoch 532/1200 | Loss 1.4652 | Win/lose count 19.5/18.60000000000002 (0.8999999999999808)\n",
      "Epoch 533/1200 | Loss 1.4105 | Win/lose count 21.5/17.499999999999975 (4.000000000000025)\n",
      "Epoch 534/1200 | Loss 1.4879 | Win/lose count 21.5/20.00000000000002 (1.4999999999999787)\n",
      "Epoch 535/1200 | Loss 1.5057 | Win/lose count 16.0/28.800000000000075 (-12.800000000000075)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/1200 | Loss 1.5300 | Win/lose count 18.0/19.20000000000002 (-1.2000000000000206)\n",
      "Epoch 537/1200 | Loss 1.6001 | Win/lose count 22.0/15.299999999999978 (6.700000000000022)\n",
      "Epoch 538/1200 | Loss 1.4872 | Win/lose count 18.5/18.40000000000001 (0.09999999999999076)\n",
      "Epoch 539/1200 | Loss 1.5001 | Win/lose count 19.0/24.600000000000016 (-5.600000000000016)\n",
      "New epsilon :  0.5\n",
      "Epoch 540/1200 | Loss 1.6283 | Win/lose count 18.0/18.599999999999998 (-0.5999999999999979)\n",
      "Epoch 541/1200 | Loss 1.5590 | Win/lose count 18.0/21.80000000000003 (-3.800000000000029)\n",
      "Epoch 542/1200 | Loss 1.4870 | Win/lose count 17.0/20.20000000000003 (-3.2000000000000313)\n",
      "Epoch 543/1200 | Loss 1.6236 | Win/lose count 16.0/21.60000000000006 (-5.600000000000058)\n",
      "Epoch 544/1200 | Loss 1.4628 | Win/lose count 26.5/25.500000000000025 (0.9999999999999751)\n",
      "Epoch 545/1200 | Loss 1.5119 | Win/lose count 21.5/25.70000000000004 (-4.200000000000038)\n",
      "Epoch 546/1200 | Loss 1.4923 | Win/lose count 23.5/26.100000000000062 (-2.600000000000062)\n",
      "Epoch 547/1200 | Loss 1.4903 | Win/lose count 18.0/21.80000000000005 (-3.8000000000000504)\n",
      "Epoch 548/1200 | Loss 1.4665 | Win/lose count 20.0/16.099999999999977 (3.9000000000000234)\n",
      "Epoch 549/1200 | Loss 1.4712 | Win/lose count 22.5/23.40000000000002 (-0.9000000000000199)\n",
      "Epoch 550/1200 | Loss 1.5885 | Win/lose count 23.0/19.70000000000001 (3.29999999999999)\n",
      "Epoch 551/1200 | Loss 1.5919 | Win/lose count 22.0/16.699999999999985 (5.300000000000015)\n",
      "Epoch 552/1200 | Loss 1.5352 | Win/lose count 18.5/23.100000000000037 (-4.600000000000037)\n",
      "Epoch 553/1200 | Loss 1.4517 | Win/lose count 19.0/19.9 (-0.8999999999999986)\n",
      "Epoch 554/1200 | Loss 1.5308 | Win/lose count 19.0/21.400000000000034 (-2.400000000000034)\n",
      "Epoch 555/1200 | Loss 1.5282 | Win/lose count 18.0/23.500000000000036 (-5.5000000000000355)\n",
      "Epoch 556/1200 | Loss 1.5811 | Win/lose count 17.5/22.50000000000003 (-5.000000000000028)\n",
      "Epoch 557/1200 | Loss 1.5828 | Win/lose count 22.5/24.700000000000017 (-2.200000000000017)\n",
      "Epoch 558/1200 | Loss 1.5658 | Win/lose count 20.5/21.10000000000001 (-0.6000000000000085)\n",
      "Epoch 559/1200 | Loss 1.5102 | Win/lose count 18.5/18.30000000000001 (0.19999999999998863)\n",
      "New epsilon :  0.4814814814814815\n",
      "Epoch 560/1200 | Loss 1.6280 | Win/lose count 26.0/17.699999999999996 (8.300000000000004)\n",
      "Epoch 561/1200 | Loss 1.6157 | Win/lose count 23.5/19.80000000000002 (3.6999999999999815)\n",
      "Epoch 562/1200 | Loss 1.5645 | Win/lose count 20.0/23.600000000000033 (-3.6000000000000334)\n",
      "Epoch 563/1200 | Loss 1.5837 | Win/lose count 15.5/22.000000000000046 (-6.500000000000046)\n",
      "Epoch 564/1200 | Loss 1.5912 | Win/lose count 23.0/22.100000000000005 (0.899999999999995)\n",
      "Epoch 565/1200 | Loss 1.5496 | Win/lose count 20.5/19.400000000000023 (1.0999999999999766)\n",
      "Epoch 566/1200 | Loss 1.4579 | Win/lose count 15.5/21.60000000000006 (-6.100000000000058)\n",
      "Epoch 567/1200 | Loss 1.5857 | Win/lose count 22.5/18.0 (4.5)\n",
      "Epoch 568/1200 | Loss 1.5277 | Win/lose count 20.5/29.60000000000005 (-9.100000000000051)\n",
      "Epoch 569/1200 | Loss 1.6201 | Win/lose count 17.5/21.200000000000017 (-3.700000000000017)\n",
      "Epoch 570/1200 | Loss 1.4763 | Win/lose count 17.5/15.699999999999969 (1.800000000000031)\n",
      "Epoch 571/1200 | Loss 1.5454 | Win/lose count 18.5/17.99999999999999 (0.5000000000000107)\n",
      "Epoch 572/1200 | Loss 1.5615 | Win/lose count 22.5/19.300000000000015 (3.199999999999985)\n",
      "Epoch 573/1200 | Loss 1.4654 | Win/lose count 12.5/23.400000000000073 (-10.900000000000073)\n",
      "Epoch 574/1200 | Loss 1.6065 | Win/lose count 20.5/19.800000000000022 (0.699999999999978)\n",
      "Epoch 575/1200 | Loss 1.5710 | Win/lose count 17.5/19.000000000000018 (-1.5000000000000178)\n",
      "Epoch 576/1200 | Loss 1.7350 | Win/lose count 18.5/22.300000000000058 (-3.8000000000000576)\n",
      "Epoch 577/1200 | Loss 1.4869 | Win/lose count 16.5/23.40000000000006 (-6.900000000000059)\n",
      "Epoch 578/1200 | Loss 1.5386 | Win/lose count 22.0/23.30000000000006 (-1.300000000000061)\n",
      "Epoch 579/1200 | Loss 1.4784 | Win/lose count 19.0/21.700000000000035 (-2.700000000000035)\n",
      "New epsilon :  0.4629629629629629\n",
      "Epoch 580/1200 | Loss 1.4904 | Win/lose count 23.5/20.200000000000024 (3.299999999999976)\n",
      "Epoch 581/1200 | Loss 1.5889 | Win/lose count 17.5/25.70000000000005 (-8.200000000000049)\n",
      "Epoch 582/1200 | Loss 1.4439 | Win/lose count 24.0/20.900000000000002 (3.099999999999998)\n",
      "Epoch 583/1200 | Loss 1.4049 | Win/lose count 23.5/26.30000000000006 (-2.800000000000061)\n",
      "Epoch 584/1200 | Loss 1.5206 | Win/lose count 27.0/15.999999999999977 (11.000000000000023)\n",
      "Epoch 585/1200 | Loss 1.5175 | Win/lose count 16.0/24.900000000000055 (-8.900000000000055)\n",
      "Epoch 586/1200 | Loss 1.5773 | Win/lose count 20.5/22.20000000000002 (-1.7000000000000206)\n",
      "Epoch 587/1200 | Loss 1.4956 | Win/lose count 17.5/20.20000000000002 (-2.7000000000000206)\n",
      "Epoch 588/1200 | Loss 1.4947 | Win/lose count 17.0/21.800000000000036 (-4.800000000000036)\n",
      "Epoch 589/1200 | Loss 1.5214 | Win/lose count 20.5/18.699999999999992 (1.8000000000000078)\n",
      "Epoch 590/1200 | Loss 1.5725 | Win/lose count 21.5/20.000000000000007 (1.499999999999993)\n",
      "Epoch 591/1200 | Loss 1.5740 | Win/lose count 20.0/26.100000000000037 (-6.100000000000037)\n",
      "Epoch 592/1200 | Loss 1.5391 | Win/lose count 16.0/25.400000000000038 (-9.400000000000038)\n",
      "Epoch 593/1200 | Loss 1.5801 | Win/lose count 20.0/22.300000000000047 (-2.300000000000047)\n",
      "Epoch 594/1200 | Loss 1.5836 | Win/lose count 15.5/21.700000000000017 (-6.200000000000017)\n",
      "Epoch 595/1200 | Loss 1.5223 | Win/lose count 25.0/21.900000000000023 (3.0999999999999766)\n",
      "Epoch 596/1200 | Loss 1.5980 | Win/lose count 15.5/23.70000000000005 (-8.200000000000049)\n",
      "Epoch 597/1200 | Loss 1.5278 | Win/lose count 19.0/23.300000000000033 (-4.300000000000033)\n",
      "Epoch 598/1200 | Loss 1.5004 | Win/lose count 19.0/21.000000000000025 (-2.000000000000025)\n",
      "Epoch 599/1200 | Loss 1.5018 | Win/lose count 23.5/18.099999999999998 (5.400000000000002)\n",
      "New epsilon :  0.4444444444444444\n",
      "Epoch 600/1200 | Loss 1.5685 | Win/lose count 19.0/22.9 (-3.8999999999999986)\n",
      "Epoch 601/1200 | Loss 1.5168 | Win/lose count 24.0/22.500000000000053 (1.4999999999999467)\n",
      "Epoch 602/1200 | Loss 1.5459 | Win/lose count 20.5/17.9 (2.6000000000000014)\n",
      "Epoch 603/1200 | Loss 1.4401 | Win/lose count 16.5/25.200000000000024 (-8.700000000000024)\n",
      "Epoch 604/1200 | Loss 1.4226 | Win/lose count 20.5/25.20000000000007 (-4.70000000000007)\n",
      "Epoch 605/1200 | Loss 1.5290 | Win/lose count 19.5/18.899999999999988 (0.6000000000000121)\n",
      "Epoch 606/1200 | Loss 1.4103 | Win/lose count 18.0/19.50000000000001 (-1.5000000000000107)\n",
      "Epoch 607/1200 | Loss 1.4631 | Win/lose count 18.0/28.200000000000074 (-10.200000000000074)\n",
      "Epoch 608/1200 | Loss 1.4747 | Win/lose count 17.0/22.700000000000017 (-5.700000000000017)\n",
      "Epoch 609/1200 | Loss 1.5431 | Win/lose count 18.5/25.60000000000004 (-7.1000000000000405)\n",
      "Epoch 610/1200 | Loss 1.3961 | Win/lose count 15.5/17.59999999999999 (-2.0999999999999908)\n",
      "Epoch 611/1200 | Loss 1.4190 | Win/lose count 19.0/20.50000000000001 (-1.5000000000000107)\n",
      "Epoch 612/1200 | Loss 1.5159 | Win/lose count 23.0/18.80000000000002 (4.1999999999999815)\n",
      "Epoch 613/1200 | Loss 1.3567 | Win/lose count 14.0/23.700000000000074 (-9.700000000000074)\n",
      "Epoch 614/1200 | Loss 1.5543 | Win/lose count 19.0/21.70000000000004 (-2.7000000000000384)\n",
      "Epoch 615/1200 | Loss 1.4391 | Win/lose count 18.0/19.9 (-1.8999999999999986)\n",
      "Epoch 616/1200 | Loss 1.3521 | Win/lose count 18.0/18.599999999999994 (-0.5999999999999943)\n",
      "Epoch 617/1200 | Loss 1.4736 | Win/lose count 15.5/24.50000000000006 (-9.00000000000006)\n",
      "Epoch 618/1200 | Loss 1.4615 | Win/lose count 16.0/18.0 (-2.0)\n",
      "Epoch 619/1200 | Loss 1.4186 | Win/lose count 16.0/26.10000000000002 (-10.10000000000002)\n",
      "New epsilon :  0.42592592592592593\n",
      "Epoch 620/1200 | Loss 1.4165 | Win/lose count 18.5/27.000000000000092 (-8.500000000000092)\n",
      "Epoch 621/1200 | Loss 1.3237 | Win/lose count 23.0/21.100000000000044 (1.899999999999956)\n",
      "Epoch 622/1200 | Loss 1.4508 | Win/lose count 18.5/19.5 (-1.0)\n",
      "Epoch 623/1200 | Loss 1.4710 | Win/lose count 17.0/22.90000000000003 (-5.9000000000000306)\n",
      "Epoch 624/1200 | Loss 1.4663 | Win/lose count 28.0/17.59999999999998 (10.40000000000002)\n",
      "Epoch 625/1200 | Loss 1.2660 | Win/lose count 17.0/31.900000000000073 (-14.900000000000073)\n",
      "Epoch 626/1200 | Loss 1.4446 | Win/lose count 23.0/18.29999999999999 (4.70000000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1200 | Loss 1.5544 | Win/lose count 21.0/16.699999999999985 (4.300000000000015)\n",
      "Epoch 628/1200 | Loss 1.4579 | Win/lose count 20.5/23.600000000000033 (-3.1000000000000334)\n",
      "Epoch 629/1200 | Loss 1.3491 | Win/lose count 18.0/21.400000000000034 (-3.400000000000034)\n",
      "Epoch 630/1200 | Loss 1.6096 | Win/lose count 21.0/16.699999999999985 (4.300000000000015)\n",
      "Epoch 631/1200 | Loss 1.3891 | Win/lose count 25.0/18.200000000000014 (6.7999999999999865)\n",
      "Epoch 632/1200 | Loss 1.5536 | Win/lose count 23.0/17.8 (5.199999999999999)\n",
      "Epoch 633/1200 | Loss 1.4996 | Win/lose count 20.0/17.19999999999999 (2.8000000000000114)\n",
      "Epoch 634/1200 | Loss 1.4831 | Win/lose count 18.0/24.100000000000037 (-6.100000000000037)\n",
      "Epoch 635/1200 | Loss 1.5223 | Win/lose count 22.0/15.599999999999971 (6.400000000000029)\n",
      "Epoch 636/1200 | Loss 1.5461 | Win/lose count 24.0/20.900000000000038 (3.0999999999999623)\n",
      "Epoch 637/1200 | Loss 1.4059 | Win/lose count 17.5/20.100000000000026 (-2.6000000000000263)\n",
      "Epoch 638/1200 | Loss 1.5831 | Win/lose count 21.5/21.60000000000005 (-0.10000000000005116)\n",
      "Epoch 639/1200 | Loss 1.4526 | Win/lose count 27.0/17.39999999999998 (9.60000000000002)\n",
      "New epsilon :  0.40740740740740744\n",
      "Epoch 640/1200 | Loss 1.4419 | Win/lose count 12.5/21.70000000000004 (-9.200000000000038)\n",
      "Epoch 641/1200 | Loss 1.4682 | Win/lose count 25.0/20.800000000000022 (4.199999999999978)\n",
      "Epoch 642/1200 | Loss 1.6572 | Win/lose count 27.5/21.700000000000017 (5.799999999999983)\n",
      "Epoch 643/1200 | Loss 1.3608 | Win/lose count 22.5/18.19999999999998 (4.3000000000000185)\n",
      "Epoch 644/1200 | Loss 1.4046 | Win/lose count 21.5/20.200000000000024 (1.2999999999999758)\n",
      "Epoch 645/1200 | Loss 1.5154 | Win/lose count 21.5/26.000000000000057 (-4.500000000000057)\n",
      "Epoch 646/1200 | Loss 1.4185 | Win/lose count 18.5/18.400000000000013 (0.09999999999998721)\n",
      "Epoch 647/1200 | Loss 1.2944 | Win/lose count 14.5/23.300000000000054 (-8.800000000000054)\n",
      "Epoch 648/1200 | Loss 1.3745 | Win/lose count 21.0/23.30000000000003 (-2.300000000000029)\n",
      "Epoch 649/1200 | Loss 1.3718 | Win/lose count 17.0/22.000000000000025 (-5.000000000000025)\n",
      "Epoch 650/1200 | Loss 1.3279 | Win/lose count 17.5/22.10000000000003 (-4.60000000000003)\n",
      "Epoch 651/1200 | Loss 1.3183 | Win/lose count 23.5/17.499999999999993 (6.000000000000007)\n",
      "Epoch 652/1200 | Loss 1.3609 | Win/lose count 24.5/20.500000000000014 (3.999999999999986)\n",
      "Epoch 653/1200 | Loss 1.5125 | Win/lose count 24.0/22.100000000000012 (1.899999999999988)\n",
      "Epoch 654/1200 | Loss 1.4590 | Win/lose count 19.0/20.00000000000003 (-1.0000000000000284)\n",
      "Epoch 655/1200 | Loss 1.5113 | Win/lose count 14.0/22.400000000000055 (-8.400000000000055)\n",
      "Epoch 656/1200 | Loss 1.3375 | Win/lose count 20.0/21.300000000000008 (-1.3000000000000078)\n",
      "Epoch 657/1200 | Loss 1.4539 | Win/lose count 19.5/21.000000000000004 (-1.5000000000000036)\n",
      "Epoch 658/1200 | Loss 1.3070 | Win/lose count 26.0/24.100000000000044 (1.899999999999956)\n",
      "Epoch 659/1200 | Loss 1.3523 | Win/lose count 22.0/20.000000000000004 (1.9999999999999964)\n",
      "New epsilon :  0.38888888888888884\n",
      "Epoch 660/1200 | Loss 1.3834 | Win/lose count 19.5/14.999999999999975 (4.500000000000025)\n",
      "Epoch 661/1200 | Loss 1.3910 | Win/lose count 16.0/20.500000000000007 (-4.500000000000007)\n",
      "Epoch 662/1200 | Loss 1.3128 | Win/lose count 16.5/16.29999999999997 (0.20000000000003126)\n",
      "Epoch 663/1200 | Loss 1.4229 | Win/lose count 17.5/18.1 (-0.6000000000000014)\n",
      "Epoch 664/1200 | Loss 1.4094 | Win/lose count 18.5/27.000000000000085 (-8.500000000000085)\n",
      "Epoch 665/1200 | Loss 1.4142 | Win/lose count 17.0/21.200000000000042 (-4.200000000000042)\n",
      "Epoch 666/1200 | Loss 1.4751 | Win/lose count 22.0/14.699999999999974 (7.300000000000026)\n",
      "Epoch 667/1200 | Loss 1.3317 | Win/lose count 19.0/17.599999999999994 (1.4000000000000057)\n",
      "Epoch 668/1200 | Loss 1.4679 | Win/lose count 21.5/17.399999999999977 (4.100000000000023)\n",
      "Epoch 669/1200 | Loss 1.4747 | Win/lose count 26.5/23.500000000000018 (2.9999999999999822)\n",
      "Epoch 670/1200 | Loss 1.4469 | Win/lose count 20.0/20.60000000000002 (-0.6000000000000192)\n",
      "Epoch 671/1200 | Loss 1.5355 | Win/lose count 14.5/22.200000000000014 (-7.7000000000000135)\n",
      "Epoch 672/1200 | Loss 1.3939 | Win/lose count 28.5/21.10000000000003 (7.39999999999997)\n",
      "Epoch 673/1200 | Loss 1.3797 | Win/lose count 21.5/20.50000000000001 (0.9999999999999893)\n",
      "Epoch 674/1200 | Loss 1.5037 | Win/lose count 16.5/17.699999999999996 (-1.1999999999999957)\n",
      "Epoch 675/1200 | Loss 1.4206 | Win/lose count 12.5/23.00000000000005 (-10.50000000000005)\n",
      "Epoch 676/1200 | Loss 1.4321 | Win/lose count 20.0/20.60000000000003 (-0.6000000000000298)\n",
      "Epoch 677/1200 | Loss 1.4469 | Win/lose count 20.5/20.30000000000003 (0.19999999999997087)\n",
      "Epoch 678/1200 | Loss 1.4527 | Win/lose count 19.0/23.400000000000063 (-4.4000000000000625)\n",
      "Epoch 679/1200 | Loss 1.4323 | Win/lose count 22.0/24.500000000000043 (-2.5000000000000426)\n",
      "New epsilon :  0.37037037037037035\n",
      "Epoch 680/1200 | Loss 1.3610 | Win/lose count 21.5/21.30000000000003 (0.19999999999997087)\n",
      "Epoch 681/1200 | Loss 1.4904 | Win/lose count 23.5/19.499999999999996 (4.0000000000000036)\n",
      "Epoch 682/1200 | Loss 1.5430 | Win/lose count 21.5/15.899999999999967 (5.600000000000033)\n",
      "Epoch 683/1200 | Loss 1.3488 | Win/lose count 21.5/22.90000000000003 (-1.4000000000000306)\n",
      "Epoch 684/1200 | Loss 1.4694 | Win/lose count 16.0/21.700000000000028 (-5.700000000000028)\n",
      "Epoch 685/1200 | Loss 1.5554 | Win/lose count 18.5/22.700000000000035 (-4.200000000000035)\n",
      "Epoch 686/1200 | Loss 1.4818 | Win/lose count 28.5/22.300000000000015 (6.199999999999985)\n",
      "Epoch 687/1200 | Loss 1.3648 | Win/lose count 21.5/19.100000000000023 (2.3999999999999773)\n",
      "Epoch 688/1200 | Loss 1.5316 | Win/lose count 23.5/19.700000000000003 (3.799999999999997)\n",
      "Epoch 689/1200 | Loss 1.6275 | Win/lose count 21.5/19.000000000000007 (2.499999999999993)\n",
      "Epoch 690/1200 | Loss 1.4212 | Win/lose count 24.0/20.5 (3.5)\n",
      "Epoch 691/1200 | Loss 1.3671 | Win/lose count 17.5/25.80000000000008 (-8.300000000000079)\n",
      "Epoch 692/1200 | Loss 1.3668 | Win/lose count 25.0/15.599999999999971 (9.400000000000029)\n",
      "Epoch 693/1200 | Loss 1.3523 | Win/lose count 22.5/16.899999999999988 (5.600000000000012)\n",
      "Epoch 694/1200 | Loss 1.4531 | Win/lose count 20.5/18.299999999999997 (2.200000000000003)\n",
      "Epoch 695/1200 | Loss 1.4605 | Win/lose count 16.0/24.800000000000065 (-8.800000000000065)\n",
      "Epoch 696/1200 | Loss 1.3758 | Win/lose count 20.5/19.600000000000023 (0.8999999999999773)\n",
      "Epoch 697/1200 | Loss 1.5086 | Win/lose count 16.0/21.700000000000024 (-5.700000000000024)\n",
      "Epoch 698/1200 | Loss 1.4185 | Win/lose count 20.0/15.799999999999974 (4.200000000000026)\n",
      "Epoch 699/1200 | Loss 1.3684 | Win/lose count 23.5/20.300000000000026 (3.1999999999999744)\n",
      "New epsilon :  0.35185185185185186\n",
      "Epoch 700/1200 | Loss 1.4413 | Win/lose count 24.5/18.400000000000013 (6.099999999999987)\n",
      "Epoch 701/1200 | Loss 1.5066 | Win/lose count 16.5/22.70000000000003 (-6.200000000000031)\n",
      "Epoch 702/1200 | Loss 1.4260 | Win/lose count 20.5/23.50000000000004 (-3.000000000000039)\n",
      "Epoch 703/1200 | Loss 1.3352 | Win/lose count 16.0/23.900000000000066 (-7.900000000000066)\n",
      "Epoch 704/1200 | Loss 1.4200 | Win/lose count 23.5/23.100000000000026 (0.3999999999999737)\n",
      "Epoch 705/1200 | Loss 1.3057 | Win/lose count 20.0/17.099999999999987 (2.900000000000013)\n",
      "Epoch 706/1200 | Loss 1.3343 | Win/lose count 19.5/20.499999999999996 (-0.9999999999999964)\n",
      "Epoch 707/1200 | Loss 1.3232 | Win/lose count 24.5/15.999999999999968 (8.500000000000032)\n",
      "Epoch 708/1200 | Loss 1.3785 | Win/lose count 24.0/18.5 (5.5)\n",
      "Epoch 709/1200 | Loss 1.5129 | Win/lose count 19.0/17.69999999999997 (1.3000000000000291)\n",
      "Epoch 710/1200 | Loss 1.3779 | Win/lose count 13.5/17.299999999999983 (-3.799999999999983)\n",
      "Epoch 711/1200 | Loss 1.2788 | Win/lose count 20.5/21.500000000000046 (-1.0000000000000462)\n",
      "Epoch 712/1200 | Loss 1.3419 | Win/lose count 21.0/19.30000000000002 (1.6999999999999815)\n",
      "Epoch 713/1200 | Loss 1.3395 | Win/lose count 13.5/18.699999999999992 (-5.199999999999992)\n",
      "Epoch 714/1200 | Loss 1.2317 | Win/lose count 17.5/15.799999999999965 (1.7000000000000348)\n",
      "Epoch 715/1200 | Loss 1.5065 | Win/lose count 21.0/19.30000000000001 (1.6999999999999886)\n",
      "Epoch 716/1200 | Loss 1.4240 | Win/lose count 18.0/19.000000000000014 (-1.0000000000000142)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/1200 | Loss 1.2846 | Win/lose count 24.5/19.100000000000012 (5.399999999999988)\n",
      "Epoch 718/1200 | Loss 1.2548 | Win/lose count 23.5/21.90000000000005 (1.5999999999999517)\n",
      "Epoch 719/1200 | Loss 1.2678 | Win/lose count 20.5/17.7 (2.8000000000000007)\n",
      "New epsilon :  0.33333333333333337\n",
      "Epoch 720/1200 | Loss 1.2569 | Win/lose count 13.0/22.000000000000057 (-9.000000000000057)\n",
      "Epoch 721/1200 | Loss 1.1749 | Win/lose count 24.5/15.199999999999976 (9.300000000000024)\n",
      "Epoch 722/1200 | Loss 1.0972 | Win/lose count 15.5/15.499999999999964 (3.552713678800501e-14)\n",
      "Epoch 723/1200 | Loss 1.2253 | Win/lose count 27.5/19.5 (8.0)\n",
      "Epoch 724/1200 | Loss 1.1755 | Win/lose count 28.0/18.200000000000014 (9.799999999999986)\n",
      "Epoch 725/1200 | Loss 1.1880 | Win/lose count 26.5/17.899999999999984 (8.600000000000016)\n",
      "Epoch 726/1200 | Loss 1.2057 | Win/lose count 17.0/23.600000000000037 (-6.600000000000037)\n",
      "Epoch 727/1200 | Loss 1.2332 | Win/lose count 14.5/18.0 (-3.5)\n",
      "Epoch 728/1200 | Loss 1.2532 | Win/lose count 19.5/17.09999999999999 (2.4000000000000092)\n",
      "Epoch 729/1200 | Loss 1.2452 | Win/lose count 16.5/18.499999999999993 (-1.999999999999993)\n",
      "Epoch 730/1200 | Loss 1.2293 | Win/lose count 21.0/18.900000000000006 (2.0999999999999943)\n",
      "Epoch 731/1200 | Loss 1.1947 | Win/lose count 22.0/18.1 (3.8999999999999986)\n",
      "Epoch 732/1200 | Loss 1.3194 | Win/lose count 20.5/21.100000000000026 (-0.6000000000000263)\n",
      "Epoch 733/1200 | Loss 1.2720 | Win/lose count 20.0/16.799999999999983 (3.200000000000017)\n",
      "Epoch 734/1200 | Loss 1.1651 | Win/lose count 22.0/25.200000000000017 (-3.200000000000017)\n",
      "Epoch 735/1200 | Loss 1.1616 | Win/lose count 23.5/20.900000000000027 (2.599999999999973)\n",
      "Epoch 736/1200 | Loss 1.2801 | Win/lose count 17.0/19.300000000000026 (-2.3000000000000256)\n",
      "Epoch 737/1200 | Loss 1.4471 | Win/lose count 19.5/19.900000000000034 (-0.4000000000000341)\n",
      "Epoch 738/1200 | Loss 1.3236 | Win/lose count 23.0/21.000000000000025 (1.9999999999999751)\n",
      "Epoch 739/1200 | Loss 1.2179 | Win/lose count 20.0/19.30000000000002 (0.6999999999999815)\n",
      "New epsilon :  0.31481481481481477\n",
      "Epoch 740/1200 | Loss 1.2663 | Win/lose count 22.0/17.4 (4.600000000000001)\n",
      "Epoch 741/1200 | Loss 1.5576 | Win/lose count 21.0/22.500000000000043 (-1.5000000000000426)\n",
      "Epoch 742/1200 | Loss 1.3485 | Win/lose count 20.5/18.999999999999993 (1.500000000000007)\n",
      "Epoch 743/1200 | Loss 1.3536 | Win/lose count 17.0/25.200000000000045 (-8.200000000000045)\n",
      "Epoch 744/1200 | Loss 1.2260 | Win/lose count 13.0/20.60000000000001 (-7.6000000000000085)\n",
      "Epoch 745/1200 | Loss 1.2236 | Win/lose count 20.0/17.299999999999976 (2.700000000000024)\n",
      "Epoch 746/1200 | Loss 1.4220 | Win/lose count 26.0/19.600000000000005 (6.399999999999995)\n",
      "Epoch 747/1200 | Loss 1.4686 | Win/lose count 21.0/21.200000000000053 (-0.20000000000005258)\n",
      "Epoch 748/1200 | Loss 1.2720 | Win/lose count 20.0/16.999999999999982 (3.0000000000000178)\n",
      "Epoch 749/1200 | Loss 1.3028 | Win/lose count 22.0/16.299999999999976 (5.700000000000024)\n",
      "Epoch 750/1200 | Loss 1.1927 | Win/lose count 22.0/16.699999999999978 (5.300000000000022)\n",
      "Epoch 751/1200 | Loss 1.2914 | Win/lose count 20.0/22.300000000000022 (-2.300000000000022)\n",
      "Epoch 752/1200 | Loss 1.2344 | Win/lose count 29.5/23.400000000000034 (6.099999999999966)\n",
      "Epoch 753/1200 | Loss 1.3084 | Win/lose count 24.5/18.800000000000008 (5.699999999999992)\n",
      "Epoch 754/1200 | Loss 1.3348 | Win/lose count 21.0/22.800000000000054 (-1.800000000000054)\n",
      "Epoch 755/1200 | Loss 1.2235 | Win/lose count 15.5/20.00000000000003 (-4.500000000000028)\n",
      "Epoch 756/1200 | Loss 1.2404 | Win/lose count 27.0/14.899999999999977 (12.100000000000023)\n",
      "Epoch 757/1200 | Loss 1.2719 | Win/lose count 17.5/24.20000000000009 (-6.700000000000092)\n",
      "Epoch 758/1200 | Loss 1.3036 | Win/lose count 19.5/18.600000000000012 (0.8999999999999879)\n",
      "Epoch 759/1200 | Loss 1.2018 | Win/lose count 15.5/21.300000000000054 (-5.800000000000054)\n",
      "New epsilon :  0.2962962962962963\n",
      "Epoch 760/1200 | Loss 1.3797 | Win/lose count 24.0/15.199999999999973 (8.800000000000027)\n",
      "Epoch 761/1200 | Loss 1.5926 | Win/lose count 23.0/20.600000000000033 (2.3999999999999666)\n",
      "Epoch 762/1200 | Loss 1.3150 | Win/lose count 23.5/21.50000000000001 (1.9999999999999893)\n",
      "Epoch 763/1200 | Loss 1.2993 | Win/lose count 26.5/15.399999999999977 (11.100000000000023)\n",
      "Epoch 764/1200 | Loss 1.1602 | Win/lose count 20.5/23.400000000000027 (-2.900000000000027)\n",
      "Epoch 765/1200 | Loss 1.2271 | Win/lose count 23.0/16.59999999999998 (6.40000000000002)\n",
      "Epoch 766/1200 | Loss 1.3743 | Win/lose count 25.5/15.599999999999982 (9.900000000000018)\n",
      "Epoch 767/1200 | Loss 1.3687 | Win/lose count 23.0/19.599999999999998 (3.400000000000002)\n",
      "Epoch 768/1200 | Loss 1.2084 | Win/lose count 16.5/21.700000000000028 (-5.200000000000028)\n",
      "Epoch 769/1200 | Loss 1.1536 | Win/lose count 22.0/14.999999999999973 (7.000000000000027)\n",
      "Epoch 770/1200 | Loss 1.2158 | Win/lose count 27.5/23.600000000000033 (3.8999999999999666)\n",
      "Epoch 771/1200 | Loss 1.3078 | Win/lose count 22.5/15.49999999999997 (7.00000000000003)\n",
      "Epoch 772/1200 | Loss 1.2325 | Win/lose count 14.0/19.300000000000015 (-5.300000000000015)\n",
      "Epoch 773/1200 | Loss 1.2117 | Win/lose count 25.5/16.799999999999986 (8.700000000000014)\n",
      "Epoch 774/1200 | Loss 1.1693 | Win/lose count 19.5/20.400000000000006 (-0.9000000000000057)\n",
      "Epoch 775/1200 | Loss 1.1026 | Win/lose count 23.0/13.199999999999976 (9.800000000000024)\n",
      "Epoch 776/1200 | Loss 1.0439 | Win/lose count 24.5/16.19999999999998 (8.300000000000018)\n",
      "Epoch 777/1200 | Loss 1.3022 | Win/lose count 26.5/15.899999999999974 (10.600000000000026)\n",
      "Epoch 778/1200 | Loss 1.1129 | Win/lose count 18.5/24.80000000000009 (-6.3000000000000895)\n",
      "Epoch 779/1200 | Loss 1.1240 | Win/lose count 22.5/20.10000000000003 (2.39999999999997)\n",
      "New epsilon :  0.2777777777777778\n",
      "Epoch 780/1200 | Loss 1.1493 | Win/lose count 14.5/20.599999999999984 (-6.099999999999984)\n",
      "Epoch 781/1200 | Loss 1.1793 | Win/lose count 19.5/15.999999999999966 (3.5000000000000338)\n",
      "Epoch 782/1200 | Loss 1.1713 | Win/lose count 22.0/20.00000000000004 (1.999999999999961)\n",
      "Epoch 783/1200 | Loss 1.1589 | Win/lose count 24.0/20.70000000000004 (3.2999999999999616)\n",
      "Epoch 784/1200 | Loss 1.2532 | Win/lose count 22.0/21.400000000000038 (0.5999999999999623)\n",
      "Epoch 785/1200 | Loss 1.2039 | Win/lose count 26.0/21.400000000000016 (4.599999999999984)\n",
      "Epoch 786/1200 | Loss 1.1943 | Win/lose count 22.0/18.800000000000022 (3.199999999999978)\n",
      "Epoch 787/1200 | Loss 1.3228 | Win/lose count 15.0/18.8 (-3.8000000000000007)\n",
      "Epoch 788/1200 | Loss 1.1044 | Win/lose count 25.5/18.9 (6.600000000000001)\n",
      "Epoch 789/1200 | Loss 1.0603 | Win/lose count 22.0/15.79999999999997 (6.2000000000000295)\n",
      "Epoch 790/1200 | Loss 1.1355 | Win/lose count 22.5/17.89999999999999 (4.6000000000000085)\n",
      "Epoch 791/1200 | Loss 1.1350 | Win/lose count 23.0/14.599999999999975 (8.400000000000025)\n",
      "Epoch 792/1200 | Loss 1.0870 | Win/lose count 23.0/20.300000000000033 (2.6999999999999673)\n",
      "Epoch 793/1200 | Loss 1.2085 | Win/lose count 26.0/18.000000000000004 (7.9999999999999964)\n",
      "Epoch 794/1200 | Loss 1.2949 | Win/lose count 24.5/19.50000000000001 (4.999999999999989)\n",
      "Epoch 795/1200 | Loss 1.1782 | Win/lose count 13.5/20.3 (-6.800000000000001)\n",
      "Epoch 796/1200 | Loss 1.2157 | Win/lose count 10.5/20.90000000000002 (-10.40000000000002)\n",
      "Epoch 797/1200 | Loss 0.9452 | Win/lose count 21.0/15.599999999999968 (5.400000000000032)\n",
      "Epoch 798/1200 | Loss 1.0409 | Win/lose count 21.5/22.70000000000004 (-1.2000000000000384)\n",
      "Epoch 799/1200 | Loss 1.1970 | Win/lose count 19.5/18.600000000000012 (0.8999999999999879)\n",
      "New epsilon :  0.2592592592592593\n",
      "Epoch 800/1200 | Loss 1.1105 | Win/lose count 24.0/16.899999999999977 (7.100000000000023)\n",
      "Epoch 801/1200 | Loss 1.2560 | Win/lose count 26.5/14.499999999999975 (12.000000000000025)\n",
      "Epoch 802/1200 | Loss 1.3154 | Win/lose count 29.0/17.900000000000002 (11.099999999999998)\n",
      "Epoch 803/1200 | Loss 1.2505 | Win/lose count 26.5/15.89999999999998 (10.60000000000002)\n",
      "Epoch 804/1200 | Loss 1.0977 | Win/lose count 21.5/19.20000000000002 (2.2999999999999794)\n",
      "Epoch 805/1200 | Loss 1.1876 | Win/lose count 18.5/14.69999999999997 (3.800000000000029)\n",
      "Epoch 806/1200 | Loss 1.0173 | Win/lose count 26.5/16.099999999999973 (10.400000000000027)\n",
      "Epoch 807/1200 | Loss 1.0655 | Win/lose count 14.0/18.3 (-4.300000000000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 808/1200 | Loss 1.2122 | Win/lose count 27.0/15.599999999999975 (11.400000000000025)\n",
      "Epoch 809/1200 | Loss 1.1661 | Win/lose count 20.0/21.700000000000006 (-1.7000000000000064)\n",
      "Epoch 810/1200 | Loss 1.2285 | Win/lose count 13.0/21.200000000000053 (-8.200000000000053)\n",
      "Epoch 811/1200 | Loss 1.1008 | Win/lose count 19.5/22.500000000000043 (-3.0000000000000426)\n",
      "Epoch 812/1200 | Loss 1.2169 | Win/lose count 22.5/21.70000000000004 (0.7999999999999616)\n",
      "Epoch 813/1200 | Loss 1.2455 | Win/lose count 27.0/16.199999999999978 (10.800000000000022)\n",
      "Epoch 814/1200 | Loss 1.2449 | Win/lose count 20.0/22.400000000000045 (-2.4000000000000448)\n",
      "Epoch 815/1200 | Loss 1.2052 | Win/lose count 21.0/21.300000000000033 (-0.3000000000000327)\n",
      "Epoch 816/1200 | Loss 1.2350 | Win/lose count 20.0/16.99999999999999 (3.0000000000000107)\n",
      "Epoch 817/1200 | Loss 1.2691 | Win/lose count 20.0/15.699999999999974 (4.300000000000026)\n",
      "Epoch 818/1200 | Loss 1.1821 | Win/lose count 20.0/19.100000000000023 (0.8999999999999773)\n",
      "Epoch 819/1200 | Loss 1.1473 | Win/lose count 23.0/20.600000000000048 (2.3999999999999524)\n",
      "New epsilon :  0.2407407407407407\n",
      "Epoch 820/1200 | Loss 1.2662 | Win/lose count 25.0/22.700000000000035 (2.299999999999965)\n",
      "Epoch 821/1200 | Loss 1.2125 | Win/lose count 20.0/15.199999999999973 (4.800000000000027)\n",
      "Epoch 822/1200 | Loss 1.1972 | Win/lose count 24.5/15.29999999999998 (9.20000000000002)\n",
      "Epoch 823/1200 | Loss 1.1562 | Win/lose count 18.0/18.1 (-0.10000000000000142)\n",
      "Epoch 824/1200 | Loss 1.1987 | Win/lose count 15.5/20.900000000000034 (-5.400000000000034)\n",
      "Epoch 825/1200 | Loss 1.2569 | Win/lose count 22.0/17.399999999999984 (4.600000000000016)\n",
      "Epoch 826/1200 | Loss 1.1718 | Win/lose count 17.0/21.10000000000004 (-4.1000000000000405)\n",
      "Epoch 827/1200 | Loss 1.1176 | Win/lose count 23.5/13.699999999999974 (9.800000000000026)\n",
      "Epoch 828/1200 | Loss 1.2575 | Win/lose count 26.0/15.899999999999977 (10.100000000000023)\n",
      "Epoch 829/1200 | Loss 1.1328 | Win/lose count 19.5/15.199999999999969 (4.300000000000031)\n",
      "Epoch 830/1200 | Loss 1.1538 | Win/lose count 22.5/18.30000000000001 (4.199999999999989)\n",
      "Epoch 831/1200 | Loss 1.1547 | Win/lose count 26.5/18.600000000000005 (7.899999999999995)\n",
      "Epoch 832/1200 | Loss 1.2784 | Win/lose count 22.0/14.299999999999972 (7.700000000000028)\n",
      "Epoch 833/1200 | Loss 1.4057 | Win/lose count 29.0/16.999999999999986 (12.000000000000014)\n",
      "Epoch 834/1200 | Loss 1.1729 | Win/lose count 16.0/16.89999999999998 (-0.8999999999999808)\n",
      "Epoch 835/1200 | Loss 1.1327 | Win/lose count 23.5/17.099999999999987 (6.400000000000013)\n",
      "Epoch 836/1200 | Loss 1.2459 | Win/lose count 23.5/15.799999999999983 (7.700000000000017)\n",
      "Epoch 837/1200 | Loss 1.1685 | Win/lose count 8.0/20.100000000000026 (-12.100000000000026)\n",
      "Epoch 838/1200 | Loss 1.1806 | Win/lose count 27.0/16.99999999999999 (10.00000000000001)\n",
      "Epoch 839/1200 | Loss 1.2703 | Win/lose count 27.0/24.900000000000013 (2.099999999999987)\n",
      "New epsilon :  0.2222222222222222\n",
      "Epoch 840/1200 | Loss 1.1746 | Win/lose count 24.5/14.199999999999978 (10.300000000000022)\n",
      "Epoch 841/1200 | Loss 1.2146 | Win/lose count 25.0/12.799999999999978 (12.200000000000022)\n",
      "Epoch 842/1200 | Loss 1.1497 | Win/lose count 22.0/20.900000000000038 (1.0999999999999623)\n",
      "Epoch 843/1200 | Loss 1.0954 | Win/lose count 23.0/18.200000000000003 (4.799999999999997)\n",
      "Epoch 844/1200 | Loss 1.1959 | Win/lose count 24.5/18.000000000000004 (6.4999999999999964)\n",
      "Epoch 845/1200 | Loss 1.0431 | Win/lose count 19.0/17.299999999999997 (1.7000000000000028)\n",
      "Epoch 846/1200 | Loss 1.1415 | Win/lose count 17.5/14.899999999999967 (2.6000000000000334)\n",
      "Epoch 847/1200 | Loss 1.0652 | Win/lose count 21.5/21.30000000000003 (0.19999999999997087)\n",
      "Epoch 848/1200 | Loss 1.2068 | Win/lose count 22.0/21.20000000000002 (0.7999999999999794)\n",
      "Epoch 849/1200 | Loss 1.1290 | Win/lose count 21.0/15.699999999999967 (5.300000000000033)\n",
      "Epoch 850/1200 | Loss 1.2174 | Win/lose count 26.5/14.599999999999975 (11.900000000000025)\n",
      "Epoch 851/1200 | Loss 1.1068 | Win/lose count 20.0/14.799999999999974 (5.200000000000026)\n",
      "Epoch 852/1200 | Loss 1.2228 | Win/lose count 16.5/16.29999999999997 (0.20000000000003126)\n",
      "Epoch 853/1200 | Loss 1.0463 | Win/lose count 26.0/18.400000000000013 (7.599999999999987)\n",
      "Epoch 854/1200 | Loss 1.2598 | Win/lose count 19.0/21.10000000000002 (-2.100000000000019)\n",
      "Epoch 855/1200 | Loss 1.0541 | Win/lose count 23.0/14.499999999999982 (8.500000000000018)\n",
      "Epoch 856/1200 | Loss 1.3244 | Win/lose count 22.0/16.59999999999998 (5.40000000000002)\n",
      "Epoch 857/1200 | Loss 1.1249 | Win/lose count 18.0/21.39999999999999 (-3.3999999999999915)\n",
      "Epoch 858/1200 | Loss 1.0338 | Win/lose count 21.5/15.799999999999974 (5.700000000000026)\n",
      "Epoch 859/1200 | Loss 1.0499 | Win/lose count 18.0/19.900000000000038 (-1.9000000000000377)\n",
      "New epsilon :  0.20370370370370372\n",
      "Epoch 860/1200 | Loss 1.1275 | Win/lose count 16.5/19.30000000000002 (-2.8000000000000185)\n",
      "Epoch 861/1200 | Loss 1.0359 | Win/lose count 26.5/16.299999999999972 (10.200000000000028)\n",
      "Epoch 862/1200 | Loss 1.1259 | Win/lose count 25.5/16.29999999999998 (9.20000000000002)\n",
      "Epoch 863/1200 | Loss 1.0514 | Win/lose count 26.5/17.09999999999999 (9.40000000000001)\n",
      "Epoch 864/1200 | Loss 1.0722 | Win/lose count 23.5/22.10000000000004 (1.3999999999999595)\n",
      "Epoch 865/1200 | Loss 1.2403 | Win/lose count 24.5/14.999999999999975 (9.500000000000025)\n",
      "Epoch 866/1200 | Loss 1.1658 | Win/lose count 25.5/11.699999999999978 (13.800000000000022)\n",
      "Epoch 867/1200 | Loss 1.0828 | Win/lose count 25.0/21.6 (3.3999999999999986)\n",
      "Epoch 868/1200 | Loss 1.0245 | Win/lose count 26.5/15.899999999999977 (10.600000000000023)\n",
      "Epoch 869/1200 | Loss 1.1162 | Win/lose count 18.0/18.599999999999994 (-0.5999999999999943)\n",
      "Epoch 870/1200 | Loss 1.0668 | Win/lose count 23.5/17.09999999999998 (6.40000000000002)\n",
      "Epoch 871/1200 | Loss 1.0132 | Win/lose count 22.0/15.999999999999973 (6.000000000000027)\n",
      "Epoch 872/1200 | Loss 1.1010 | Win/lose count 21.0/19.900000000000016 (1.0999999999999837)\n",
      "Epoch 873/1200 | Loss 1.0454 | Win/lose count 30.5/17.500000000000007 (12.999999999999993)\n",
      "Epoch 874/1200 | Loss 0.9089 | Win/lose count 24.5/11.899999999999979 (12.600000000000021)\n",
      "Epoch 875/1200 | Loss 1.0108 | Win/lose count 22.5/15.299999999999976 (7.200000000000024)\n",
      "Epoch 876/1200 | Loss 0.9939 | Win/lose count 15.0/18.099999999999994 (-3.0999999999999943)\n",
      "Epoch 877/1200 | Loss 0.9211 | Win/lose count 20.5/16.499999999999975 (4.000000000000025)\n",
      "Epoch 878/1200 | Loss 1.0707 | Win/lose count 23.0/11.299999999999983 (11.700000000000017)\n",
      "Epoch 879/1200 | Loss 1.0229 | Win/lose count 17.5/19.100000000000016 (-1.6000000000000156)\n",
      "New epsilon :  0.18518518518518523\n",
      "Epoch 880/1200 | Loss 1.0942 | Win/lose count 21.0/16.399999999999988 (4.600000000000012)\n",
      "Epoch 881/1200 | Loss 1.1448 | Win/lose count 20.0/20.700000000000017 (-0.700000000000017)\n",
      "Epoch 882/1200 | Loss 1.1677 | Win/lose count 22.0/13.599999999999975 (8.400000000000025)\n",
      "Epoch 883/1200 | Loss 1.0397 | Win/lose count 22.5/18.300000000000008 (4.199999999999992)\n",
      "Epoch 884/1200 | Loss 0.9695 | Win/lose count 21.0/20.300000000000026 (0.6999999999999744)\n",
      "Epoch 885/1200 | Loss 0.9059 | Win/lose count 18.0/14.699999999999966 (3.3000000000000345)\n",
      "Epoch 886/1200 | Loss 0.9494 | Win/lose count 22.0/18.499999999999993 (3.500000000000007)\n",
      "Epoch 887/1200 | Loss 0.9457 | Win/lose count 28.0/18.800000000000008 (9.199999999999992)\n",
      "Epoch 888/1200 | Loss 1.0158 | Win/lose count 18.5/19.70000000000003 (-1.2000000000000313)\n",
      "Epoch 889/1200 | Loss 0.8891 | Win/lose count 18.0/17.299999999999983 (0.700000000000017)\n",
      "Epoch 890/1200 | Loss 0.9747 | Win/lose count 10.5/15.69999999999996 (-5.19999999999996)\n",
      "Epoch 891/1200 | Loss 1.0667 | Win/lose count 24.0/13.299999999999976 (10.700000000000024)\n",
      "Epoch 892/1200 | Loss 0.8600 | Win/lose count 15.5/18.400000000000002 (-2.900000000000002)\n",
      "Epoch 893/1200 | Loss 0.9233 | Win/lose count 16.5/15.499999999999972 (1.0000000000000284)\n",
      "Epoch 894/1200 | Loss 0.8931 | Win/lose count 17.0/14.799999999999967 (2.200000000000033)\n",
      "Epoch 895/1200 | Loss 0.8887 | Win/lose count 23.5/12.099999999999977 (11.400000000000023)\n",
      "Epoch 896/1200 | Loss 1.0388 | Win/lose count 25.5/15.69999999999997 (9.80000000000003)\n",
      "Epoch 897/1200 | Loss 1.0435 | Win/lose count 17.0/20.200000000000035 (-3.200000000000035)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898/1200 | Loss 1.0518 | Win/lose count 23.0/19.80000000000002 (3.1999999999999815)\n",
      "Epoch 899/1200 | Loss 0.8987 | Win/lose count 25.0/19.300000000000022 (5.699999999999978)\n",
      "New epsilon :  0.16666666666666663\n",
      "Epoch 900/1200 | Loss 0.8209 | Win/lose count 24.0/14.699999999999973 (9.300000000000027)\n",
      "Epoch 901/1200 | Loss 0.8322 | Win/lose count 21.0/16.09999999999998 (4.90000000000002)\n",
      "Epoch 902/1200 | Loss 0.9649 | Win/lose count 21.0/20.90000000000002 (0.0999999999999801)\n",
      "Epoch 903/1200 | Loss 0.9413 | Win/lose count 26.0/14.199999999999976 (11.800000000000024)\n",
      "Epoch 904/1200 | Loss 0.8997 | Win/lose count 27.0/14.499999999999972 (12.500000000000028)\n",
      "Epoch 905/1200 | Loss 0.9831 | Win/lose count 25.5/11.399999999999979 (14.100000000000021)\n",
      "Epoch 906/1200 | Loss 1.0332 | Win/lose count 26.5/16.99999999999999 (9.50000000000001)\n",
      "Epoch 907/1200 | Loss 0.8463 | Win/lose count 20.0/15.299999999999972 (4.700000000000028)\n",
      "Epoch 908/1200 | Loss 1.0793 | Win/lose count 28.5/14.699999999999974 (13.800000000000026)\n",
      "Epoch 909/1200 | Loss 0.8841 | Win/lose count 19.0/17.9 (1.1000000000000014)\n",
      "Epoch 910/1200 | Loss 1.0839 | Win/lose count 21.0/16.299999999999976 (4.700000000000024)\n",
      "Epoch 911/1200 | Loss 0.9853 | Win/lose count 25.0/12.999999999999973 (12.000000000000027)\n",
      "Epoch 912/1200 | Loss 0.8980 | Win/lose count 19.5/19.000000000000004 (0.49999999999999645)\n",
      "Epoch 913/1200 | Loss 0.8937 | Win/lose count 19.0/16.299999999999972 (2.7000000000000277)\n",
      "Epoch 914/1200 | Loss 0.8343 | Win/lose count 22.5/17.499999999999982 (5.000000000000018)\n",
      "Epoch 915/1200 | Loss 0.9786 | Win/lose count 27.5/17.199999999999992 (10.300000000000008)\n",
      "Epoch 916/1200 | Loss 1.0054 | Win/lose count 25.0/17.29999999999999 (7.70000000000001)\n",
      "Epoch 917/1200 | Loss 1.0648 | Win/lose count 32.0/14.399999999999983 (17.600000000000016)\n",
      "Epoch 918/1200 | Loss 1.1447 | Win/lose count 27.0/13.799999999999981 (13.200000000000019)\n",
      "Epoch 919/1200 | Loss 1.0831 | Win/lose count 21.0/16.899999999999988 (4.100000000000012)\n",
      "New epsilon :  0.14814814814814814\n",
      "Epoch 920/1200 | Loss 1.1859 | Win/lose count 23.5/15.099999999999975 (8.400000000000025)\n",
      "Epoch 921/1200 | Loss 1.0004 | Win/lose count 20.5/16.89999999999999 (3.6000000000000085)\n",
      "Epoch 922/1200 | Loss 1.1602 | Win/lose count 20.0/18.80000000000002 (1.1999999999999815)\n",
      "Epoch 923/1200 | Loss 1.0664 | Win/lose count 20.0/15.89999999999997 (4.10000000000003)\n",
      "Epoch 924/1200 | Loss 1.1000 | Win/lose count 27.0/9.499999999999986 (17.500000000000014)\n",
      "Epoch 925/1200 | Loss 0.9780 | Win/lose count 21.0/13.99999999999997 (7.00000000000003)\n",
      "Epoch 926/1200 | Loss 1.2731 | Win/lose count 21.0/15.799999999999976 (5.200000000000024)\n",
      "Epoch 927/1200 | Loss 1.0532 | Win/lose count 26.0/14.69999999999997 (11.30000000000003)\n",
      "Epoch 928/1200 | Loss 0.9198 | Win/lose count 22.0/20.200000000000042 (1.799999999999958)\n",
      "Epoch 929/1200 | Loss 1.0007 | Win/lose count 18.0/15.599999999999975 (2.4000000000000252)\n",
      "Epoch 930/1200 | Loss 1.0567 | Win/lose count 23.5/13.999999999999973 (9.500000000000027)\n",
      "Epoch 931/1200 | Loss 1.0676 | Win/lose count 22.0/18.0 (4.0)\n",
      "Epoch 932/1200 | Loss 1.0867 | Win/lose count 23.0/13.199999999999978 (9.800000000000022)\n",
      "Epoch 933/1200 | Loss 0.9525 | Win/lose count 25.0/20.80000000000004 (4.19999999999996)\n",
      "Epoch 934/1200 | Loss 0.8399 | Win/lose count 24.5/13.29999999999998 (11.20000000000002)\n",
      "Epoch 935/1200 | Loss 0.9448 | Win/lose count 26.0/16.599999999999987 (9.400000000000013)\n",
      "Epoch 936/1200 | Loss 1.1790 | Win/lose count 21.5/17.900000000000006 (3.5999999999999943)\n",
      "Epoch 937/1200 | Loss 0.8842 | Win/lose count 22.5/18.399999999999988 (4.100000000000012)\n",
      "Epoch 938/1200 | Loss 1.0097 | Win/lose count 23.5/16.999999999999986 (6.500000000000014)\n",
      "Epoch 939/1200 | Loss 0.9761 | Win/lose count 22.0/17.199999999999992 (4.800000000000008)\n",
      "New epsilon :  0.12962962962962965\n",
      "Epoch 940/1200 | Loss 1.0079 | Win/lose count 25.0/16.699999999999985 (8.300000000000015)\n",
      "Epoch 941/1200 | Loss 1.0689 | Win/lose count 20.0/14.599999999999968 (5.400000000000032)\n",
      "Epoch 942/1200 | Loss 0.8068 | Win/lose count 18.5/15.399999999999967 (3.1000000000000334)\n",
      "Epoch 943/1200 | Loss 0.9437 | Win/lose count 24.5/17.39999999999999 (7.1000000000000085)\n",
      "Epoch 944/1200 | Loss 0.9797 | Win/lose count 23.5/18.199999999999985 (5.300000000000015)\n",
      "Epoch 945/1200 | Loss 1.0923 | Win/lose count 20.5/19.60000000000003 (0.8999999999999702)\n",
      "Epoch 946/1200 | Loss 0.8134 | Win/lose count 22.0/18.300000000000008 (3.699999999999992)\n",
      "Epoch 947/1200 | Loss 0.9024 | Win/lose count 20.0/16.199999999999974 (3.8000000000000256)\n",
      "Epoch 948/1200 | Loss 0.8041 | Win/lose count 24.0/14.29999999999998 (9.70000000000002)\n",
      "Epoch 949/1200 | Loss 0.8730 | Win/lose count 23.5/16.999999999999982 (6.500000000000018)\n",
      "Epoch 950/1200 | Loss 0.8676 | Win/lose count 17.5/16.899999999999988 (0.6000000000000121)\n",
      "Epoch 951/1200 | Loss 0.9372 | Win/lose count 23.0/9.799999999999981 (13.200000000000019)\n",
      "Epoch 952/1200 | Loss 0.8600 | Win/lose count 21.5/14.099999999999966 (7.400000000000034)\n",
      "Epoch 953/1200 | Loss 0.8020 | Win/lose count 29.5/15.599999999999975 (13.900000000000025)\n",
      "Epoch 954/1200 | Loss 0.7762 | Win/lose count 23.0/15.199999999999973 (7.800000000000027)\n",
      "Epoch 955/1200 | Loss 0.7438 | Win/lose count 23.5/16.19999999999997 (7.300000000000029)\n",
      "Epoch 956/1200 | Loss 0.6975 | Win/lose count 22.5/15.699999999999978 (6.800000000000022)\n",
      "Epoch 957/1200 | Loss 0.9116 | Win/lose count 24.0/18.200000000000006 (5.799999999999994)\n",
      "Epoch 958/1200 | Loss 0.7946 | Win/lose count 26.5/13.999999999999979 (12.500000000000021)\n",
      "Epoch 959/1200 | Loss 0.9357 | Win/lose count 20.5/11.999999999999973 (8.500000000000027)\n",
      "New epsilon :  0.11111111111111116\n",
      "Epoch 960/1200 | Loss 0.8364 | Win/lose count 22.0/19.800000000000033 (2.1999999999999673)\n",
      "Epoch 961/1200 | Loss 0.8575 | Win/lose count 24.0/14.899999999999977 (9.100000000000023)\n",
      "Epoch 962/1200 | Loss 0.9272 | Win/lose count 28.0/15.799999999999969 (12.200000000000031)\n",
      "Epoch 963/1200 | Loss 0.7716 | Win/lose count 22.0/14.299999999999972 (7.700000000000028)\n",
      "Epoch 964/1200 | Loss 0.8725 | Win/lose count 29.5/13.699999999999978 (15.800000000000022)\n",
      "Epoch 965/1200 | Loss 0.8682 | Win/lose count 19.0/21.400000000000055 (-2.4000000000000554)\n",
      "Epoch 966/1200 | Loss 1.0467 | Win/lose count 21.5/15.499999999999968 (6.000000000000032)\n",
      "Epoch 967/1200 | Loss 0.7888 | Win/lose count 26.5/15.899999999999968 (10.600000000000032)\n",
      "Epoch 968/1200 | Loss 0.9093 | Win/lose count 20.5/16.499999999999975 (4.000000000000025)\n",
      "Epoch 969/1200 | Loss 0.9407 | Win/lose count 25.0/16.09999999999997 (8.90000000000003)\n",
      "Epoch 970/1200 | Loss 1.0032 | Win/lose count 22.0/16.199999999999967 (5.800000000000033)\n",
      "Epoch 971/1200 | Loss 0.7856 | Win/lose count 19.0/16.699999999999964 (2.3000000000000362)\n",
      "Epoch 972/1200 | Loss 0.7290 | Win/lose count 19.0/12.899999999999977 (6.100000000000023)\n",
      "Epoch 973/1200 | Loss 0.8094 | Win/lose count 22.0/14.699999999999973 (7.300000000000027)\n",
      "Epoch 974/1200 | Loss 0.7165 | Win/lose count 18.5/18.499999999999982 (1.7763568394002505e-14)\n",
      "Epoch 975/1200 | Loss 0.7494 | Win/lose count 26.5/16.299999999999976 (10.200000000000024)\n",
      "Epoch 976/1200 | Loss 0.8203 | Win/lose count 25.0/14.799999999999976 (10.200000000000024)\n",
      "Epoch 977/1200 | Loss 0.7781 | Win/lose count 29.5/14.499999999999973 (15.000000000000027)\n",
      "Epoch 978/1200 | Loss 0.9325 | Win/lose count 20.0/13.999999999999979 (6.000000000000021)\n",
      "Epoch 979/1200 | Loss 0.7832 | Win/lose count 23.0/14.199999999999974 (8.800000000000026)\n",
      "New epsilon :  0.09259259259259256\n",
      "Epoch 980/1200 | Loss 1.0182 | Win/lose count 19.5/16.899999999999984 (2.6000000000000156)\n",
      "Epoch 981/1200 | Loss 0.8350 | Win/lose count 18.0/17.199999999999985 (0.8000000000000149)\n",
      "Epoch 982/1200 | Loss 0.8017 | Win/lose count 26.0/16.099999999999977 (9.900000000000023)\n",
      "Epoch 983/1200 | Loss 0.9333 | Win/lose count 21.0/16.09999999999997 (4.9000000000000306)\n",
      "Epoch 984/1200 | Loss 0.9418 | Win/lose count 26.5/14.099999999999971 (12.400000000000029)\n",
      "Epoch 985/1200 | Loss 0.8750 | Win/lose count 27.0/18.200000000000014 (8.799999999999986)\n",
      "Epoch 986/1200 | Loss 0.7559 | Win/lose count 27.0/17.699999999999985 (9.300000000000015)\n",
      "Epoch 987/1200 | Loss 0.9089 | Win/lose count 23.5/18.200000000000003 (5.299999999999997)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1200 | Loss 0.9314 | Win/lose count 23.5/13.599999999999975 (9.900000000000025)\n",
      "Epoch 989/1200 | Loss 0.8059 | Win/lose count 23.0/15.899999999999967 (7.100000000000033)\n",
      "Epoch 990/1200 | Loss 0.9109 | Win/lose count 25.5/12.099999999999973 (13.400000000000027)\n",
      "Epoch 991/1200 | Loss 0.8789 | Win/lose count 23.0/14.69999999999997 (8.30000000000003)\n",
      "Epoch 992/1200 | Loss 0.7187 | Win/lose count 20.5/16.599999999999984 (3.9000000000000163)\n",
      "Epoch 993/1200 | Loss 0.9047 | Win/lose count 21.0/15.89999999999997 (5.10000000000003)\n",
      "Epoch 994/1200 | Loss 0.8586 | Win/lose count 24.0/16.999999999999986 (7.000000000000014)\n",
      "Epoch 995/1200 | Loss 0.7614 | Win/lose count 21.0/16.29999999999998 (4.700000000000021)\n",
      "Epoch 996/1200 | Loss 0.9082 | Win/lose count 21.5/12.599999999999971 (8.900000000000029)\n",
      "Epoch 997/1200 | Loss 0.9634 | Win/lose count 21.5/20.200000000000042 (1.299999999999958)\n",
      "Epoch 998/1200 | Loss 0.7318 | Win/lose count 24.5/20.600000000000044 (3.899999999999956)\n",
      "Epoch 999/1200 | Loss 1.0668 | Win/lose count 22.5/10.999999999999979 (11.500000000000021)\n",
      "New epsilon :  0.1\n",
      "Epoch 1000/1200 | Loss 0.8181 | Win/lose count 22.0/14.399999999999972 (7.600000000000028)\n",
      "Epoch 1001/1200 | Loss 0.9400 | Win/lose count 24.5/17.3 (7.199999999999999)\n",
      "Epoch 1002/1200 | Loss 0.7748 | Win/lose count 21.0/14.999999999999968 (6.000000000000032)\n",
      "Epoch 1003/1200 | Loss 0.8487 | Win/lose count 17.5/16.999999999999982 (0.5000000000000178)\n",
      "Epoch 1004/1200 | Loss 0.6947 | Win/lose count 22.0/13.399999999999972 (8.600000000000028)\n",
      "Epoch 1005/1200 | Loss 0.6510 | Win/lose count 24.0/18.0 (6.0)\n",
      "Epoch 1006/1200 | Loss 0.8190 | Win/lose count 23.5/16.199999999999974 (7.300000000000026)\n",
      "Epoch 1007/1200 | Loss 0.9118 | Win/lose count 21.0/18.900000000000013 (2.099999999999987)\n",
      "Epoch 1008/1200 | Loss 0.6134 | Win/lose count 22.0/13.299999999999976 (8.700000000000024)\n",
      "Epoch 1009/1200 | Loss 0.6294 | Win/lose count 25.0/17.500000000000004 (7.4999999999999964)\n",
      "Epoch 1010/1200 | Loss 0.7703 | Win/lose count 22.0/17.9 (4.100000000000001)\n",
      "Epoch 1011/1200 | Loss 0.6688 | Win/lose count 18.0/15.099999999999973 (2.900000000000027)\n",
      "Epoch 1012/1200 | Loss 0.6735 | Win/lose count 21.0/19.40000000000003 (1.5999999999999694)\n",
      "Epoch 1013/1200 | Loss 0.6786 | Win/lose count 25.0/13.499999999999977 (11.500000000000023)\n",
      "Epoch 1014/1200 | Loss 0.9941 | Win/lose count 26.0/16.699999999999978 (9.300000000000022)\n",
      "Epoch 1015/1200 | Loss 0.6865 | Win/lose count 24.5/13.599999999999973 (10.900000000000027)\n",
      "Epoch 1016/1200 | Loss 0.6803 | Win/lose count 23.0/17.199999999999992 (5.800000000000008)\n",
      "Epoch 1017/1200 | Loss 0.5524 | Win/lose count 25.0/18.600000000000012 (6.399999999999988)\n",
      "Epoch 1018/1200 | Loss 0.7968 | Win/lose count 26.0/15.899999999999972 (10.100000000000028)\n",
      "Epoch 1019/1200 | Loss 0.5625 | Win/lose count 16.5/18.099999999999994 (-1.5999999999999943)\n",
      "New epsilon :  0.1\n",
      "Epoch 1020/1200 | Loss 0.7192 | Win/lose count 21.0/13.099999999999975 (7.900000000000025)\n",
      "Epoch 1021/1200 | Loss 0.7722 | Win/lose count 23.5/15.099999999999977 (8.400000000000023)\n",
      "Epoch 1022/1200 | Loss 0.8260 | Win/lose count 19.0/19.200000000000017 (-0.20000000000001705)\n",
      "Epoch 1023/1200 | Loss 0.5342 | Win/lose count 17.5/14.599999999999971 (2.9000000000000288)\n",
      "Epoch 1024/1200 | Loss 0.6596 | Win/lose count 25.5/12.699999999999973 (12.800000000000027)\n",
      "Epoch 1025/1200 | Loss 0.8599 | Win/lose count 25.0/13.999999999999973 (11.000000000000027)\n",
      "Epoch 1026/1200 | Loss 0.6208 | Win/lose count 19.0/19.700000000000028 (-0.7000000000000277)\n",
      "Epoch 1027/1200 | Loss 0.5625 | Win/lose count 26.0/13.199999999999974 (12.800000000000026)\n",
      "Epoch 1028/1200 | Loss 0.6741 | Win/lose count 24.0/16.49999999999999 (7.500000000000011)\n",
      "Epoch 1029/1200 | Loss 0.7189 | Win/lose count 15.5/19.10000000000001 (-3.6000000000000085)\n",
      "Epoch 1030/1200 | Loss 0.7624 | Win/lose count 22.5/12.399999999999972 (10.100000000000028)\n",
      "Epoch 1031/1200 | Loss 0.7440 | Win/lose count 22.5/14.199999999999982 (8.300000000000018)\n",
      "Epoch 1032/1200 | Loss 0.7647 | Win/lose count 24.0/14.799999999999974 (9.200000000000026)\n",
      "Epoch 1033/1200 | Loss 0.6424 | Win/lose count 19.5/13.799999999999974 (5.700000000000026)\n",
      "Epoch 1034/1200 | Loss 0.7174 | Win/lose count 23.0/12.19999999999998 (10.80000000000002)\n",
      "Epoch 1035/1200 | Loss 0.5447 | Win/lose count 14.0/16.09999999999996 (-2.099999999999959)\n",
      "Epoch 1036/1200 | Loss 0.7922 | Win/lose count 21.5/21.50000000000003 (-2.842170943040401e-14)\n",
      "Epoch 1037/1200 | Loss 0.8847 | Win/lose count 24.0/14.29999999999998 (9.70000000000002)\n",
      "Epoch 1038/1200 | Loss 0.7174 | Win/lose count 17.5/16.899999999999984 (0.6000000000000156)\n",
      "Epoch 1039/1200 | Loss 0.7385 | Win/lose count 20.0/15.799999999999965 (4.200000000000035)\n",
      "New epsilon :  0.1\n",
      "Epoch 1040/1200 | Loss 0.6593 | Win/lose count 20.0/18.299999999999972 (1.7000000000000277)\n",
      "Epoch 1041/1200 | Loss 0.7024 | Win/lose count 21.0/16.399999999999974 (4.600000000000026)\n",
      "Epoch 1042/1200 | Loss 0.5236 | Win/lose count 23.5/14.599999999999971 (8.900000000000029)\n",
      "Epoch 1043/1200 | Loss 0.7654 | Win/lose count 27.5/8.899999999999986 (18.600000000000016)\n",
      "Epoch 1044/1200 | Loss 0.7892 | Win/lose count 26.0/16.69999999999998 (9.300000000000018)\n",
      "Epoch 1045/1200 | Loss 0.6582 | Win/lose count 25.0/16.899999999999988 (8.100000000000012)\n",
      "Epoch 1046/1200 | Loss 0.6185 | Win/lose count 24.5/8.799999999999985 (15.700000000000015)\n",
      "Epoch 1047/1200 | Loss 0.8649 | Win/lose count 17.5/16.199999999999964 (1.3000000000000362)\n",
      "Epoch 1048/1200 | Loss 0.6721 | Win/lose count 23.5/13.699999999999978 (9.800000000000022)\n",
      "Epoch 1049/1200 | Loss 0.9064 | Win/lose count 28.0/15.499999999999977 (12.500000000000023)\n",
      "Epoch 1050/1200 | Loss 0.6187 | Win/lose count 24.0/13.399999999999974 (10.600000000000026)\n",
      "Epoch 1051/1200 | Loss 0.8860 | Win/lose count 20.5/19.000000000000007 (1.499999999999993)\n",
      "Epoch 1052/1200 | Loss 0.7036 | Win/lose count 24.0/11.599999999999978 (12.400000000000022)\n",
      "Epoch 1053/1200 | Loss 0.7004 | Win/lose count 26.0/18.200000000000003 (7.799999999999997)\n",
      "Epoch 1054/1200 | Loss 0.8746 | Win/lose count 15.0/16.99999999999998 (-1.9999999999999787)\n",
      "Epoch 1055/1200 | Loss 0.7244 | Win/lose count 26.5/15.999999999999977 (10.500000000000023)\n",
      "Epoch 1056/1200 | Loss 0.7141 | Win/lose count 20.0/15.299999999999967 (4.700000000000033)\n",
      "Epoch 1057/1200 | Loss 0.8927 | Win/lose count 21.0/14.199999999999973 (6.800000000000027)\n",
      "Epoch 1058/1200 | Loss 1.0003 | Win/lose count 26.0/16.499999999999982 (9.500000000000018)\n",
      "Epoch 1059/1200 | Loss 0.9653 | Win/lose count 21.5/16.399999999999977 (5.100000000000023)\n",
      "New epsilon :  0.1\n",
      "Epoch 1060/1200 | Loss 0.8184 | Win/lose count 27.0/13.999999999999982 (13.000000000000018)\n",
      "Epoch 1061/1200 | Loss 0.7762 | Win/lose count 23.0/12.599999999999975 (10.400000000000025)\n",
      "Epoch 1062/1200 | Loss 1.0391 | Win/lose count 26.5/11.09999999999998 (15.40000000000002)\n",
      "Epoch 1063/1200 | Loss 0.8898 | Win/lose count 25.5/11.899999999999977 (13.600000000000023)\n",
      "Epoch 1064/1200 | Loss 0.8548 | Win/lose count 21.5/16.299999999999976 (5.200000000000024)\n",
      "Epoch 1065/1200 | Loss 0.9385 | Win/lose count 26.5/13.499999999999973 (13.000000000000027)\n",
      "Epoch 1066/1200 | Loss 0.8850 | Win/lose count 18.5/15.09999999999997 (3.4000000000000306)\n",
      "Epoch 1067/1200 | Loss 0.8851 | Win/lose count 16.0/20.599999999999987 (-4.599999999999987)\n",
      "Epoch 1068/1200 | Loss 0.7484 | Win/lose count 18.5/20.100000000000037 (-1.600000000000037)\n",
      "Epoch 1069/1200 | Loss 0.7291 | Win/lose count 22.0/19.80000000000003 (2.199999999999971)\n",
      "Epoch 1070/1200 | Loss 0.7415 | Win/lose count 19.5/16.499999999999986 (3.000000000000014)\n",
      "Epoch 1071/1200 | Loss 0.6574 | Win/lose count 21.5/14.399999999999975 (7.1000000000000245)\n",
      "Epoch 1072/1200 | Loss 1.0006 | Win/lose count 21.0/13.69999999999997 (7.300000000000029)\n",
      "Epoch 1073/1200 | Loss 0.7294 | Win/lose count 22.0/15.499999999999975 (6.500000000000025)\n",
      "Epoch 1074/1200 | Loss 0.6948 | Win/lose count 18.0/23.200000000000067 (-5.200000000000067)\n",
      "Epoch 1075/1200 | Loss 0.6750 | Win/lose count 29.5/16.099999999999977 (13.400000000000023)\n",
      "Epoch 1076/1200 | Loss 0.6949 | Win/lose count 20.5/13.399999999999968 (7.100000000000032)\n",
      "Epoch 1077/1200 | Loss 0.5127 | Win/lose count 20.5/17.099999999999987 (3.400000000000013)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1078/1200 | Loss 0.7300 | Win/lose count 16.5/21.600000000000048 (-5.100000000000048)\n",
      "Epoch 1079/1200 | Loss 0.5290 | Win/lose count 22.0/18.300000000000008 (3.699999999999992)\n",
      "New epsilon :  0.1\n",
      "Epoch 1080/1200 | Loss 0.6198 | Win/lose count 26.0/13.699999999999978 (12.300000000000022)\n",
      "Epoch 1081/1200 | Loss 0.8210 | Win/lose count 25.0/19.000000000000007 (5.999999999999993)\n",
      "Epoch 1082/1200 | Loss 0.5486 | Win/lose count 24.0/13.999999999999982 (10.000000000000018)\n",
      "Epoch 1083/1200 | Loss 0.7418 | Win/lose count 27.5/17.6 (9.899999999999999)\n",
      "Epoch 1084/1200 | Loss 0.8362 | Win/lose count 25.0/12.299999999999972 (12.700000000000028)\n",
      "Epoch 1085/1200 | Loss 0.8034 | Win/lose count 15.0/18.099999999999994 (-3.0999999999999943)\n",
      "Epoch 1086/1200 | Loss 0.8048 | Win/lose count 26.5/13.199999999999976 (13.300000000000024)\n",
      "Epoch 1087/1200 | Loss 0.8071 | Win/lose count 25.0/11.399999999999984 (13.600000000000016)\n",
      "Epoch 1088/1200 | Loss 0.5879 | Win/lose count 23.0/16.39999999999998 (6.600000000000019)\n",
      "Epoch 1089/1200 | Loss 0.9985 | Win/lose count 25.5/14.79999999999997 (10.70000000000003)\n",
      "Epoch 1090/1200 | Loss 0.7096 | Win/lose count 23.0/17.8 (5.199999999999999)\n",
      "Epoch 1091/1200 | Loss 0.7418 | Win/lose count 15.0/14.399999999999967 (0.6000000000000334)\n",
      "Epoch 1092/1200 | Loss 0.6669 | Win/lose count 22.5/16.199999999999978 (6.300000000000022)\n",
      "Epoch 1093/1200 | Loss 0.6221 | Win/lose count 20.0/19.8 (0.1999999999999993)\n",
      "Epoch 1094/1200 | Loss 0.8748 | Win/lose count 25.5/16.89999999999999 (8.600000000000009)\n",
      "Epoch 1095/1200 | Loss 0.6834 | Win/lose count 21.5/15.799999999999963 (5.700000000000037)\n",
      "Epoch 1096/1200 | Loss 0.7026 | Win/lose count 19.5/10.099999999999984 (9.400000000000016)\n",
      "Epoch 1097/1200 | Loss 0.8856 | Win/lose count 22.0/18.20000000000001 (3.79999999999999)\n",
      "Epoch 1098/1200 | Loss 0.7514 | Win/lose count 22.0/20.300000000000033 (1.6999999999999673)\n",
      "Epoch 1099/1200 | Loss 0.6808 | Win/lose count 24.5/14.599999999999973 (9.900000000000027)\n",
      "New epsilon :  0.1\n",
      "Epoch 1100/1200 | Loss 0.7453 | Win/lose count 22.5/18.800000000000004 (3.6999999999999957)\n",
      "Epoch 1101/1200 | Loss 0.7676 | Win/lose count 25.0/14.699999999999978 (10.300000000000022)\n",
      "Epoch 1102/1200 | Loss 0.8047 | Win/lose count 31.0/13.299999999999976 (17.700000000000024)\n",
      "Epoch 1103/1200 | Loss 0.6552 | Win/lose count 18.5/17.5 (1.0)\n",
      "Epoch 1104/1200 | Loss 0.6443 | Win/lose count 24.0/13.099999999999978 (10.900000000000022)\n",
      "Epoch 1105/1200 | Loss 0.8440 | Win/lose count 10.5/18.69999999999999 (-8.199999999999989)\n",
      "Epoch 1106/1200 | Loss 0.9071 | Win/lose count 22.0/17.299999999999976 (4.700000000000024)\n",
      "Epoch 1107/1200 | Loss 0.8995 | Win/lose count 27.5/13.399999999999979 (14.100000000000021)\n",
      "Epoch 1108/1200 | Loss 0.7006 | Win/lose count 21.0/16.29999999999997 (4.700000000000031)\n",
      "Epoch 1109/1200 | Loss 0.7917 | Win/lose count 26.5/14.399999999999975 (12.100000000000025)\n",
      "Epoch 1110/1200 | Loss 0.8530 | Win/lose count 21.0/17.799999999999976 (3.200000000000024)\n",
      "Epoch 1111/1200 | Loss 0.7598 | Win/lose count 27.0/13.899999999999975 (13.100000000000025)\n",
      "Epoch 1112/1200 | Loss 0.7160 | Win/lose count 26.5/16.099999999999977 (10.400000000000023)\n",
      "Epoch 1113/1200 | Loss 0.6330 | Win/lose count 17.5/16.199999999999974 (1.3000000000000256)\n",
      "Epoch 1114/1200 | Loss 0.7777 | Win/lose count 21.5/16.699999999999985 (4.800000000000015)\n",
      "Epoch 1115/1200 | Loss 0.8636 | Win/lose count 23.0/8.699999999999989 (14.300000000000011)\n",
      "Epoch 1116/1200 | Loss 0.6301 | Win/lose count 26.0/18.30000000000001 (7.699999999999989)\n",
      "Epoch 1117/1200 | Loss 0.9417 | Win/lose count 18.0/13.699999999999969 (4.300000000000031)\n",
      "Epoch 1118/1200 | Loss 1.0028 | Win/lose count 19.5/16.999999999999986 (2.500000000000014)\n",
      "Epoch 1119/1200 | Loss 0.6294 | Win/lose count 24.0/12.999999999999977 (11.000000000000023)\n",
      "New epsilon :  0.1\n",
      "Epoch 1120/1200 | Loss 0.5885 | Win/lose count 27.5/15.699999999999978 (11.800000000000022)\n",
      "Epoch 1121/1200 | Loss 0.7687 | Win/lose count 20.5/13.29999999999998 (7.200000000000021)\n",
      "Epoch 1122/1200 | Loss 0.7242 | Win/lose count 18.5/17.199999999999985 (1.300000000000015)\n",
      "Epoch 1123/1200 | Loss 0.7170 | Win/lose count 24.5/17.29999999999999 (7.20000000000001)\n",
      "Epoch 1124/1200 | Loss 0.7368 | Win/lose count 28.5/11.29999999999998 (17.20000000000002)\n",
      "Epoch 1125/1200 | Loss 0.8048 | Win/lose count 18.5/14.79999999999997 (3.7000000000000295)\n",
      "Epoch 1126/1200 | Loss 0.8351 | Win/lose count 22.5/18.599999999999998 (3.900000000000002)\n",
      "Epoch 1127/1200 | Loss 0.6653 | Win/lose count 21.5/15.199999999999967 (6.300000000000033)\n",
      "Epoch 1128/1200 | Loss 0.7475 | Win/lose count 18.5/23.500000000000043 (-5.000000000000043)\n",
      "Epoch 1129/1200 | Loss 0.6162 | Win/lose count 25.0/13.299999999999972 (11.700000000000028)\n",
      "Epoch 1130/1200 | Loss 0.5756 | Win/lose count 17.5/16.499999999999968 (1.000000000000032)\n",
      "Epoch 1131/1200 | Loss 0.5902 | Win/lose count 26.5/15.799999999999974 (10.700000000000026)\n",
      "Epoch 1132/1200 | Loss 0.5784 | Win/lose count 19.0/19.900000000000034 (-0.9000000000000341)\n",
      "Epoch 1133/1200 | Loss 0.9082 | Win/lose count 23.5/14.29999999999998 (9.20000000000002)\n",
      "Epoch 1134/1200 | Loss 0.5343 | Win/lose count 25.0/13.999999999999973 (11.000000000000027)\n",
      "Epoch 1135/1200 | Loss 0.5649 | Win/lose count 22.0/13.799999999999972 (8.200000000000028)\n",
      "Epoch 1136/1200 | Loss 0.4760 | Win/lose count 24.0/13.099999999999984 (10.900000000000016)\n",
      "Epoch 1137/1200 | Loss 0.9107 | Win/lose count 22.0/21.000000000000025 (0.9999999999999751)\n",
      "Epoch 1138/1200 | Loss 0.6920 | Win/lose count 28.5/14.099999999999977 (14.400000000000023)\n",
      "Epoch 1139/1200 | Loss 0.9006 | Win/lose count 24.0/18.5 (5.5)\n",
      "New epsilon :  0.1\n",
      "Epoch 1140/1200 | Loss 0.5686 | Win/lose count 22.0/18.200000000000006 (3.7999999999999936)\n",
      "Epoch 1141/1200 | Loss 0.9178 | Win/lose count 27.0/12.29999999999998 (14.70000000000002)\n",
      "Epoch 1142/1200 | Loss 0.8090 | Win/lose count 26.5/14.29999999999997 (12.20000000000003)\n",
      "Epoch 1143/1200 | Loss 0.6769 | Win/lose count 24.0/14.799999999999974 (9.200000000000026)\n",
      "Epoch 1144/1200 | Loss 0.7007 | Win/lose count 18.5/15.599999999999966 (2.900000000000034)\n",
      "Epoch 1145/1200 | Loss 0.7914 | Win/lose count 21.0/15.499999999999968 (5.500000000000032)\n",
      "Epoch 1146/1200 | Loss 0.9202 | Win/lose count 22.0/12.699999999999973 (9.300000000000027)\n",
      "Epoch 1147/1200 | Loss 0.7669 | Win/lose count 25.5/14.29999999999997 (11.20000000000003)\n",
      "Epoch 1148/1200 | Loss 0.9131 | Win/lose count 12.0/16.499999999999964 (-4.4999999999999645)\n",
      "Epoch 1149/1200 | Loss 0.8886 | Win/lose count 23.0/14.799999999999974 (8.200000000000026)\n",
      "Epoch 1150/1200 | Loss 0.6602 | Win/lose count 19.5/15.699999999999966 (3.8000000000000345)\n",
      "Epoch 1151/1200 | Loss 0.8424 | Win/lose count 19.5/14.99999999999997 (4.50000000000003)\n",
      "Epoch 1152/1200 | Loss 0.4951 | Win/lose count 17.5/16.69999999999998 (0.8000000000000185)\n",
      "Epoch 1153/1200 | Loss 0.5298 | Win/lose count 20.5/14.199999999999974 (6.300000000000026)\n",
      "Epoch 1154/1200 | Loss 0.6483 | Win/lose count 22.0/14.89999999999997 (7.10000000000003)\n",
      "Epoch 1155/1200 | Loss 0.8098 | Win/lose count 23.5/12.19999999999998 (11.30000000000002)\n",
      "Epoch 1156/1200 | Loss 0.5580 | Win/lose count 21.5/13.89999999999997 (7.60000000000003)\n",
      "Epoch 1157/1200 | Loss 0.8896 | Win/lose count 19.5/19.100000000000012 (0.3999999999999879)\n",
      "Epoch 1158/1200 | Loss 0.5932 | Win/lose count 27.0/14.899999999999974 (12.100000000000026)\n",
      "Epoch 1159/1200 | Loss 0.4659 | Win/lose count 24.5/16.099999999999973 (8.400000000000027)\n",
      "New epsilon :  0.1\n",
      "Epoch 1160/1200 | Loss 0.7482 | Win/lose count 21.0/17.800000000000004 (3.1999999999999957)\n",
      "Epoch 1161/1200 | Loss 0.6529 | Win/lose count 24.0/16.599999999999984 (7.400000000000016)\n",
      "Epoch 1162/1200 | Loss 0.6307 | Win/lose count 21.0/15.099999999999977 (5.9000000000000234)\n",
      "Epoch 1163/1200 | Loss 0.5429 | Win/lose count 19.5/15.49999999999997 (4.00000000000003)\n",
      "Epoch 1164/1200 | Loss 0.7587 | Win/lose count 28.5/12.29999999999998 (16.20000000000002)\n",
      "Epoch 1165/1200 | Loss 0.6627 | Win/lose count 20.5/18.200000000000003 (2.299999999999997)\n",
      "Epoch 1166/1200 | Loss 0.5337 | Win/lose count 20.5/18.30000000000002 (2.1999999999999815)\n",
      "Epoch 1167/1200 | Loss 0.8113 | Win/lose count 23.0/14.899999999999977 (8.100000000000023)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1168/1200 | Loss 0.7066 | Win/lose count 13.5/15.499999999999966 (-1.9999999999999662)\n",
      "Epoch 1169/1200 | Loss 0.9297 | Win/lose count 12.0/20.400000000000034 (-8.400000000000034)\n",
      "Epoch 1170/1200 | Loss 0.7469 | Win/lose count 26.0/17.4 (8.600000000000001)\n",
      "Epoch 1171/1200 | Loss 0.5969 | Win/lose count 21.0/18.900000000000006 (2.0999999999999943)\n",
      "Epoch 1172/1200 | Loss 0.7660 | Win/lose count 18.5/16.39999999999998 (2.100000000000019)\n",
      "Epoch 1173/1200 | Loss 0.4550 | Win/lose count 22.0/18.200000000000003 (3.799999999999997)\n",
      "Epoch 1174/1200 | Loss 0.5611 | Win/lose count 25.0/16.899999999999977 (8.100000000000023)\n",
      "Epoch 1175/1200 | Loss 0.7676 | Win/lose count 21.0/17.899999999999995 (3.100000000000005)\n",
      "Epoch 1176/1200 | Loss 0.5939 | Win/lose count 24.5/14.29999999999998 (10.20000000000002)\n",
      "Epoch 1177/1200 | Loss 0.7758 | Win/lose count 23.0/13.199999999999974 (9.800000000000026)\n",
      "Epoch 1178/1200 | Loss 0.8694 | Win/lose count 28.0/16.39999999999998 (11.60000000000002)\n",
      "Epoch 1179/1200 | Loss 0.6628 | Win/lose count 26.0/14.599999999999975 (11.400000000000025)\n",
      "New epsilon :  0.1\n",
      "Epoch 1180/1200 | Loss 0.4516 | Win/lose count 23.5/21.50000000000003 (1.9999999999999716)\n",
      "Epoch 1181/1200 | Loss 0.6592 | Win/lose count 25.0/16.499999999999986 (8.500000000000014)\n",
      "Epoch 1182/1200 | Loss 0.6892 | Win/lose count 19.0/15.59999999999997 (3.4000000000000306)\n",
      "Epoch 1183/1200 | Loss 0.8081 | Win/lose count 25.0/14.099999999999977 (10.900000000000023)\n",
      "Epoch 1184/1200 | Loss 0.8243 | Win/lose count 25.0/14.599999999999975 (10.400000000000025)\n",
      "Epoch 1185/1200 | Loss 0.8617 | Win/lose count 24.0/14.999999999999972 (9.000000000000028)\n",
      "Epoch 1186/1200 | Loss 0.8066 | Win/lose count 23.5/18.900000000000016 (4.599999999999984)\n",
      "Epoch 1187/1200 | Loss 0.7825 | Win/lose count 21.0/19.900000000000027 (1.099999999999973)\n",
      "Epoch 1188/1200 | Loss 0.9256 | Win/lose count 23.5/14.699999999999974 (8.800000000000026)\n",
      "Epoch 1189/1200 | Loss 0.7635 | Win/lose count 21.0/16.599999999999977 (4.4000000000000234)\n",
      "Epoch 1190/1200 | Loss 0.8375 | Win/lose count 28.0/12.799999999999986 (15.200000000000014)\n",
      "Epoch 1191/1200 | Loss 0.7251 | Win/lose count 26.0/17.399999999999995 (8.600000000000005)\n",
      "Epoch 1192/1200 | Loss 0.7954 | Win/lose count 21.5/14.69999999999997 (6.800000000000029)\n",
      "Epoch 1193/1200 | Loss 0.9231 | Win/lose count 21.0/13.499999999999972 (7.500000000000028)\n",
      "Epoch 1194/1200 | Loss 0.6575 | Win/lose count 18.5/19.500000000000014 (-1.0000000000000142)\n",
      "Epoch 1195/1200 | Loss 0.7267 | Win/lose count 23.0/14.49999999999997 (8.50000000000003)\n",
      "Epoch 1196/1200 | Loss 0.7143 | Win/lose count 19.0/16.499999999999975 (2.500000000000025)\n",
      "Epoch 1197/1200 | Loss 1.0294 | Win/lose count 26.5/13.499999999999977 (13.000000000000023)\n",
      "Epoch 1198/1200 | Loss 0.6824 | Win/lose count 21.0/14.099999999999968 (6.900000000000032)\n",
      "Epoch 1199/1200 | Loss 0.6417 | Win/lose count 23.5/18.700000000000014 (4.7999999999999865)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=temperature)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 1, memory_size=2500, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 20.0/4.0. Average score (16.0)\n",
      "Win/lose count 23.0/2.0. Average score (18.5)\n",
      "Win/lose count 27.0/3.0. Average score (20.333333333333332)\n",
      "Win/lose count 21.5/3.0. Average score (19.875)\n",
      "Win/lose count 26.0/0. Average score (21.1)\n",
      "Win/lose count 12.0/3.0. Average score (19.083333333333332)\n",
      "Win/lose count 17.0/0. Average score (18.785714285714285)\n",
      "Win/lose count 23.0/6.0. Average score (18.5625)\n",
      "Win/lose count 29.5/7.0. Average score (19.0)\n",
      "Win/lose count 25.0/4.0. Average score (19.2)\n",
      "Win/lose count 22.5/2.0. Average score (19.318181818181817)\n",
      "Win/lose count 19.0/3.0. Average score (19.041666666666668)\n",
      "Win/lose count 24.0/3.0. Average score (19.192307692307693)\n",
      "Win/lose count 22.0/4.0. Average score (19.107142857142858)\n",
      "Win/lose count 20.5/1.0. Average score (19.133333333333333)\n",
      "Win/lose count 24.0/4.0. Average score (19.1875)\n",
      "Win/lose count 9.5/2.0. Average score (18.5)\n",
      "Win/lose count 21.0/5.0. Average score (18.36111111111111)\n",
      "Win/lose count 18.0/2.0. Average score (18.236842105263158)\n",
      "Win/lose count 12.5/1.0. Average score (17.9)\n",
      "Win/lose count 25.5/5.0. Average score (18.023809523809526)\n",
      "Win/lose count 19.0/8.0. Average score (17.704545454545453)\n",
      "Win/lose count 20.5/7.0. Average score (17.52173913043478)\n",
      "Win/lose count 9.0/1.0. Average score (17.125)\n",
      "Win/lose count 26.0/6.0. Average score (17.24)\n",
      "Final score: 17.24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T,temperature=temperature)\n",
    "agent_cnn_explore = DQN_CNN(size, lr=.1, epsilon = 1, memory_size=2500, batch_size = 32,n_state=3)\n",
    "agent_cnn_explore.load(name_weights='cnn_train_exploremodel.h5',name_model='cnn_train_exploremodel.json')\n",
    "\n",
    "test(agent_cnn_explore,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__ At first, I tried training for 400 epochs with a temperature of 0.3. Our agent explored a much larger area of the map but, still, it got stuck at the end, oscillating whereas a non negligable number of bonus cases were remaining (the results were still better than in the previous model). \n",
    "\n",
    "I then tried training for a longer time (1200 epochs) still with a temperature of 0.3: the results were much better. If the temperature is small enough during testing (like 0.2), all bonuses are usually picked up. When the temperarture increases, our agent is still doing a good work even if he often forgets some bonuses at the end of the game, especially if they are sparse on the board (it then starts oscillating). To tackle this issue, we could consider training for an even longer time and change epsilon a little bit less often so that the period of high exploration lasts longer. Indeed, here epsilon decreases every 20 epochs at the beginning until it reachs 0.1 after around 90% of the epochs, and at this moment, we let it to 0.1 for the 10% remaining epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
